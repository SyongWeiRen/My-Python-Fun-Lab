{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 準備資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# 匯入datasets\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n",
      "60000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# 確認data數量沒錯\n",
    "print(len(x_train))\n",
    "print(len(x_test))\n",
    "print(len(y_train))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n",
      "(28, 28)\n",
      "()\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "# 確認data的shape\n",
    "print(x_train[0].shape)\n",
    "print(x_test[0].shape)\n",
    "print(y_train[0].shape)\n",
    "print(y_test[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將x_train, x_test改成784*1向量\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "# 做標準化\n",
    "x_train_st = (x_train - x_train.min()) / (x_train.max() - x_train.min())\n",
    "x_test_st = (x_test - x_test.min()) / (x_test.max() - x_test.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 匯入 one-hot encoding \n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將y_train, y_test以 one-hot encoding 進行編碼\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建立神經網路"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 想探討 learning rate 的大小對於正確率的影響\n",
    "* 固定 2 層 hidden layer, 第一層為 20, 第二層為 15\n",
    "* 逐漸加大 learning rate 的數值(0.01~1), 並畫圖比較 accuracy 及 loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 20)                15700     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 15)                315       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                160       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 16,175\n",
      "Trainable params: 16,175\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "\n",
    "model1.add(Dense(20, input_dim=784))\n",
    "model1.add(Activation('sigmoid'))\n",
    "\n",
    "model1.add(Dense(15))\n",
    "model1.add(Activation('sigmoid'))\n",
    "\n",
    "model1.add(Dense(10))\n",
    "model1.add(Activation('softmax'))\n",
    "            \n",
    "model1.compile(loss='mse', optimizer=SGD(lr=0.01), metrics=['accuracy'])\n",
    "            \n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0977 - acc: 0.0974 - val_loss: 0.0962 - val_acc: 0.0982\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0953 - acc: 0.0974 - val_loss: 0.0945 - val_acc: 0.0982\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0940 - acc: 0.0974 - val_loss: 0.0935 - val_acc: 0.0982\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0932 - acc: 0.0974 - val_loss: 0.0928 - val_acc: 0.0982\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0926 - acc: 0.0974 - val_loss: 0.0924 - val_acc: 0.0982\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0922 - acc: 0.0974 - val_loss: 0.0920 - val_acc: 0.0982\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0919 - acc: 0.0974 - val_loss: 0.0917 - val_acc: 0.0982\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0917 - acc: 0.0974 - val_loss: 0.0915 - val_acc: 0.0982\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0915 - acc: 0.0974 - val_loss: 0.0913 - val_acc: 0.0982\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0913 - acc: 0.0974 - val_loss: 0.0912 - val_acc: 0.0983\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0911 - acc: 0.0975 - val_loss: 0.0910 - val_acc: 0.0989\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0910 - acc: 0.0982 - val_loss: 0.0909 - val_acc: 0.1004\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0909 - acc: 0.1003 - val_loss: 0.0908 - val_acc: 0.1029\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0908 - acc: 0.1032 - val_loss: 0.0907 - val_acc: 0.1063\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0907 - acc: 0.1074 - val_loss: 0.0906 - val_acc: 0.1118\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0906 - acc: 0.1118 - val_loss: 0.0906 - val_acc: 0.1174\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0906 - acc: 0.1161 - val_loss: 0.0905 - val_acc: 0.1191\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0905 - acc: 0.1197 - val_loss: 0.0904 - val_acc: 0.1211\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0905 - acc: 0.1236 - val_loss: 0.0904 - val_acc: 0.1236\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0904 - acc: 0.1256 - val_loss: 0.0903 - val_acc: 0.1271\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0904 - acc: 0.1283 - val_loss: 0.0903 - val_acc: 0.1293\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0903 - acc: 0.1302 - val_loss: 0.0903 - val_acc: 0.1318\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0903 - acc: 0.1323 - val_loss: 0.0902 - val_acc: 0.1342\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0902 - acc: 0.1348 - val_loss: 0.0902 - val_acc: 0.1356\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0902 - acc: 0.1375 - val_loss: 0.0902 - val_acc: 0.1408\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0902 - acc: 0.1414 - val_loss: 0.0901 - val_acc: 0.1442\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0901 - acc: 0.1454 - val_loss: 0.0901 - val_acc: 0.1495\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0901 - acc: 0.1492 - val_loss: 0.0901 - val_acc: 0.1538\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0901 - acc: 0.1539 - val_loss: 0.0900 - val_acc: 0.1586\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0901 - acc: 0.1574 - val_loss: 0.0900 - val_acc: 0.1615\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0900 - acc: 0.1616 - val_loss: 0.0900 - val_acc: 0.1647\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0900 - acc: 0.1647 - val_loss: 0.0900 - val_acc: 0.1664\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0900 - acc: 0.1669 - val_loss: 0.0900 - val_acc: 0.1690\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0900 - acc: 0.1694 - val_loss: 0.0899 - val_acc: 0.1718\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0900 - acc: 0.1718 - val_loss: 0.0899 - val_acc: 0.1742\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0899 - acc: 0.1735 - val_loss: 0.0899 - val_acc: 0.1769\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0899 - acc: 0.1757 - val_loss: 0.0899 - val_acc: 0.1783\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0899 - acc: 0.1770 - val_loss: 0.0899 - val_acc: 0.1803\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0899 - acc: 0.1779 - val_loss: 0.0899 - val_acc: 0.1809\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0899 - acc: 0.1790 - val_loss: 0.0898 - val_acc: 0.1808\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0899 - acc: 0.1796 - val_loss: 0.0898 - val_acc: 0.1807\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0899 - acc: 0.1802 - val_loss: 0.0898 - val_acc: 0.1818\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0898 - acc: 0.1813 - val_loss: 0.0898 - val_acc: 0.1831\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0898 - acc: 0.1839 - val_loss: 0.0898 - val_acc: 0.1856\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0898 - acc: 0.1881 - val_loss: 0.0898 - val_acc: 0.1925\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0898 - acc: 0.1961 - val_loss: 0.0898 - val_acc: 0.2023\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0898 - acc: 0.2056 - val_loss: 0.0898 - val_acc: 0.2112\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0898 - acc: 0.2128 - val_loss: 0.0897 - val_acc: 0.2195\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0898 - acc: 0.2202 - val_loss: 0.0897 - val_acc: 0.2234\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0898 - acc: 0.2224 - val_loss: 0.0897 - val_acc: 0.2235\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0897 - acc: 0.2203 - val_loss: 0.0897 - val_acc: 0.2176\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0897 - acc: 0.2164 - val_loss: 0.0897 - val_acc: 0.2125\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0897 - acc: 0.2106 - val_loss: 0.0897 - val_acc: 0.2049\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0897 - acc: 0.2045 - val_loss: 0.0897 - val_acc: 0.1979\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0897 - acc: 0.2003 - val_loss: 0.0897 - val_acc: 0.1914\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0897 - acc: 0.1943 - val_loss: 0.0897 - val_acc: 0.1869\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0897 - acc: 0.1890 - val_loss: 0.0896 - val_acc: 0.1836\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0897 - acc: 0.1847 - val_loss: 0.0896 - val_acc: 0.1792\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0897 - acc: 0.1805 - val_loss: 0.0896 - val_acc: 0.1759\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0897 - acc: 0.1770 - val_loss: 0.0896 - val_acc: 0.1739\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0896 - acc: 0.1738 - val_loss: 0.0896 - val_acc: 0.1720\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0896 - acc: 0.1722 - val_loss: 0.0896 - val_acc: 0.1690\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0896 - acc: 0.1697 - val_loss: 0.0896 - val_acc: 0.1683\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0896 - acc: 0.1681 - val_loss: 0.0896 - val_acc: 0.1670\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0896 - acc: 0.1670 - val_loss: 0.0896 - val_acc: 0.1666\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0896 - acc: 0.1651 - val_loss: 0.0896 - val_acc: 0.1670\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0896 - acc: 0.1653 - val_loss: 0.0896 - val_acc: 0.1670\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0896 - acc: 0.1655 - val_loss: 0.0895 - val_acc: 0.1668\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0896 - acc: 0.1655 - val_loss: 0.0895 - val_acc: 0.1663\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0896 - acc: 0.1653 - val_loss: 0.0895 - val_acc: 0.1670\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0896 - acc: 0.1661 - val_loss: 0.0895 - val_acc: 0.1679\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 0.0895 - acc: 0.166 - 1s 19us/step - loss: 0.0895 - acc: 0.1669 - val_loss: 0.0895 - val_acc: 0.1680\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0895 - acc: 0.1671 - val_loss: 0.0895 - val_acc: 0.1695\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0895 - acc: 0.1689 - val_loss: 0.0895 - val_acc: 0.1716\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0895 - acc: 0.1694 - val_loss: 0.0895 - val_acc: 0.1729\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0895 - acc: 0.1715 - val_loss: 0.0895 - val_acc: 0.1742\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0895 - acc: 0.1725 - val_loss: 0.0895 - val_acc: 0.1761\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0895 - acc: 0.1740 - val_loss: 0.0895 - val_acc: 0.1777\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0895 - acc: 0.1748 - val_loss: 0.0895 - val_acc: 0.1794\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0895 - acc: 0.1768 - val_loss: 0.0894 - val_acc: 0.1810\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0895 - acc: 0.1788 - val_loss: 0.0894 - val_acc: 0.1825\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0895 - acc: 0.1799 - val_loss: 0.0894 - val_acc: 0.1850\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0894 - acc: 0.1825 - val_loss: 0.0894 - val_acc: 0.1866\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0894 - acc: 0.1843 - val_loss: 0.0894 - val_acc: 0.1884\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0894 - acc: 0.1864 - val_loss: 0.0894 - val_acc: 0.1908\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0894 - acc: 0.1884 - val_loss: 0.0894 - val_acc: 0.1933\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0894 - acc: 0.1914 - val_loss: 0.0894 - val_acc: 0.1953\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0894 - acc: 0.1930 - val_loss: 0.0894 - val_acc: 0.1987\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0894 - acc: 0.1950 - val_loss: 0.0894 - val_acc: 0.2014\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0894 - acc: 0.1970 - val_loss: 0.0894 - val_acc: 0.2036\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0894 - acc: 0.2008 - val_loss: 0.0894 - val_acc: 0.2055\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0894 - acc: 0.2030 - val_loss: 0.0893 - val_acc: 0.2092\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0894 - acc: 0.2041 - val_loss: 0.0893 - val_acc: 0.2124\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0894 - acc: 0.2073 - val_loss: 0.0893 - val_acc: 0.2141\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0893 - acc: 0.2097 - val_loss: 0.0893 - val_acc: 0.2154\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0893 - acc: 0.2116 - val_loss: 0.0893 - val_acc: 0.2174\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0893 - acc: 0.2147 - val_loss: 0.0893 - val_acc: 0.2195\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0893 - acc: 0.2165 - val_loss: 0.0893 - val_acc: 0.2227\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0893 - acc: 0.2187 - val_loss: 0.0893 - val_acc: 0.2254\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0893 - acc: 0.2207 - val_loss: 0.0893 - val_acc: 0.2278\n"
     ]
    }
   ],
   "source": [
    "model1_1 = model1.fit(x_train_st, y_train, batch_size=150, epochs=100, verbose=1, validation_data=(x_test_st, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lr = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 20)                15700     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 15)                315       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                160       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 16,175\n",
      "Trainable params: 16,175\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "\n",
    "model2.add(Dense(20, input_dim=784))\n",
    "model2.add(Activation('sigmoid'))\n",
    "\n",
    "model2.add(Dense(15))\n",
    "model2.add(Activation('sigmoid'))\n",
    "\n",
    "model2.add(Dense(10))\n",
    "model2.add(Activation('softmax'))\n",
    "            \n",
    "model2.compile(loss='mse', optimizer=SGD(lr=0.05), metrics=['accuracy'])\n",
    "            \n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0919 - acc: 0.0888 - val_loss: 0.0915 - val_acc: 0.0882\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0912 - acc: 0.0939 - val_loss: 0.0910 - val_acc: 0.0932\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0908 - acc: 0.0968 - val_loss: 0.0906 - val_acc: 0.0926\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0904 - acc: 0.1189 - val_loss: 0.0903 - val_acc: 0.1334\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0902 - acc: 0.1347 - val_loss: 0.0901 - val_acc: 0.1283\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0900 - acc: 0.1254 - val_loss: 0.0900 - val_acc: 0.1225\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0899 - acc: 0.1216 - val_loss: 0.0899 - val_acc: 0.1202\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0898 - acc: 0.1202 - val_loss: 0.0898 - val_acc: 0.1186\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0897 - acc: 0.1177 - val_loss: 0.0897 - val_acc: 0.1177\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0897 - acc: 0.1173 - val_loss: 0.0896 - val_acc: 0.1181\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0896 - acc: 0.1181 - val_loss: 0.0896 - val_acc: 0.1197\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0896 - acc: 0.1185 - val_loss: 0.0895 - val_acc: 0.1214\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0895 - acc: 0.1206 - val_loss: 0.0895 - val_acc: 0.1240\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0895 - acc: 0.1219 - val_loss: 0.0894 - val_acc: 0.1264\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0894 - acc: 0.1248 - val_loss: 0.0894 - val_acc: 0.1296\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0894 - acc: 0.1283 - val_loss: 0.0894 - val_acc: 0.1323\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0894 - acc: 0.1303 - val_loss: 0.0893 - val_acc: 0.1369\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0893 - acc: 0.1347 - val_loss: 0.0893 - val_acc: 0.1422\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0893 - acc: 0.1405 - val_loss: 0.0892 - val_acc: 0.1461\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0892 - acc: 0.1437 - val_loss: 0.0892 - val_acc: 0.1530\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0892 - acc: 0.1482 - val_loss: 0.0891 - val_acc: 0.1575\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0891 - acc: 0.1516 - val_loss: 0.0891 - val_acc: 0.1630\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0891 - acc: 0.1602 - val_loss: 0.0890 - val_acc: 0.1679\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0890 - acc: 0.1631 - val_loss: 0.0890 - val_acc: 0.1722\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0890 - acc: 0.1679 - val_loss: 0.0889 - val_acc: 0.1778\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0889 - acc: 0.1726 - val_loss: 0.0889 - val_acc: 0.1831\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0889 - acc: 0.1793 - val_loss: 0.0888 - val_acc: 0.1867\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0888 - acc: 0.1807 - val_loss: 0.0888 - val_acc: 0.1915\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0888 - acc: 0.1896 - val_loss: 0.0887 - val_acc: 0.1951\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0887 - acc: 0.1925 - val_loss: 0.0886 - val_acc: 0.1992\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0886 - acc: 0.1984 - val_loss: 0.0886 - val_acc: 0.2028\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0886 - acc: 0.2014 - val_loss: 0.0885 - val_acc: 0.2087\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0885 - acc: 0.2054 - val_loss: 0.0884 - val_acc: 0.2143\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0884 - acc: 0.2125 - val_loss: 0.0884 - val_acc: 0.2179\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0884 - acc: 0.2161 - val_loss: 0.0883 - val_acc: 0.2213\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0883 - acc: 0.2184 - val_loss: 0.0882 - val_acc: 0.2265\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0882 - acc: 0.2228 - val_loss: 0.0881 - val_acc: 0.2306\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0881 - acc: 0.2281 - val_loss: 0.0881 - val_acc: 0.2342\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0881 - acc: 0.2332 - val_loss: 0.0880 - val_acc: 0.2368\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0880 - acc: 0.2366 - val_loss: 0.0879 - val_acc: 0.2400\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0879 - acc: 0.2401 - val_loss: 0.0878 - val_acc: 0.2440\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0878 - acc: 0.2446 - val_loss: 0.0877 - val_acc: 0.2479\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0877 - acc: 0.2459 - val_loss: 0.0876 - val_acc: 0.2516\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0876 - acc: 0.2499 - val_loss: 0.0875 - val_acc: 0.2540\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0875 - acc: 0.2533 - val_loss: 0.0874 - val_acc: 0.2564\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0874 - acc: 0.2556 - val_loss: 0.0873 - val_acc: 0.2584\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0873 - acc: 0.2605 - val_loss: 0.0871 - val_acc: 0.2598\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0871 - acc: 0.2593 - val_loss: 0.0870 - val_acc: 0.2621\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0870 - acc: 0.2621 - val_loss: 0.0869 - val_acc: 0.2642\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0869 - acc: 0.2655 - val_loss: 0.0867 - val_acc: 0.2657\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0868 - acc: 0.2659 - val_loss: 0.0866 - val_acc: 0.2681\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0866 - acc: 0.2695 - val_loss: 0.0864 - val_acc: 0.2693\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0865 - acc: 0.2713 - val_loss: 0.0863 - val_acc: 0.2703\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0863 - acc: 0.2721 - val_loss: 0.0861 - val_acc: 0.2715\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0861 - acc: 0.2738 - val_loss: 0.0859 - val_acc: 0.2718\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0860 - acc: 0.2744 - val_loss: 0.0858 - val_acc: 0.2725\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0858 - acc: 0.2750 - val_loss: 0.0856 - val_acc: 0.2736\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0856 - acc: 0.2758 - val_loss: 0.0854 - val_acc: 0.2747\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0854 - acc: 0.2780 - val_loss: 0.0851 - val_acc: 0.2752\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0852 - acc: 0.2777 - val_loss: 0.0849 - val_acc: 0.2765\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0849 - acc: 0.2797 - val_loss: 0.0847 - val_acc: 0.2770\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0847 - acc: 0.2807 - val_loss: 0.0844 - val_acc: 0.2775\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0845 - acc: 0.2818 - val_loss: 0.0842 - val_acc: 0.2787\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0842 - acc: 0.2825 - val_loss: 0.0839 - val_acc: 0.2795\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0839 - acc: 0.2845 - val_loss: 0.0836 - val_acc: 0.2801\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0836 - acc: 0.2867 - val_loss: 0.0833 - val_acc: 0.2821\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0833 - acc: 0.2882 - val_loss: 0.0830 - val_acc: 0.2839\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0830 - acc: 0.2916 - val_loss: 0.0827 - val_acc: 0.2865\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0827 - acc: 0.2937 - val_loss: 0.0823 - val_acc: 0.2901\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0823 - acc: 0.2974 - val_loss: 0.0820 - val_acc: 0.2940\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0820 - acc: 0.3005 - val_loss: 0.0816 - val_acc: 0.2985\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0816 - acc: 0.3067 - val_loss: 0.0812 - val_acc: 0.3026\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0812 - acc: 0.3103 - val_loss: 0.0808 - val_acc: 0.3063\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0808 - acc: 0.3145 - val_loss: 0.0804 - val_acc: 0.3117\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0805 - acc: 0.3200 - val_loss: 0.0800 - val_acc: 0.3185\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0801 - acc: 0.3268 - val_loss: 0.0796 - val_acc: 0.3263\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0797 - acc: 0.3347 - val_loss: 0.0792 - val_acc: 0.3328\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0793 - acc: 0.3414 - val_loss: 0.0788 - val_acc: 0.3388\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0789 - acc: 0.3473 - val_loss: 0.0784 - val_acc: 0.3460\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0785 - acc: 0.3562 - val_loss: 0.0780 - val_acc: 0.3528\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0781 - acc: 0.3616 - val_loss: 0.0776 - val_acc: 0.3600\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0777 - acc: 0.3693 - val_loss: 0.0772 - val_acc: 0.3660\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0773 - acc: 0.3737 - val_loss: 0.0768 - val_acc: 0.3748\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0769 - acc: 0.3847 - val_loss: 0.0765 - val_acc: 0.3830\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0765 - acc: 0.3946 - val_loss: 0.0761 - val_acc: 0.3894\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0762 - acc: 0.3995 - val_loss: 0.0757 - val_acc: 0.3958\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0758 - acc: 0.4072 - val_loss: 0.0754 - val_acc: 0.4036\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0755 - acc: 0.4137 - val_loss: 0.0750 - val_acc: 0.4115\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0751 - acc: 0.4206 - val_loss: 0.0747 - val_acc: 0.4173\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0748 - acc: 0.4263 - val_loss: 0.0743 - val_acc: 0.4232\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0744 - acc: 0.4319 - val_loss: 0.0740 - val_acc: 0.4290\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0741 - acc: 0.4392 - val_loss: 0.0737 - val_acc: 0.4338\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0738 - acc: 0.4424 - val_loss: 0.0734 - val_acc: 0.4393\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0735 - acc: 0.4484 - val_loss: 0.0730 - val_acc: 0.4439\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0731 - acc: 0.4523 - val_loss: 0.0727 - val_acc: 0.4483\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0728 - acc: 0.4568 - val_loss: 0.0724 - val_acc: 0.4517\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0725 - acc: 0.4592 - val_loss: 0.0721 - val_acc: 0.4552\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0722 - acc: 0.4629 - val_loss: 0.0718 - val_acc: 0.4585\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0718 - acc: 0.4658 - val_loss: 0.0714 - val_acc: 0.4622\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0715 - acc: 0.4694 - val_loss: 0.0711 - val_acc: 0.4652\n"
     ]
    }
   ],
   "source": [
    "model2_1 = model2.fit(x_train_st, y_train, batch_size=150, epochs=100, verbose=1, validation_data=(x_test_st, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 20)                15700     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 15)                315       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                160       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 16,175\n",
      "Trainable params: 16,175\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "\n",
    "model3.add(Dense(20, input_dim=784))\n",
    "model3.add(Activation('sigmoid'))\n",
    "\n",
    "model3.add(Dense(15))\n",
    "model3.add(Activation('sigmoid'))\n",
    "\n",
    "model3.add(Dense(10))\n",
    "model3.add(Activation('softmax'))\n",
    "            \n",
    "model3.compile(loss='mse', optimizer=SGD(lr=0.1), metrics=['accuracy'])\n",
    "            \n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0923 - acc: 0.1651 - val_loss: 0.0913 - val_acc: 0.1766\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0909 - acc: 0.1762 - val_loss: 0.0905 - val_acc: 0.1745\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0903 - acc: 0.1767 - val_loss: 0.0901 - val_acc: 0.1793\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0900 - acc: 0.1771 - val_loss: 0.0898 - val_acc: 0.1857\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0897 - acc: 0.1866 - val_loss: 0.0896 - val_acc: 0.1896\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0895 - acc: 0.1892 - val_loss: 0.0894 - val_acc: 0.1934\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0894 - acc: 0.1919 - val_loss: 0.0893 - val_acc: 0.1961\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0892 - acc: 0.1946 - val_loss: 0.0891 - val_acc: 0.2002\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0891 - acc: 0.1993 - val_loss: 0.0890 - val_acc: 0.2016\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0889 - acc: 0.1999 - val_loss: 0.0888 - val_acc: 0.2047\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0888 - acc: 0.2021 - val_loss: 0.0887 - val_acc: 0.2062\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0886 - acc: 0.2035 - val_loss: 0.0885 - val_acc: 0.2078\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0885 - acc: 0.2054 - val_loss: 0.0883 - val_acc: 0.2085\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0883 - acc: 0.2061 - val_loss: 0.0881 - val_acc: 0.2100\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0881 - acc: 0.2074 - val_loss: 0.0879 - val_acc: 0.2108\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0879 - acc: 0.2080 - val_loss: 0.0877 - val_acc: 0.2106\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0876 - acc: 0.2085 - val_loss: 0.0874 - val_acc: 0.2106\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0873 - acc: 0.2089 - val_loss: 0.0871 - val_acc: 0.2110\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0870 - acc: 0.2096 - val_loss: 0.0868 - val_acc: 0.2112\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0866 - acc: 0.2099 - val_loss: 0.0864 - val_acc: 0.2113\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0862 - acc: 0.2102 - val_loss: 0.0859 - val_acc: 0.2116\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0858 - acc: 0.2106 - val_loss: 0.0854 - val_acc: 0.2119\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0853 - acc: 0.2107 - val_loss: 0.0849 - val_acc: 0.2132\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0847 - acc: 0.2116 - val_loss: 0.0842 - val_acc: 0.2141\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0841 - acc: 0.2129 - val_loss: 0.0836 - val_acc: 0.2161\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0834 - acc: 0.2150 - val_loss: 0.0829 - val_acc: 0.2180\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0828 - acc: 0.2169 - val_loss: 0.0822 - val_acc: 0.2216\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0821 - acc: 0.2206 - val_loss: 0.0815 - val_acc: 0.2251\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0814 - acc: 0.2249 - val_loss: 0.0809 - val_acc: 0.2287\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0808 - acc: 0.2292 - val_loss: 0.0802 - val_acc: 0.2333\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0801 - acc: 0.2349 - val_loss: 0.0796 - val_acc: 0.2381\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0795 - acc: 0.2418 - val_loss: 0.0789 - val_acc: 0.2456\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0789 - acc: 0.2503 - val_loss: 0.0783 - val_acc: 0.2553\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0783 - acc: 0.2613 - val_loss: 0.0777 - val_acc: 0.2654\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0777 - acc: 0.2732 - val_loss: 0.0771 - val_acc: 0.2764\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0771 - acc: 0.2848 - val_loss: 0.0765 - val_acc: 0.2882\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0766 - acc: 0.2971 - val_loss: 0.0760 - val_acc: 0.2999\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0760 - acc: 0.3084 - val_loss: 0.0754 - val_acc: 0.3110\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0754 - acc: 0.3231 - val_loss: 0.0748 - val_acc: 0.3214\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0749 - acc: 0.3316 - val_loss: 0.0743 - val_acc: 0.3371\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0744 - acc: 0.3450 - val_loss: 0.0737 - val_acc: 0.3490\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0738 - acc: 0.3564 - val_loss: 0.0732 - val_acc: 0.3618\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0733 - acc: 0.3676 - val_loss: 0.0727 - val_acc: 0.3739\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0728 - acc: 0.3777 - val_loss: 0.0721 - val_acc: 0.3835\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0723 - acc: 0.3870 - val_loss: 0.0716 - val_acc: 0.3951\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0718 - acc: 0.3966 - val_loss: 0.0711 - val_acc: 0.4064\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0712 - acc: 0.4043 - val_loss: 0.0706 - val_acc: 0.4181\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0707 - acc: 0.4132 - val_loss: 0.0700 - val_acc: 0.4278\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0702 - acc: 0.4239 - val_loss: 0.0695 - val_acc: 0.4357\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0697 - acc: 0.4316 - val_loss: 0.0690 - val_acc: 0.4455\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0692 - acc: 0.4438 - val_loss: 0.0685 - val_acc: 0.4553\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0687 - acc: 0.4539 - val_loss: 0.0679 - val_acc: 0.4647\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0681 - acc: 0.4651 - val_loss: 0.0674 - val_acc: 0.4735\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0676 - acc: 0.4755 - val_loss: 0.0668 - val_acc: 0.4837\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0671 - acc: 0.4847 - val_loss: 0.0663 - val_acc: 0.4954\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0665 - acc: 0.4962 - val_loss: 0.0657 - val_acc: 0.5081\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0659 - acc: 0.5098 - val_loss: 0.0651 - val_acc: 0.5191\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0653 - acc: 0.5196 - val_loss: 0.0645 - val_acc: 0.5311\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0648 - acc: 0.5324 - val_loss: 0.0639 - val_acc: 0.5412\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0641 - acc: 0.5430 - val_loss: 0.0633 - val_acc: 0.5502\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0635 - acc: 0.5496 - val_loss: 0.0626 - val_acc: 0.5613\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0628 - acc: 0.5597 - val_loss: 0.0620 - val_acc: 0.5698\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0621 - acc: 0.5700 - val_loss: 0.0612 - val_acc: 0.5757\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0614 - acc: 0.5772 - val_loss: 0.0605 - val_acc: 0.5816\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0607 - acc: 0.5823 - val_loss: 0.0598 - val_acc: 0.5874\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0599 - acc: 0.5902 - val_loss: 0.0590 - val_acc: 0.5946\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0592 - acc: 0.5965 - val_loss: 0.0582 - val_acc: 0.6024\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0584 - acc: 0.6014 - val_loss: 0.0574 - val_acc: 0.6083\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0576 - acc: 0.6061 - val_loss: 0.0566 - val_acc: 0.6141\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0568 - acc: 0.6106 - val_loss: 0.0558 - val_acc: 0.6178\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0560 - acc: 0.6142 - val_loss: 0.0550 - val_acc: 0.6224\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0552 - acc: 0.6178 - val_loss: 0.0542 - val_acc: 0.6251\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0544 - acc: 0.6209 - val_loss: 0.0535 - val_acc: 0.6292\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0537 - acc: 0.6250 - val_loss: 0.0527 - val_acc: 0.6334\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0530 - acc: 0.6287 - val_loss: 0.0520 - val_acc: 0.6363\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0522 - acc: 0.6329 - val_loss: 0.0513 - val_acc: 0.6412\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0515 - acc: 0.6371 - val_loss: 0.0506 - val_acc: 0.6458\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0509 - acc: 0.6412 - val_loss: 0.0499 - val_acc: 0.6507\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0502 - acc: 0.6460 - val_loss: 0.0493 - val_acc: 0.6565\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0496 - acc: 0.6503 - val_loss: 0.0486 - val_acc: 0.6606\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0489 - acc: 0.6551 - val_loss: 0.0480 - val_acc: 0.6656\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0483 - acc: 0.6606 - val_loss: 0.0474 - val_acc: 0.6701\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0477 - acc: 0.6658 - val_loss: 0.0468 - val_acc: 0.6742\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0471 - acc: 0.6698 - val_loss: 0.0462 - val_acc: 0.6797\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0465 - acc: 0.6750 - val_loss: 0.0456 - val_acc: 0.6842\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0459 - acc: 0.6789 - val_loss: 0.0451 - val_acc: 0.6887\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0454 - acc: 0.6838 - val_loss: 0.0445 - val_acc: 0.6914\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0448 - acc: 0.6876 - val_loss: 0.0440 - val_acc: 0.6967\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0443 - acc: 0.6926 - val_loss: 0.0434 - val_acc: 0.7005\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0437 - acc: 0.6971 - val_loss: 0.0429 - val_acc: 0.7048\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0432 - acc: 0.7017 - val_loss: 0.0424 - val_acc: 0.7090\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0427 - acc: 0.7066 - val_loss: 0.0418 - val_acc: 0.7138\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0422 - acc: 0.7113 - val_loss: 0.0413 - val_acc: 0.7176\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0417 - acc: 0.7159 - val_loss: 0.0408 - val_acc: 0.7224\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0412 - acc: 0.7204 - val_loss: 0.0404 - val_acc: 0.7270\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0407 - acc: 0.7245 - val_loss: 0.0399 - val_acc: 0.7319\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0402 - acc: 0.7290 - val_loss: 0.0394 - val_acc: 0.7375\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0397 - acc: 0.7346 - val_loss: 0.0389 - val_acc: 0.7410\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0392 - acc: 0.7400 - val_loss: 0.0385 - val_acc: 0.7465\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0388 - acc: 0.7458 - val_loss: 0.0380 - val_acc: 0.7518\n"
     ]
    }
   ],
   "source": [
    "model3_1 = model3.fit(x_train_st, y_train, batch_size=150, epochs=100, verbose=1, validation_data=(x_test_st, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lr = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 20)                15700     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 15)                315       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                160       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 16,175\n",
      "Trainable params: 16,175\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model4 = Sequential()\n",
    "\n",
    "model4.add(Dense(20, input_dim=784))\n",
    "model4.add(Activation('sigmoid'))\n",
    "\n",
    "model4.add(Dense(15))\n",
    "model4.add(Activation('sigmoid'))\n",
    "\n",
    "model4.add(Dense(10))\n",
    "model4.add(Activation('softmax'))\n",
    "            \n",
    "model4.compile(loss='mse', optimizer=SGD(lr=0.5), metrics=['accuracy'])\n",
    "            \n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0904 - acc: 0.1627 - val_loss: 0.0896 - val_acc: 0.1700\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0894 - acc: 0.1758 - val_loss: 0.0891 - val_acc: 0.2170\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0889 - acc: 0.2246 - val_loss: 0.0886 - val_acc: 0.2273\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0883 - acc: 0.2267 - val_loss: 0.0878 - val_acc: 0.2215\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0874 - acc: 0.2203 - val_loss: 0.0867 - val_acc: 0.2153\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0859 - acc: 0.2132 - val_loss: 0.0847 - val_acc: 0.2129\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0835 - acc: 0.2155 - val_loss: 0.0819 - val_acc: 0.2231\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0804 - acc: 0.2397 - val_loss: 0.0785 - val_acc: 0.2746\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0770 - acc: 0.3288 - val_loss: 0.0750 - val_acc: 0.3789\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0736 - acc: 0.4146 - val_loss: 0.0716 - val_acc: 0.4396\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0701 - acc: 0.4539 - val_loss: 0.0679 - val_acc: 0.4697\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0663 - acc: 0.4830 - val_loss: 0.0638 - val_acc: 0.5017\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0619 - acc: 0.5282 - val_loss: 0.0593 - val_acc: 0.5742\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0573 - acc: 0.5972 - val_loss: 0.0547 - val_acc: 0.6287\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0529 - acc: 0.6406 - val_loss: 0.0503 - val_acc: 0.6654\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0486 - acc: 0.6766 - val_loss: 0.0462 - val_acc: 0.6898\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0448 - acc: 0.7021 - val_loss: 0.0426 - val_acc: 0.7336\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0415 - acc: 0.7390 - val_loss: 0.0395 - val_acc: 0.7577\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0386 - acc: 0.7692 - val_loss: 0.0367 - val_acc: 0.7874\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0360 - acc: 0.7959 - val_loss: 0.0342 - val_acc: 0.8140\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0336 - acc: 0.8177 - val_loss: 0.0318 - val_acc: 0.8325\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0313 - acc: 0.8334 - val_loss: 0.0296 - val_acc: 0.8434\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0293 - acc: 0.8456 - val_loss: 0.0277 - val_acc: 0.8529\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0275 - acc: 0.8547 - val_loss: 0.0259 - val_acc: 0.8602\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0259 - acc: 0.8620 - val_loss: 0.0245 - val_acc: 0.8647\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0245 - acc: 0.8674 - val_loss: 0.0232 - val_acc: 0.8710\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0232 - acc: 0.8722 - val_loss: 0.0221 - val_acc: 0.8745\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0222 - acc: 0.8760 - val_loss: 0.0211 - val_acc: 0.8780\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0213 - acc: 0.8798 - val_loss: 0.0203 - val_acc: 0.8825\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0205 - acc: 0.8827 - val_loss: 0.0196 - val_acc: 0.8846\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0198 - acc: 0.8851 - val_loss: 0.0190 - val_acc: 0.8865\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0192 - acc: 0.8880 - val_loss: 0.0184 - val_acc: 0.8886\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0187 - acc: 0.8904 - val_loss: 0.0179 - val_acc: 0.8909\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0182 - acc: 0.8926 - val_loss: 0.0175 - val_acc: 0.8936\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0178 - acc: 0.8949 - val_loss: 0.0171 - val_acc: 0.8947\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0173 - acc: 0.8968 - val_loss: 0.0168 - val_acc: 0.8975\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0170 - acc: 0.8984 - val_loss: 0.0164 - val_acc: 0.8990\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0166 - acc: 0.8999 - val_loss: 0.0161 - val_acc: 0.9018\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0163 - acc: 0.9011 - val_loss: 0.0158 - val_acc: 0.9015\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0160 - acc: 0.9025 - val_loss: 0.0156 - val_acc: 0.9044\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0158 - acc: 0.9041 - val_loss: 0.0153 - val_acc: 0.9053\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0155 - acc: 0.9052 - val_loss: 0.0151 - val_acc: 0.9071\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0153 - acc: 0.9066 - val_loss: 0.0149 - val_acc: 0.9085\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0151 - acc: 0.9082 - val_loss: 0.0147 - val_acc: 0.9088\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0148 - acc: 0.9094 - val_loss: 0.0145 - val_acc: 0.9095\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0146 - acc: 0.9107 - val_loss: 0.0143 - val_acc: 0.9110\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0145 - acc: 0.9113 - val_loss: 0.0141 - val_acc: 0.9116\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0143 - acc: 0.9121 - val_loss: 0.0140 - val_acc: 0.9124\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0141 - acc: 0.9133 - val_loss: 0.0139 - val_acc: 0.9132\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0139 - acc: 0.9143 - val_loss: 0.0137 - val_acc: 0.9143\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0138 - acc: 0.9151 - val_loss: 0.0136 - val_acc: 0.9150\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0136 - acc: 0.9161 - val_loss: 0.0134 - val_acc: 0.9151\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0135 - acc: 0.9168 - val_loss: 0.0133 - val_acc: 0.9158\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0133 - acc: 0.9178 - val_loss: 0.0132 - val_acc: 0.9167\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0132 - acc: 0.9187 - val_loss: 0.0131 - val_acc: 0.9174\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0131 - acc: 0.9192 - val_loss: 0.0130 - val_acc: 0.9179\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0130 - acc: 0.9198 - val_loss: 0.0129 - val_acc: 0.9184\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0128 - acc: 0.9207 - val_loss: 0.0128 - val_acc: 0.9186\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0127 - acc: 0.9214 - val_loss: 0.0127 - val_acc: 0.9186\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0126 - acc: 0.9218 - val_loss: 0.0126 - val_acc: 0.9198\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0125 - acc: 0.9227 - val_loss: 0.0125 - val_acc: 0.9204\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0124 - acc: 0.9234 - val_loss: 0.0124 - val_acc: 0.9211\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0123 - acc: 0.9238 - val_loss: 0.0123 - val_acc: 0.9217\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0122 - acc: 0.9245 - val_loss: 0.0122 - val_acc: 0.9227\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0121 - acc: 0.9250 - val_loss: 0.0121 - val_acc: 0.9229\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0120 - acc: 0.9256 - val_loss: 0.0120 - val_acc: 0.9238\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0119 - acc: 0.9265 - val_loss: 0.0119 - val_acc: 0.9244\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0118 - acc: 0.9266 - val_loss: 0.0119 - val_acc: 0.9254\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0117 - acc: 0.9274 - val_loss: 0.0118 - val_acc: 0.9263\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0116 - acc: 0.9278 - val_loss: 0.0117 - val_acc: 0.9264\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0116 - acc: 0.9286 - val_loss: 0.0117 - val_acc: 0.9260\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0115 - acc: 0.9291 - val_loss: 0.0116 - val_acc: 0.9273\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0114 - acc: 0.9293 - val_loss: 0.0115 - val_acc: 0.9275\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0113 - acc: 0.9301 - val_loss: 0.0114 - val_acc: 0.9282\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0112 - acc: 0.9303 - val_loss: 0.0114 - val_acc: 0.9289\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0112 - acc: 0.9309 - val_loss: 0.0113 - val_acc: 0.9296\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0111 - acc: 0.9311 - val_loss: 0.0112 - val_acc: 0.9297\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0110 - acc: 0.9315 - val_loss: 0.0112 - val_acc: 0.9305\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0110 - acc: 0.9319 - val_loss: 0.0111 - val_acc: 0.9304\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0109 - acc: 0.9326 - val_loss: 0.0111 - val_acc: 0.9299\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0108 - acc: 0.9331 - val_loss: 0.0110 - val_acc: 0.9312\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0108 - acc: 0.9334 - val_loss: 0.0110 - val_acc: 0.9314\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0107 - acc: 0.9338 - val_loss: 0.0109 - val_acc: 0.9320\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0106 - acc: 0.9339 - val_loss: 0.0109 - val_acc: 0.9323\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0106 - acc: 0.9344 - val_loss: 0.0108 - val_acc: 0.9318\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0105 - acc: 0.9346 - val_loss: 0.0108 - val_acc: 0.9322\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0105 - acc: 0.9349 - val_loss: 0.0107 - val_acc: 0.9326\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0104 - acc: 0.9355 - val_loss: 0.0107 - val_acc: 0.9328\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0103 - acc: 0.9356 - val_loss: 0.0106 - val_acc: 0.9332\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0103 - acc: 0.9360 - val_loss: 0.0106 - val_acc: 0.9339\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0102 - acc: 0.9365 - val_loss: 0.0105 - val_acc: 0.9339\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0102 - acc: 0.9369 - val_loss: 0.0105 - val_acc: 0.9339\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0101 - acc: 0.9370 - val_loss: 0.0104 - val_acc: 0.9346\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0101 - acc: 0.9373 - val_loss: 0.0104 - val_acc: 0.9349\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0100 - acc: 0.9377 - val_loss: 0.0103 - val_acc: 0.9352\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0100 - acc: 0.9381 - val_loss: 0.0103 - val_acc: 0.9353\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0099 - acc: 0.9382 - val_loss: 0.0103 - val_acc: 0.9354\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0099 - acc: 0.9386 - val_loss: 0.0102 - val_acc: 0.9364\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0098 - acc: 0.9385 - val_loss: 0.0102 - val_acc: 0.9365\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0098 - acc: 0.9392 - val_loss: 0.0101 - val_acc: 0.9370\n"
     ]
    }
   ],
   "source": [
    "model4_1 = model4.fit(x_train_st, y_train, batch_size=150, epochs=100, verbose=1, validation_data=(x_test_st, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lr = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 20)                15700     \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 15)                315       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                160       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 16,175\n",
      "Trainable params: 16,175\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model5 = Sequential()\n",
    "\n",
    "model5.add(Dense(20, input_dim=784))\n",
    "model5.add(Activation('sigmoid'))\n",
    "\n",
    "model5.add(Dense(15))\n",
    "model5.add(Activation('sigmoid'))\n",
    "\n",
    "model5.add(Dense(10))\n",
    "model5.add(Activation('softmax'))\n",
    "            \n",
    "model5.compile(loss='mse', optimizer=SGD(lr=1), metrics=['accuracy'])\n",
    "            \n",
    "model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0904 - acc: 0.1914 - val_loss: 0.0893 - val_acc: 0.3008\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0888 - acc: 0.3428 - val_loss: 0.0881 - val_acc: 0.4099\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0872 - acc: 0.3653 - val_loss: 0.0859 - val_acc: 0.3097\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0840 - acc: 0.3202 - val_loss: 0.0816 - val_acc: 0.3733\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0788 - acc: 0.4130 - val_loss: 0.0755 - val_acc: 0.4739\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0718 - acc: 0.5021 - val_loss: 0.0673 - val_acc: 0.5502\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0628 - acc: 0.5697 - val_loss: 0.0577 - val_acc: 0.5932\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0538 - acc: 0.6308 - val_loss: 0.0494 - val_acc: 0.6721\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0464 - acc: 0.7068 - val_loss: 0.0427 - val_acc: 0.7418\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0403 - acc: 0.7611 - val_loss: 0.0372 - val_acc: 0.7878\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0352 - acc: 0.7970 - val_loss: 0.0326 - val_acc: 0.8167\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0310 - acc: 0.8235 - val_loss: 0.0288 - val_acc: 0.8358\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0276 - acc: 0.8407 - val_loss: 0.0258 - val_acc: 0.8527\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0249 - acc: 0.8561 - val_loss: 0.0234 - val_acc: 0.8631\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0228 - acc: 0.8660 - val_loss: 0.0215 - val_acc: 0.8725\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0211 - acc: 0.8736 - val_loss: 0.0201 - val_acc: 0.8800\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0198 - acc: 0.8800 - val_loss: 0.0189 - val_acc: 0.8844\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0187 - acc: 0.8860 - val_loss: 0.0179 - val_acc: 0.8895\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0178 - acc: 0.8906 - val_loss: 0.0171 - val_acc: 0.8963\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0170 - acc: 0.8950 - val_loss: 0.0164 - val_acc: 0.8996\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0164 - acc: 0.8983 - val_loss: 0.0158 - val_acc: 0.9035\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0158 - acc: 0.9012 - val_loss: 0.0153 - val_acc: 0.9058\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0153 - acc: 0.9041 - val_loss: 0.0149 - val_acc: 0.9089\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0149 - acc: 0.9066 - val_loss: 0.0145 - val_acc: 0.9110\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0145 - acc: 0.9089 - val_loss: 0.0141 - val_acc: 0.9138\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0141 - acc: 0.9114 - val_loss: 0.0138 - val_acc: 0.9144\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0138 - acc: 0.9130 - val_loss: 0.0134 - val_acc: 0.9165\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0135 - acc: 0.9150 - val_loss: 0.0132 - val_acc: 0.9182\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0132 - acc: 0.9169 - val_loss: 0.0129 - val_acc: 0.9193\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0129 - acc: 0.9187 - val_loss: 0.0127 - val_acc: 0.9214\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0127 - acc: 0.9199 - val_loss: 0.0125 - val_acc: 0.9219\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0124 - acc: 0.9216 - val_loss: 0.0123 - val_acc: 0.9218\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0122 - acc: 0.9230 - val_loss: 0.0121 - val_acc: 0.9237\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0120 - acc: 0.9245 - val_loss: 0.0120 - val_acc: 0.9244\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0118 - acc: 0.9255 - val_loss: 0.0118 - val_acc: 0.9249\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0116 - acc: 0.9270 - val_loss: 0.0116 - val_acc: 0.9262\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0114 - acc: 0.9282 - val_loss: 0.0115 - val_acc: 0.9270\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0113 - acc: 0.9291 - val_loss: 0.0113 - val_acc: 0.9284\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0111 - acc: 0.9304 - val_loss: 0.0112 - val_acc: 0.9284\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0109 - acc: 0.9312 - val_loss: 0.0110 - val_acc: 0.9302\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0108 - acc: 0.9319 - val_loss: 0.0109 - val_acc: 0.9305\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0106 - acc: 0.9333 - val_loss: 0.0108 - val_acc: 0.9311\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0105 - acc: 0.9341 - val_loss: 0.0106 - val_acc: 0.9323\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0103 - acc: 0.9353 - val_loss: 0.0105 - val_acc: 0.9324\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0102 - acc: 0.9358 - val_loss: 0.0104 - val_acc: 0.9334\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0101 - acc: 0.9367 - val_loss: 0.0103 - val_acc: 0.9343\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0100 - acc: 0.9379 - val_loss: 0.0102 - val_acc: 0.9350\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0098 - acc: 0.9389 - val_loss: 0.0101 - val_acc: 0.9354\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0097 - acc: 0.9394 - val_loss: 0.0100 - val_acc: 0.9352\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0096 - acc: 0.9402 - val_loss: 0.0099 - val_acc: 0.9366\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0095 - acc: 0.9410 - val_loss: 0.0098 - val_acc: 0.9379\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0094 - acc: 0.9417 - val_loss: 0.0097 - val_acc: 0.9375\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0093 - acc: 0.9423 - val_loss: 0.0096 - val_acc: 0.9389\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0092 - acc: 0.9431 - val_loss: 0.0095 - val_acc: 0.9396\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0091 - acc: 0.9433 - val_loss: 0.0094 - val_acc: 0.9398\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0090 - acc: 0.9442 - val_loss: 0.0094 - val_acc: 0.9402\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0089 - acc: 0.9451 - val_loss: 0.0093 - val_acc: 0.9405\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0088 - acc: 0.9455 - val_loss: 0.0092 - val_acc: 0.9403\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0087 - acc: 0.9458 - val_loss: 0.0092 - val_acc: 0.9413\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0087 - acc: 0.9463 - val_loss: 0.0091 - val_acc: 0.9420\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0086 - acc: 0.9468 - val_loss: 0.0090 - val_acc: 0.9414\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0085 - acc: 0.9472 - val_loss: 0.0089 - val_acc: 0.9415\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0084 - acc: 0.9479 - val_loss: 0.0089 - val_acc: 0.9428\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0083 - acc: 0.9485 - val_loss: 0.0088 - val_acc: 0.9434\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0083 - acc: 0.9491 - val_loss: 0.0088 - val_acc: 0.9434\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0082 - acc: 0.9495 - val_loss: 0.0087 - val_acc: 0.9436\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0081 - acc: 0.9501 - val_loss: 0.0086 - val_acc: 0.9442\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0080 - acc: 0.9505 - val_loss: 0.0086 - val_acc: 0.9442\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0080 - acc: 0.9514 - val_loss: 0.0085 - val_acc: 0.9451\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0079 - acc: 0.9514 - val_loss: 0.0085 - val_acc: 0.9455\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0078 - acc: 0.9519 - val_loss: 0.0085 - val_acc: 0.9451\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0078 - acc: 0.9525 - val_loss: 0.0084 - val_acc: 0.9456\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0077 - acc: 0.9527 - val_loss: 0.0083 - val_acc: 0.9471\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0076 - acc: 0.9531 - val_loss: 0.0083 - val_acc: 0.9464\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0076 - acc: 0.9533 - val_loss: 0.0083 - val_acc: 0.9472\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0075 - acc: 0.9537 - val_loss: 0.0082 - val_acc: 0.9483\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0075 - acc: 0.9543 - val_loss: 0.0082 - val_acc: 0.9480\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0074 - acc: 0.9548 - val_loss: 0.0081 - val_acc: 0.9485\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0074 - acc: 0.9549 - val_loss: 0.0080 - val_acc: 0.9492\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0073 - acc: 0.9554 - val_loss: 0.0080 - val_acc: 0.9489\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0072 - acc: 0.9555 - val_loss: 0.0080 - val_acc: 0.9490\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0072 - acc: 0.9562 - val_loss: 0.0079 - val_acc: 0.9495\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0071 - acc: 0.9565 - val_loss: 0.0079 - val_acc: 0.9498\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0071 - acc: 0.9568 - val_loss: 0.0079 - val_acc: 0.9506\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0070 - acc: 0.9572 - val_loss: 0.0078 - val_acc: 0.9509\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0070 - acc: 0.9573 - val_loss: 0.0078 - val_acc: 0.9502\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0070 - acc: 0.9575 - val_loss: 0.0078 - val_acc: 0.9504\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0069 - acc: 0.9579 - val_loss: 0.0077 - val_acc: 0.9509\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 0.0068 - acc: 0.958 - 1s 19us/step - loss: 0.0069 - acc: 0.9584 - val_loss: 0.0077 - val_acc: 0.9507\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0068 - acc: 0.9582 - val_loss: 0.0077 - val_acc: 0.9511\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0068 - acc: 0.9588 - val_loss: 0.0076 - val_acc: 0.9510\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0067 - acc: 0.9590 - val_loss: 0.0076 - val_acc: 0.9511\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0067 - acc: 0.9594 - val_loss: 0.0076 - val_acc: 0.9521\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0066 - acc: 0.9597 - val_loss: 0.0075 - val_acc: 0.9530\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0066 - acc: 0.9597 - val_loss: 0.0075 - val_acc: 0.9514\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0066 - acc: 0.9602 - val_loss: 0.0075 - val_acc: 0.9533\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0065 - acc: 0.9604 - val_loss: 0.0075 - val_acc: 0.9524\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0065 - acc: 0.9611 - val_loss: 0.0074 - val_acc: 0.9521\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0065 - acc: 0.9608 - val_loss: 0.0074 - val_acc: 0.9533\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0064 - acc: 0.9613 - val_loss: 0.0074 - val_acc: 0.9519\n"
     ]
    }
   ],
   "source": [
    "model5_1 = model5.fit(x_train_st, y_train, batch_size=150, epochs=100, verbose=1, validation_data=(x_test_st, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 畫圖比較結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 畫圖 accuracy as a function of epochs\n",
    "plt.plot(model1_1.history[\"acc\"])\n",
    "plt.plot(model2_1.history[\"acc\"])\n",
    "plt.plot(model3_1.history[\"acc\"])\n",
    "plt.plot(model4_1.history[\"acc\"])\n",
    "plt.plot(model5_1.history[\"acc\"])\n",
    "\n",
    "plt.title(\"training accuracy\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend([\"lr = 0.01\", \"lr = 0.05\", \"lr = 0.1\", \"lr = 0.5\", \"lr = 1\"], loc = \"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model1_1.history[\"loss\"])\n",
    "plt.plot(model2_1.history[\"loss\"])\n",
    "plt.plot(model3_1.history[\"loss\"])\n",
    "plt.plot(model4_1.history[\"loss\"])\n",
    "plt.plot(model5_1.history[\"loss\"])\n",
    "\n",
    "plt.title(\"model validation loss\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend([\"lr = 0.01\", \"lr = 0.05\", \"lr = 0.1\", \"lr = 0.5\", \"lr = 1\"], loc = \"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 心得"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 雖然 lr 越小能夠使結果較準確，但由結果可知 lr 的大小會影響正確率到達最大值的時間\n",
    "* 在 epochs = 100 的情況可知，即使被認為應該最準確的 lr = 0.01 其正確率是所有中最低的\n",
    "* 但為了確認 lr = 0.01 能夠達最大值，我們繼續加大其執行的 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 再繼續畫 lr = 0.01 的圖"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 再多加 2000 個 epochs, 看是否能達飽和值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0893 - acc: 0.2230 - val_loss: 0.0893 - val_acc: 0.2295\n",
      "Epoch 2/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0893 - acc: 0.2262 - val_loss: 0.0893 - val_acc: 0.2313\n",
      "Epoch 3/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0893 - acc: 0.2275 - val_loss: 0.0893 - val_acc: 0.2342\n",
      "Epoch 4/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0893 - acc: 0.2300 - val_loss: 0.0892 - val_acc: 0.2370\n",
      "Epoch 5/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0893 - acc: 0.2317 - val_loss: 0.0892 - val_acc: 0.2396\n",
      "Epoch 6/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0893 - acc: 0.2345 - val_loss: 0.0892 - val_acc: 0.2411\n",
      "Epoch 7/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0892 - acc: 0.2368 - val_loss: 0.0892 - val_acc: 0.2432\n",
      "Epoch 8/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0892 - acc: 0.2384 - val_loss: 0.0892 - val_acc: 0.2462\n",
      "Epoch 9/2000\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0892 - acc: 0.2411 - val_loss: 0.0892 - val_acc: 0.2487\n",
      "Epoch 10/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0892 - acc: 0.2434 - val_loss: 0.0892 - val_acc: 0.2503\n",
      "Epoch 11/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0892 - acc: 0.2466 - val_loss: 0.0892 - val_acc: 0.2521\n",
      "Epoch 12/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0892 - acc: 0.2486 - val_loss: 0.0892 - val_acc: 0.2548\n",
      "Epoch 13/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0892 - acc: 0.2490 - val_loss: 0.0892 - val_acc: 0.2568\n",
      "Epoch 14/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0892 - acc: 0.2520 - val_loss: 0.0892 - val_acc: 0.2588\n",
      "Epoch 15/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0892 - acc: 0.2550 - val_loss: 0.0891 - val_acc: 0.2613\n",
      "Epoch 16/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0892 - acc: 0.2575 - val_loss: 0.0891 - val_acc: 0.2637\n",
      "Epoch 17/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0892 - acc: 0.2585 - val_loss: 0.0891 - val_acc: 0.2662\n",
      "Epoch 18/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0892 - acc: 0.2612 - val_loss: 0.0891 - val_acc: 0.2687\n",
      "Epoch 19/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0891 - acc: 0.2646 - val_loss: 0.0891 - val_acc: 0.2711\n",
      "Epoch 20/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0891 - acc: 0.2664 - val_loss: 0.0891 - val_acc: 0.2727\n",
      "Epoch 21/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0891 - acc: 0.2666 - val_loss: 0.0891 - val_acc: 0.2750\n",
      "Epoch 22/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0891 - acc: 0.2695 - val_loss: 0.0891 - val_acc: 0.2768\n",
      "Epoch 23/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0891 - acc: 0.2730 - val_loss: 0.0891 - val_acc: 0.2790\n",
      "Epoch 24/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0891 - acc: 0.2744 - val_loss: 0.0891 - val_acc: 0.2817\n",
      "Epoch 25/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0891 - acc: 0.2766 - val_loss: 0.0891 - val_acc: 0.2839\n",
      "Epoch 26/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0891 - acc: 0.2780 - val_loss: 0.0890 - val_acc: 0.2856\n",
      "Epoch 27/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0891 - acc: 0.2807 - val_loss: 0.0890 - val_acc: 0.2879\n",
      "Epoch 28/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0891 - acc: 0.2816 - val_loss: 0.0890 - val_acc: 0.2890\n",
      "Epoch 29/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0891 - acc: 0.2847 - val_loss: 0.0890 - val_acc: 0.2906\n",
      "Epoch 30/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0890 - acc: 0.2880 - val_loss: 0.0890 - val_acc: 0.2925\n",
      "Epoch 31/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0890 - acc: 0.2888 - val_loss: 0.0890 - val_acc: 0.2948\n",
      "Epoch 32/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0890 - acc: 0.2915 - val_loss: 0.0890 - val_acc: 0.2971\n",
      "Epoch 33/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0890 - acc: 0.2931 - val_loss: 0.0890 - val_acc: 0.2991\n",
      "Epoch 34/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0890 - acc: 0.2950 - val_loss: 0.0890 - val_acc: 0.3002\n",
      "Epoch 35/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0890 - acc: 0.2977 - val_loss: 0.0890 - val_acc: 0.3025\n",
      "Epoch 36/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0890 - acc: 0.2989 - val_loss: 0.0890 - val_acc: 0.3048\n",
      "Epoch 37/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0890 - acc: 0.3014 - val_loss: 0.0889 - val_acc: 0.3068\n",
      "Epoch 38/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0890 - acc: 0.3022 - val_loss: 0.0889 - val_acc: 0.3085\n",
      "Epoch 39/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0890 - acc: 0.3041 - val_loss: 0.0889 - val_acc: 0.3112\n",
      "Epoch 40/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0889 - acc: 0.3064 - val_loss: 0.0889 - val_acc: 0.3126\n",
      "Epoch 41/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0889 - acc: 0.3083 - val_loss: 0.0889 - val_acc: 0.3144\n",
      "Epoch 42/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0889 - acc: 0.3122 - val_loss: 0.0889 - val_acc: 0.3172\n",
      "Epoch 43/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0889 - acc: 0.3126 - val_loss: 0.0889 - val_acc: 0.3193\n",
      "Epoch 44/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0889 - acc: 0.3152 - val_loss: 0.0889 - val_acc: 0.3215\n",
      "Epoch 45/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0889 - acc: 0.3162 - val_loss: 0.0889 - val_acc: 0.3236\n",
      "Epoch 46/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0889 - acc: 0.3183 - val_loss: 0.0888 - val_acc: 0.3254\n",
      "Epoch 47/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0889 - acc: 0.3192 - val_loss: 0.0888 - val_acc: 0.3281\n",
      "Epoch 48/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0889 - acc: 0.3209 - val_loss: 0.0888 - val_acc: 0.3308\n",
      "Epoch 49/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0889 - acc: 0.3245 - val_loss: 0.0888 - val_acc: 0.3328\n",
      "Epoch 50/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0888 - acc: 0.3257 - val_loss: 0.0888 - val_acc: 0.3351\n",
      "Epoch 51/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0888 - acc: 0.3286 - val_loss: 0.0888 - val_acc: 0.3378\n",
      "Epoch 52/2000\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 0.0888 - acc: 0.329 - 1s 19us/step - loss: 0.0888 - acc: 0.3296 - val_loss: 0.0888 - val_acc: 0.3391\n",
      "Epoch 53/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0888 - acc: 0.3321 - val_loss: 0.0888 - val_acc: 0.3407\n",
      "Epoch 54/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0888 - acc: 0.3321 - val_loss: 0.0888 - val_acc: 0.3426\n",
      "Epoch 55/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0888 - acc: 0.3345 - val_loss: 0.0888 - val_acc: 0.3446\n",
      "Epoch 56/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0888 - acc: 0.3373 - val_loss: 0.0887 - val_acc: 0.3462\n",
      "Epoch 57/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0888 - acc: 0.3386 - val_loss: 0.0887 - val_acc: 0.3480\n",
      "Epoch 58/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0888 - acc: 0.3400 - val_loss: 0.0887 - val_acc: 0.3506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0887 - acc: 0.3411 - val_loss: 0.0887 - val_acc: 0.3525\n",
      "Epoch 60/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0887 - acc: 0.3441 - val_loss: 0.0887 - val_acc: 0.3537\n",
      "Epoch 61/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0887 - acc: 0.3439 - val_loss: 0.0887 - val_acc: 0.3565\n",
      "Epoch 62/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0887 - acc: 0.3472 - val_loss: 0.0887 - val_acc: 0.3583\n",
      "Epoch 63/2000\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0887 - acc: 0.3481 - val_loss: 0.0887 - val_acc: 0.3604\n",
      "Epoch 64/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0887 - acc: 0.3509 - val_loss: 0.0887 - val_acc: 0.3626\n",
      "Epoch 65/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0887 - acc: 0.3525 - val_loss: 0.0886 - val_acc: 0.3644\n",
      "Epoch 66/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0887 - acc: 0.3548 - val_loss: 0.0886 - val_acc: 0.3664\n",
      "Epoch 67/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0887 - acc: 0.3557 - val_loss: 0.0886 - val_acc: 0.3690\n",
      "Epoch 68/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0886 - acc: 0.3576 - val_loss: 0.0886 - val_acc: 0.3714\n",
      "Epoch 69/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0886 - acc: 0.3585 - val_loss: 0.0886 - val_acc: 0.3742\n",
      "Epoch 70/2000\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0886 - acc: 0.3611 - val_loss: 0.0886 - val_acc: 0.3754\n",
      "Epoch 71/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0886 - acc: 0.3633 - val_loss: 0.0886 - val_acc: 0.3777\n",
      "Epoch 72/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0886 - acc: 0.3654 - val_loss: 0.0886 - val_acc: 0.3795\n",
      "Epoch 73/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0886 - acc: 0.3670 - val_loss: 0.0885 - val_acc: 0.3809\n",
      "Epoch 74/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0886 - acc: 0.3694 - val_loss: 0.0885 - val_acc: 0.3829\n",
      "Epoch 75/2000\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0886 - acc: 0.3706 - val_loss: 0.0885 - val_acc: 0.3852\n",
      "Epoch 76/2000\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0886 - acc: 0.3729 - val_loss: 0.0885 - val_acc: 0.3879\n",
      "Epoch 77/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0885 - acc: 0.3745 - val_loss: 0.0885 - val_acc: 0.3898\n",
      "Epoch 78/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0885 - acc: 0.3766 - val_loss: 0.0885 - val_acc: 0.3917\n",
      "Epoch 79/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0885 - acc: 0.3781 - val_loss: 0.0885 - val_acc: 0.3938\n",
      "Epoch 80/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0885 - acc: 0.3794 - val_loss: 0.0885 - val_acc: 0.3961\n",
      "Epoch 81/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0885 - acc: 0.3820 - val_loss: 0.0884 - val_acc: 0.3985\n",
      "Epoch 82/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0885 - acc: 0.3840 - val_loss: 0.0884 - val_acc: 0.4009\n",
      "Epoch 83/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0885 - acc: 0.3853 - val_loss: 0.0884 - val_acc: 0.4026\n",
      "Epoch 84/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0885 - acc: 0.3875 - val_loss: 0.0884 - val_acc: 0.4040\n",
      "Epoch 85/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0884 - acc: 0.3895 - val_loss: 0.0884 - val_acc: 0.4053\n",
      "Epoch 86/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0884 - acc: 0.3917 - val_loss: 0.0884 - val_acc: 0.4075\n",
      "Epoch 87/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0884 - acc: 0.3922 - val_loss: 0.0884 - val_acc: 0.4097\n",
      "Epoch 88/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0884 - acc: 0.3946 - val_loss: 0.0884 - val_acc: 0.4108\n",
      "Epoch 89/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0884 - acc: 0.3964 - val_loss: 0.0883 - val_acc: 0.4122\n",
      "Epoch 90/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0884 - acc: 0.3992 - val_loss: 0.0883 - val_acc: 0.4145\n",
      "Epoch 91/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0884 - acc: 0.4001 - val_loss: 0.0883 - val_acc: 0.4160\n",
      "Epoch 92/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0883 - acc: 0.4015 - val_loss: 0.0883 - val_acc: 0.4176\n",
      "Epoch 93/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0883 - acc: 0.4029 - val_loss: 0.0883 - val_acc: 0.4191\n",
      "Epoch 94/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0883 - acc: 0.4055 - val_loss: 0.0883 - val_acc: 0.4206\n",
      "Epoch 95/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0883 - acc: 0.4082 - val_loss: 0.0883 - val_acc: 0.4217\n",
      "Epoch 96/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0883 - acc: 0.4084 - val_loss: 0.0882 - val_acc: 0.4228\n",
      "Epoch 97/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0883 - acc: 0.4100 - val_loss: 0.0882 - val_acc: 0.4254\n",
      "Epoch 98/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0883 - acc: 0.4119 - val_loss: 0.0882 - val_acc: 0.4269\n",
      "Epoch 99/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0883 - acc: 0.4128 - val_loss: 0.0882 - val_acc: 0.4284\n",
      "Epoch 100/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0882 - acc: 0.4144 - val_loss: 0.0882 - val_acc: 0.4297\n",
      "Epoch 101/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0882 - acc: 0.4170 - val_loss: 0.0882 - val_acc: 0.4320\n",
      "Epoch 102/2000\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0882 - acc: 0.4168 - val_loss: 0.0882 - val_acc: 0.4335\n",
      "Epoch 103/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0882 - acc: 0.4192 - val_loss: 0.0881 - val_acc: 0.4348\n",
      "Epoch 104/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0882 - acc: 0.4207 - val_loss: 0.0881 - val_acc: 0.4374\n",
      "Epoch 105/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0882 - acc: 0.4213 - val_loss: 0.0881 - val_acc: 0.4380\n",
      "Epoch 106/2000\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 0.0882 - acc: 0.422 - 1s 19us/step - loss: 0.0882 - acc: 0.4223 - val_loss: 0.0881 - val_acc: 0.4398\n",
      "Epoch 107/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0881 - acc: 0.4247 - val_loss: 0.0881 - val_acc: 0.4403\n",
      "Epoch 108/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0881 - acc: 0.4254 - val_loss: 0.0881 - val_acc: 0.4418\n",
      "Epoch 109/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0881 - acc: 0.4269 - val_loss: 0.0881 - val_acc: 0.4427\n",
      "Epoch 110/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0881 - acc: 0.4283 - val_loss: 0.0880 - val_acc: 0.4438\n",
      "Epoch 111/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0881 - acc: 0.4290 - val_loss: 0.0880 - val_acc: 0.4451\n",
      "Epoch 112/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0881 - acc: 0.4304 - val_loss: 0.0880 - val_acc: 0.4461\n",
      "Epoch 113/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0880 - acc: 0.4309 - val_loss: 0.0880 - val_acc: 0.4467\n",
      "Epoch 114/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0880 - acc: 0.4328 - val_loss: 0.0880 - val_acc: 0.4483\n",
      "Epoch 115/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0880 - acc: 0.4329 - val_loss: 0.0880 - val_acc: 0.4493\n",
      "Epoch 116/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0880 - acc: 0.4345 - val_loss: 0.0879 - val_acc: 0.4507\n",
      "Epoch 117/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0880 - acc: 0.4350 - val_loss: 0.0879 - val_acc: 0.4517\n",
      "Epoch 118/2000\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0880 - acc: 0.4366 - val_loss: 0.0879 - val_acc: 0.4528\n",
      "Epoch 119/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0880 - acc: 0.4378 - val_loss: 0.0879 - val_acc: 0.4534\n",
      "Epoch 120/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0879 - acc: 0.4385 - val_loss: 0.0879 - val_acc: 0.4541\n",
      "Epoch 121/2000\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0879 - acc: 0.4400 - val_loss: 0.0879 - val_acc: 0.4542\n",
      "Epoch 122/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0879 - acc: 0.4406 - val_loss: 0.0878 - val_acc: 0.4551\n",
      "Epoch 123/2000\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0879 - acc: 0.4420 - val_loss: 0.0878 - val_acc: 0.4552\n",
      "Epoch 124/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0879 - acc: 0.4430 - val_loss: 0.0878 - val_acc: 0.4554\n",
      "Epoch 125/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0879 - acc: 0.4435 - val_loss: 0.0878 - val_acc: 0.4562\n",
      "Epoch 126/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0878 - acc: 0.4447 - val_loss: 0.0878 - val_acc: 0.4570\n",
      "Epoch 127/2000\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0878 - acc: 0.4454 - val_loss: 0.0878 - val_acc: 0.4571\n",
      "Epoch 128/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0878 - acc: 0.4458 - val_loss: 0.0877 - val_acc: 0.4580\n",
      "Epoch 129/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0878 - acc: 0.4475 - val_loss: 0.0877 - val_acc: 0.4589\n",
      "Epoch 130/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0878 - acc: 0.4481 - val_loss: 0.0877 - val_acc: 0.4596\n",
      "Epoch 131/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0878 - acc: 0.4488 - val_loss: 0.0877 - val_acc: 0.4603\n",
      "Epoch 132/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0877 - acc: 0.4495 - val_loss: 0.0877 - val_acc: 0.4610\n",
      "Epoch 133/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0877 - acc: 0.4498 - val_loss: 0.0877 - val_acc: 0.4616\n",
      "Epoch 134/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0877 - acc: 0.4509 - val_loss: 0.0876 - val_acc: 0.4618\n",
      "Epoch 135/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0877 - acc: 0.4509 - val_loss: 0.0876 - val_acc: 0.4623\n",
      "Epoch 136/2000\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 0.0877 - acc: 0.451 - 1s 19us/step - loss: 0.0877 - acc: 0.4523 - val_loss: 0.0876 - val_acc: 0.4636\n",
      "Epoch 137/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0876 - acc: 0.4525 - val_loss: 0.0876 - val_acc: 0.4645\n",
      "Epoch 138/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0876 - acc: 0.4530 - val_loss: 0.0876 - val_acc: 0.4651\n",
      "Epoch 139/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0876 - acc: 0.4542 - val_loss: 0.0875 - val_acc: 0.4656\n",
      "Epoch 140/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0876 - acc: 0.4543 - val_loss: 0.0875 - val_acc: 0.4662\n",
      "Epoch 141/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0876 - acc: 0.4546 - val_loss: 0.0875 - val_acc: 0.4671\n",
      "Epoch 142/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0876 - acc: 0.4556 - val_loss: 0.0875 - val_acc: 0.4677\n",
      "Epoch 143/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0875 - acc: 0.4564 - val_loss: 0.0875 - val_acc: 0.4687\n",
      "Epoch 144/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0875 - acc: 0.4571 - val_loss: 0.0874 - val_acc: 0.4692\n",
      "Epoch 145/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0875 - acc: 0.4570 - val_loss: 0.0874 - val_acc: 0.4699\n",
      "Epoch 146/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0875 - acc: 0.4580 - val_loss: 0.0874 - val_acc: 0.4700\n",
      "Epoch 147/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0875 - acc: 0.4586 - val_loss: 0.0874 - val_acc: 0.4702\n",
      "Epoch 148/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0874 - acc: 0.4590 - val_loss: 0.0874 - val_acc: 0.4704\n",
      "Epoch 149/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0874 - acc: 0.4600 - val_loss: 0.0873 - val_acc: 0.4707\n",
      "Epoch 150/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0874 - acc: 0.4608 - val_loss: 0.0873 - val_acc: 0.4710\n",
      "Epoch 151/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0874 - acc: 0.4611 - val_loss: 0.0873 - val_acc: 0.4711\n",
      "Epoch 152/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0874 - acc: 0.4615 - val_loss: 0.0873 - val_acc: 0.4721\n",
      "Epoch 153/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0873 - acc: 0.4615 - val_loss: 0.0873 - val_acc: 0.4722\n",
      "Epoch 154/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0873 - acc: 0.4624 - val_loss: 0.0872 - val_acc: 0.4726\n",
      "Epoch 155/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0873 - acc: 0.4629 - val_loss: 0.0872 - val_acc: 0.4733\n",
      "Epoch 156/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0873 - acc: 0.4630 - val_loss: 0.0872 - val_acc: 0.4731\n",
      "Epoch 157/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0872 - acc: 0.4635 - val_loss: 0.0872 - val_acc: 0.4736\n",
      "Epoch 158/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0872 - acc: 0.4639 - val_loss: 0.0872 - val_acc: 0.4736\n",
      "Epoch 159/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0872 - acc: 0.4647 - val_loss: 0.0871 - val_acc: 0.4740\n",
      "Epoch 160/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0872 - acc: 0.4648 - val_loss: 0.0871 - val_acc: 0.4742\n",
      "Epoch 161/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0872 - acc: 0.4655 - val_loss: 0.0871 - val_acc: 0.4747\n",
      "Epoch 162/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0871 - acc: 0.4658 - val_loss: 0.0871 - val_acc: 0.4749\n",
      "Epoch 163/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0871 - acc: 0.4662 - val_loss: 0.0870 - val_acc: 0.4752\n",
      "Epoch 164/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0871 - acc: 0.4663 - val_loss: 0.0870 - val_acc: 0.4754\n",
      "Epoch 165/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0871 - acc: 0.4665 - val_loss: 0.0870 - val_acc: 0.4758\n",
      "Epoch 166/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0871 - acc: 0.4668 - val_loss: 0.0870 - val_acc: 0.4766\n",
      "Epoch 167/2000\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0870 - acc: 0.4676 - val_loss: 0.0870 - val_acc: 0.4770\n",
      "Epoch 168/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0870 - acc: 0.4679 - val_loss: 0.0869 - val_acc: 0.4774\n",
      "Epoch 169/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0870 - acc: 0.4686 - val_loss: 0.0869 - val_acc: 0.4773\n",
      "Epoch 170/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0870 - acc: 0.4686 - val_loss: 0.0869 - val_acc: 0.4776\n",
      "Epoch 171/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0869 - acc: 0.4691 - val_loss: 0.0869 - val_acc: 0.4777\n",
      "Epoch 172/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0869 - acc: 0.4695 - val_loss: 0.0868 - val_acc: 0.4778\n",
      "Epoch 173/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0869 - acc: 0.4696 - val_loss: 0.0868 - val_acc: 0.4784\n",
      "Epoch 174/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0869 - acc: 0.4700 - val_loss: 0.0868 - val_acc: 0.4789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0868 - acc: 0.4702 - val_loss: 0.0868 - val_acc: 0.4790\n",
      "Epoch 176/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0868 - acc: 0.4704 - val_loss: 0.0867 - val_acc: 0.4793\n",
      "Epoch 177/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0868 - acc: 0.4709 - val_loss: 0.0867 - val_acc: 0.4800\n",
      "Epoch 178/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0868 - acc: 0.4709 - val_loss: 0.0867 - val_acc: 0.4800\n",
      "Epoch 179/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0867 - acc: 0.4710 - val_loss: 0.0867 - val_acc: 0.4800\n",
      "Epoch 180/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0867 - acc: 0.4717 - val_loss: 0.0866 - val_acc: 0.4799\n",
      "Epoch 181/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0867 - acc: 0.4717 - val_loss: 0.0866 - val_acc: 0.4800\n",
      "Epoch 182/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0867 - acc: 0.4720 - val_loss: 0.0866 - val_acc: 0.4799\n",
      "Epoch 183/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0866 - acc: 0.4725 - val_loss: 0.0866 - val_acc: 0.4801\n",
      "Epoch 184/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0866 - acc: 0.4724 - val_loss: 0.0865 - val_acc: 0.4805\n",
      "Epoch 185/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0866 - acc: 0.4727 - val_loss: 0.0865 - val_acc: 0.4808\n",
      "Epoch 186/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0866 - acc: 0.4732 - val_loss: 0.0865 - val_acc: 0.4808\n",
      "Epoch 187/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0865 - acc: 0.4732 - val_loss: 0.0864 - val_acc: 0.4810\n",
      "Epoch 188/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0865 - acc: 0.4733 - val_loss: 0.0864 - val_acc: 0.4812\n",
      "Epoch 189/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0865 - acc: 0.4736 - val_loss: 0.0864 - val_acc: 0.4811\n",
      "Epoch 190/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0864 - acc: 0.4735 - val_loss: 0.0864 - val_acc: 0.4812\n",
      "Epoch 191/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0864 - acc: 0.4743 - val_loss: 0.0863 - val_acc: 0.4814\n",
      "Epoch 192/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0864 - acc: 0.4744 - val_loss: 0.0863 - val_acc: 0.4814\n",
      "Epoch 193/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0864 - acc: 0.4745 - val_loss: 0.0863 - val_acc: 0.4813\n",
      "Epoch 194/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0863 - acc: 0.4746 - val_loss: 0.0863 - val_acc: 0.4815\n",
      "Epoch 195/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0863 - acc: 0.4752 - val_loss: 0.0862 - val_acc: 0.4814\n",
      "Epoch 196/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0863 - acc: 0.4753 - val_loss: 0.0862 - val_acc: 0.4814\n",
      "Epoch 197/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0862 - acc: 0.4754 - val_loss: 0.0862 - val_acc: 0.4817\n",
      "Epoch 198/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0862 - acc: 0.4754 - val_loss: 0.0861 - val_acc: 0.4819\n",
      "Epoch 199/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0862 - acc: 0.4756 - val_loss: 0.0861 - val_acc: 0.4821\n",
      "Epoch 200/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0862 - acc: 0.4761 - val_loss: 0.0861 - val_acc: 0.4817\n",
      "Epoch 201/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0861 - acc: 0.4764 - val_loss: 0.0860 - val_acc: 0.4819\n",
      "Epoch 202/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0861 - acc: 0.4764 - val_loss: 0.0860 - val_acc: 0.4823\n",
      "Epoch 203/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0861 - acc: 0.4765 - val_loss: 0.0860 - val_acc: 0.4824\n",
      "Epoch 204/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0860 - acc: 0.4765 - val_loss: 0.0860 - val_acc: 0.4826\n",
      "Epoch 205/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0860 - acc: 0.4770 - val_loss: 0.0859 - val_acc: 0.4823\n",
      "Epoch 206/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0860 - acc: 0.4773 - val_loss: 0.0859 - val_acc: 0.4822\n",
      "Epoch 207/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0859 - acc: 0.4775 - val_loss: 0.0859 - val_acc: 0.4823\n",
      "Epoch 208/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0859 - acc: 0.4774 - val_loss: 0.0858 - val_acc: 0.4823\n",
      "Epoch 209/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0859 - acc: 0.4772 - val_loss: 0.0858 - val_acc: 0.4824\n",
      "Epoch 210/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0858 - acc: 0.4775 - val_loss: 0.0858 - val_acc: 0.4827\n",
      "Epoch 211/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0858 - acc: 0.4775 - val_loss: 0.0857 - val_acc: 0.4826\n",
      "Epoch 212/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0858 - acc: 0.4778 - val_loss: 0.0857 - val_acc: 0.4824\n",
      "Epoch 213/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0858 - acc: 0.4778 - val_loss: 0.0857 - val_acc: 0.4829\n",
      "Epoch 214/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0857 - acc: 0.4775 - val_loss: 0.0856 - val_acc: 0.4829\n",
      "Epoch 215/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0857 - acc: 0.4776 - val_loss: 0.0856 - val_acc: 0.4836\n",
      "Epoch 216/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0856 - acc: 0.4776 - val_loss: 0.0856 - val_acc: 0.4835\n",
      "Epoch 217/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0856 - acc: 0.4782 - val_loss: 0.0855 - val_acc: 0.4841\n",
      "Epoch 218/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0856 - acc: 0.4783 - val_loss: 0.0855 - val_acc: 0.4841\n",
      "Epoch 219/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0855 - acc: 0.4781 - val_loss: 0.0855 - val_acc: 0.4846\n",
      "Epoch 220/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0855 - acc: 0.4787 - val_loss: 0.0854 - val_acc: 0.4846\n",
      "Epoch 221/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0855 - acc: 0.4788 - val_loss: 0.0854 - val_acc: 0.4851\n",
      "Epoch 222/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0854 - acc: 0.4789 - val_loss: 0.0853 - val_acc: 0.4857\n",
      "Epoch 223/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0854 - acc: 0.4787 - val_loss: 0.0853 - val_acc: 0.4860\n",
      "Epoch 224/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0854 - acc: 0.4793 - val_loss: 0.0853 - val_acc: 0.4859\n",
      "Epoch 225/2000\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0853 - acc: 0.4791 - val_loss: 0.0852 - val_acc: 0.4857\n",
      "Epoch 226/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0853 - acc: 0.4792 - val_loss: 0.0852 - val_acc: 0.4856\n",
      "Epoch 227/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0853 - acc: 0.4792 - val_loss: 0.0852 - val_acc: 0.4859\n",
      "Epoch 228/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0852 - acc: 0.4791 - val_loss: 0.0851 - val_acc: 0.4864\n",
      "Epoch 229/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0852 - acc: 0.4794 - val_loss: 0.0851 - val_acc: 0.4863\n",
      "Epoch 230/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0851 - acc: 0.4794 - val_loss: 0.0850 - val_acc: 0.4865\n",
      "Epoch 231/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0851 - acc: 0.4794 - val_loss: 0.0850 - val_acc: 0.4865\n",
      "Epoch 232/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0851 - acc: 0.4795 - val_loss: 0.0850 - val_acc: 0.4864\n",
      "Epoch 233/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0850 - acc: 0.4795 - val_loss: 0.0849 - val_acc: 0.4862\n",
      "Epoch 234/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0850 - acc: 0.4794 - val_loss: 0.0849 - val_acc: 0.4861\n",
      "Epoch 235/2000\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 0.0849 - acc: 0.479 - 1s 19us/step - loss: 0.0849 - acc: 0.4798 - val_loss: 0.0848 - val_acc: 0.4860\n",
      "Epoch 236/2000\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0849 - acc: 0.4798 - val_loss: 0.0848 - val_acc: 0.4858\n",
      "Epoch 237/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0849 - acc: 0.4796 - val_loss: 0.0848 - val_acc: 0.4854\n",
      "Epoch 238/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0848 - acc: 0.4795 - val_loss: 0.0847 - val_acc: 0.4851\n",
      "Epoch 239/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0848 - acc: 0.4796 - val_loss: 0.0847 - val_acc: 0.4844\n",
      "Epoch 240/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0847 - acc: 0.4796 - val_loss: 0.0846 - val_acc: 0.4845\n",
      "Epoch 241/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0847 - acc: 0.4792 - val_loss: 0.0846 - val_acc: 0.4842\n",
      "Epoch 242/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0847 - acc: 0.4790 - val_loss: 0.0846 - val_acc: 0.4841\n",
      "Epoch 243/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0846 - acc: 0.4795 - val_loss: 0.0845 - val_acc: 0.4839\n",
      "Epoch 244/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0846 - acc: 0.4791 - val_loss: 0.0845 - val_acc: 0.4835\n",
      "Epoch 245/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0845 - acc: 0.4789 - val_loss: 0.0844 - val_acc: 0.4833\n",
      "Epoch 246/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0845 - acc: 0.4784 - val_loss: 0.0844 - val_acc: 0.4830\n",
      "Epoch 247/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0844 - acc: 0.4783 - val_loss: 0.0843 - val_acc: 0.4824\n",
      "Epoch 248/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0844 - acc: 0.4781 - val_loss: 0.0843 - val_acc: 0.4821\n",
      "Epoch 249/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0844 - acc: 0.4778 - val_loss: 0.0842 - val_acc: 0.4821\n",
      "Epoch 250/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0843 - acc: 0.4773 - val_loss: 0.0842 - val_acc: 0.4822\n",
      "Epoch 251/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0843 - acc: 0.4774 - val_loss: 0.0842 - val_acc: 0.4820\n",
      "Epoch 252/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0842 - acc: 0.4775 - val_loss: 0.0841 - val_acc: 0.4816\n",
      "Epoch 253/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0842 - acc: 0.4770 - val_loss: 0.0841 - val_acc: 0.4810\n",
      "Epoch 254/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0841 - acc: 0.4767 - val_loss: 0.0840 - val_acc: 0.4801\n",
      "Epoch 255/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0841 - acc: 0.4758 - val_loss: 0.0840 - val_acc: 0.4799\n",
      "Epoch 256/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0840 - acc: 0.4754 - val_loss: 0.0839 - val_acc: 0.4797\n",
      "Epoch 257/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0840 - acc: 0.4748 - val_loss: 0.0839 - val_acc: 0.4794\n",
      "Epoch 258/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0839 - acc: 0.4744 - val_loss: 0.0838 - val_acc: 0.4791\n",
      "Epoch 259/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0839 - acc: 0.4743 - val_loss: 0.0838 - val_acc: 0.4782\n",
      "Epoch 260/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0838 - acc: 0.4735 - val_loss: 0.0837 - val_acc: 0.4783\n",
      "Epoch 261/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0838 - acc: 0.4737 - val_loss: 0.0837 - val_acc: 0.4774\n",
      "Epoch 262/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0837 - acc: 0.4729 - val_loss: 0.0836 - val_acc: 0.4773\n",
      "Epoch 263/2000\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0837 - acc: 0.4726 - val_loss: 0.0836 - val_acc: 0.4768\n",
      "Epoch 264/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0836 - acc: 0.4717 - val_loss: 0.0835 - val_acc: 0.4759\n",
      "Epoch 265/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0836 - acc: 0.4720 - val_loss: 0.0835 - val_acc: 0.4753\n",
      "Epoch 266/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0835 - acc: 0.4716 - val_loss: 0.0834 - val_acc: 0.4749\n",
      "Epoch 267/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0835 - acc: 0.4714 - val_loss: 0.0834 - val_acc: 0.4745\n",
      "Epoch 268/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0834 - acc: 0.4707 - val_loss: 0.0833 - val_acc: 0.4743\n",
      "Epoch 269/2000\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0834 - acc: 0.4703 - val_loss: 0.0833 - val_acc: 0.4737\n",
      "Epoch 270/2000\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0833 - acc: 0.4697 - val_loss: 0.0832 - val_acc: 0.4725\n",
      "Epoch 271/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0833 - acc: 0.4689 - val_loss: 0.0832 - val_acc: 0.4715\n",
      "Epoch 272/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0832 - acc: 0.4690 - val_loss: 0.0831 - val_acc: 0.4703\n",
      "Epoch 273/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0832 - acc: 0.4677 - val_loss: 0.0830 - val_acc: 0.4701\n",
      "Epoch 274/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0831 - acc: 0.4669 - val_loss: 0.0830 - val_acc: 0.4693\n",
      "Epoch 275/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0831 - acc: 0.4664 - val_loss: 0.0829 - val_acc: 0.4685\n",
      "Epoch 276/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0830 - acc: 0.4650 - val_loss: 0.0829 - val_acc: 0.4682\n",
      "Epoch 277/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0829 - acc: 0.4655 - val_loss: 0.0828 - val_acc: 0.4677\n",
      "Epoch 278/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0829 - acc: 0.4644 - val_loss: 0.0828 - val_acc: 0.4665\n",
      "Epoch 279/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0828 - acc: 0.4634 - val_loss: 0.0827 - val_acc: 0.4661\n",
      "Epoch 280/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0828 - acc: 0.4626 - val_loss: 0.0827 - val_acc: 0.4654\n",
      "Epoch 281/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0827 - acc: 0.4618 - val_loss: 0.0826 - val_acc: 0.4644\n",
      "Epoch 282/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0827 - acc: 0.4611 - val_loss: 0.0825 - val_acc: 0.4634\n",
      "Epoch 283/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0826 - acc: 0.4604 - val_loss: 0.0825 - val_acc: 0.4627\n",
      "Epoch 284/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0825 - acc: 0.4593 - val_loss: 0.0824 - val_acc: 0.4620\n",
      "Epoch 285/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0825 - acc: 0.4593 - val_loss: 0.0824 - val_acc: 0.4609\n",
      "Epoch 286/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0824 - acc: 0.4586 - val_loss: 0.0823 - val_acc: 0.4605\n",
      "Epoch 287/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0824 - acc: 0.4575 - val_loss: 0.0822 - val_acc: 0.4604\n",
      "Epoch 288/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0823 - acc: 0.4566 - val_loss: 0.0822 - val_acc: 0.4596\n",
      "Epoch 289/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0822 - acc: 0.4562 - val_loss: 0.0821 - val_acc: 0.4586\n",
      "Epoch 290/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0822 - acc: 0.4551 - val_loss: 0.0821 - val_acc: 0.4572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 291/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0821 - acc: 0.4541 - val_loss: 0.0820 - val_acc: 0.4560\n",
      "Epoch 292/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0821 - acc: 0.4534 - val_loss: 0.0819 - val_acc: 0.4552\n",
      "Epoch 293/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0820 - acc: 0.4518 - val_loss: 0.0819 - val_acc: 0.4538\n",
      "Epoch 294/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0819 - acc: 0.4510 - val_loss: 0.0818 - val_acc: 0.4530\n",
      "Epoch 295/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0819 - acc: 0.4504 - val_loss: 0.0817 - val_acc: 0.4522\n",
      "Epoch 296/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0818 - acc: 0.4490 - val_loss: 0.0817 - val_acc: 0.4508\n",
      "Epoch 297/2000\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0817 - acc: 0.4481 - val_loss: 0.0816 - val_acc: 0.4501\n",
      "Epoch 298/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0817 - acc: 0.4474 - val_loss: 0.0815 - val_acc: 0.4495\n",
      "Epoch 299/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0816 - acc: 0.4465 - val_loss: 0.0815 - val_acc: 0.4482\n",
      "Epoch 300/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0815 - acc: 0.4454 - val_loss: 0.0814 - val_acc: 0.4475\n",
      "Epoch 301/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0815 - acc: 0.4445 - val_loss: 0.0813 - val_acc: 0.4470\n",
      "Epoch 302/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0814 - acc: 0.4440 - val_loss: 0.0813 - val_acc: 0.4462\n",
      "Epoch 303/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0813 - acc: 0.4435 - val_loss: 0.0812 - val_acc: 0.4451\n",
      "Epoch 304/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0813 - acc: 0.4423 - val_loss: 0.0811 - val_acc: 0.4442\n",
      "Epoch 305/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0812 - acc: 0.4408 - val_loss: 0.0811 - val_acc: 0.4441\n",
      "Epoch 306/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0811 - acc: 0.4403 - val_loss: 0.0810 - val_acc: 0.4429\n",
      "Epoch 307/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0811 - acc: 0.4395 - val_loss: 0.0809 - val_acc: 0.4419\n",
      "Epoch 308/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0810 - acc: 0.4386 - val_loss: 0.0808 - val_acc: 0.4410\n",
      "Epoch 309/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0809 - acc: 0.4376 - val_loss: 0.0808 - val_acc: 0.4397\n",
      "Epoch 310/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0808 - acc: 0.4367 - val_loss: 0.0807 - val_acc: 0.4392\n",
      "Epoch 311/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0808 - acc: 0.4362 - val_loss: 0.0806 - val_acc: 0.4385\n",
      "Epoch 312/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0807 - acc: 0.4352 - val_loss: 0.0806 - val_acc: 0.4369\n",
      "Epoch 313/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0806 - acc: 0.4338 - val_loss: 0.0805 - val_acc: 0.4357\n",
      "Epoch 314/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0805 - acc: 0.4334 - val_loss: 0.0804 - val_acc: 0.4347\n",
      "Epoch 315/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0805 - acc: 0.4320 - val_loss: 0.0803 - val_acc: 0.4342\n",
      "Epoch 316/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0804 - acc: 0.4318 - val_loss: 0.0803 - val_acc: 0.4335\n",
      "Epoch 317/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0803 - acc: 0.4304 - val_loss: 0.0802 - val_acc: 0.4329\n",
      "Epoch 318/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0802 - acc: 0.4300 - val_loss: 0.0801 - val_acc: 0.4320\n",
      "Epoch 319/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0802 - acc: 0.4282 - val_loss: 0.0800 - val_acc: 0.4313\n",
      "Epoch 320/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0801 - acc: 0.4284 - val_loss: 0.0799 - val_acc: 0.4308\n",
      "Epoch 321/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0800 - acc: 0.4276 - val_loss: 0.0799 - val_acc: 0.4293\n",
      "Epoch 322/2000\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0799 - acc: 0.4271 - val_loss: 0.0798 - val_acc: 0.4286\n",
      "Epoch 323/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0799 - acc: 0.4263 - val_loss: 0.0797 - val_acc: 0.4283\n",
      "Epoch 324/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0798 - acc: 0.4252 - val_loss: 0.0796 - val_acc: 0.4275\n",
      "Epoch 325/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0797 - acc: 0.4246 - val_loss: 0.0796 - val_acc: 0.4269\n",
      "Epoch 326/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0796 - acc: 0.4240 - val_loss: 0.0795 - val_acc: 0.4264\n",
      "Epoch 327/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0795 - acc: 0.4231 - val_loss: 0.0794 - val_acc: 0.4247\n",
      "Epoch 328/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0795 - acc: 0.4226 - val_loss: 0.0793 - val_acc: 0.4237\n",
      "Epoch 329/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0794 - acc: 0.4217 - val_loss: 0.0792 - val_acc: 0.4227\n",
      "Epoch 330/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0793 - acc: 0.4215 - val_loss: 0.0791 - val_acc: 0.4224\n",
      "Epoch 331/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0792 - acc: 0.4208 - val_loss: 0.0791 - val_acc: 0.4219\n",
      "Epoch 332/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0791 - acc: 0.4203 - val_loss: 0.0790 - val_acc: 0.4213\n",
      "Epoch 333/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0790 - acc: 0.4199 - val_loss: 0.0789 - val_acc: 0.4209\n",
      "Epoch 334/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0790 - acc: 0.4194 - val_loss: 0.0788 - val_acc: 0.4204\n",
      "Epoch 335/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0789 - acc: 0.4189 - val_loss: 0.0787 - val_acc: 0.4197\n",
      "Epoch 336/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0788 - acc: 0.4185 - val_loss: 0.0786 - val_acc: 0.4195\n",
      "Epoch 337/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0787 - acc: 0.4176 - val_loss: 0.0786 - val_acc: 0.4191\n",
      "Epoch 338/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0786 - acc: 0.4177 - val_loss: 0.0785 - val_acc: 0.4183\n",
      "Epoch 339/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0785 - acc: 0.4171 - val_loss: 0.0784 - val_acc: 0.4176\n",
      "Epoch 340/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0784 - acc: 0.4167 - val_loss: 0.0783 - val_acc: 0.4177\n",
      "Epoch 341/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0784 - acc: 0.4164 - val_loss: 0.0782 - val_acc: 0.4172\n",
      "Epoch 342/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0783 - acc: 0.4158 - val_loss: 0.0781 - val_acc: 0.4170\n",
      "Epoch 343/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0782 - acc: 0.4152 - val_loss: 0.0780 - val_acc: 0.4167\n",
      "Epoch 344/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0781 - acc: 0.4149 - val_loss: 0.0779 - val_acc: 0.4165\n",
      "Epoch 345/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0780 - acc: 0.4147 - val_loss: 0.0779 - val_acc: 0.4156\n",
      "Epoch 346/2000\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0779 - acc: 0.4147 - val_loss: 0.0778 - val_acc: 0.4153\n",
      "Epoch 347/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0778 - acc: 0.4138 - val_loss: 0.0777 - val_acc: 0.4152\n",
      "Epoch 348/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0777 - acc: 0.4143 - val_loss: 0.0776 - val_acc: 0.4144\n",
      "Epoch 349/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0777 - acc: 0.4141 - val_loss: 0.0775 - val_acc: 0.4142\n",
      "Epoch 350/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0776 - acc: 0.4135 - val_loss: 0.0774 - val_acc: 0.4138\n",
      "Epoch 351/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0775 - acc: 0.4136 - val_loss: 0.0773 - val_acc: 0.4132\n",
      "Epoch 352/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0774 - acc: 0.4133 - val_loss: 0.0772 - val_acc: 0.4128\n",
      "Epoch 353/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0773 - acc: 0.4133 - val_loss: 0.0771 - val_acc: 0.4128\n",
      "Epoch 354/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0772 - acc: 0.4132 - val_loss: 0.0770 - val_acc: 0.4125\n",
      "Epoch 355/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0771 - acc: 0.4131 - val_loss: 0.0769 - val_acc: 0.4123\n",
      "Epoch 356/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0770 - acc: 0.4130 - val_loss: 0.0768 - val_acc: 0.4117\n",
      "Epoch 357/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0769 - acc: 0.4125 - val_loss: 0.0768 - val_acc: 0.4116\n",
      "Epoch 358/2000\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0768 - acc: 0.4126 - val_loss: 0.0767 - val_acc: 0.4112\n",
      "Epoch 359/2000\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0767 - acc: 0.4114 - val_loss: 0.0766 - val_acc: 0.4116\n",
      "Epoch 360/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0766 - acc: 0.4120 - val_loss: 0.0765 - val_acc: 0.4113\n",
      "Epoch 361/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0765 - acc: 0.4124 - val_loss: 0.0764 - val_acc: 0.4109\n",
      "Epoch 362/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0764 - acc: 0.4118 - val_loss: 0.0763 - val_acc: 0.4105\n",
      "Epoch 363/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0763 - acc: 0.4120 - val_loss: 0.0762 - val_acc: 0.4100\n",
      "Epoch 364/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0763 - acc: 0.4120 - val_loss: 0.0761 - val_acc: 0.4105\n",
      "Epoch 365/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0762 - acc: 0.4115 - val_loss: 0.0760 - val_acc: 0.4104\n",
      "Epoch 366/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0761 - acc: 0.4120 - val_loss: 0.0759 - val_acc: 0.4099\n",
      "Epoch 367/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0760 - acc: 0.4119 - val_loss: 0.0758 - val_acc: 0.4099\n",
      "Epoch 368/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0759 - acc: 0.4120 - val_loss: 0.0757 - val_acc: 0.4102\n",
      "Epoch 369/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0758 - acc: 0.4120 - val_loss: 0.0756 - val_acc: 0.4106\n",
      "Epoch 370/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0757 - acc: 0.4126 - val_loss: 0.0755 - val_acc: 0.4105\n",
      "Epoch 371/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0756 - acc: 0.4122 - val_loss: 0.0754 - val_acc: 0.4106\n",
      "Epoch 372/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0755 - acc: 0.4120 - val_loss: 0.0753 - val_acc: 0.4109\n",
      "Epoch 373/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0754 - acc: 0.4126 - val_loss: 0.0752 - val_acc: 0.4110\n",
      "Epoch 374/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0753 - acc: 0.4127 - val_loss: 0.0751 - val_acc: 0.4108\n",
      "Epoch 375/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0752 - acc: 0.4127 - val_loss: 0.0750 - val_acc: 0.4105\n",
      "Epoch 376/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0751 - acc: 0.4127 - val_loss: 0.0749 - val_acc: 0.4109\n",
      "Epoch 377/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0750 - acc: 0.4133 - val_loss: 0.0748 - val_acc: 0.4113\n",
      "Epoch 378/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0749 - acc: 0.4137 - val_loss: 0.0747 - val_acc: 0.4114\n",
      "Epoch 379/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0748 - acc: 0.4137 - val_loss: 0.0746 - val_acc: 0.4118\n",
      "Epoch 380/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0747 - acc: 0.4148 - val_loss: 0.0745 - val_acc: 0.4119\n",
      "Epoch 381/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0746 - acc: 0.4149 - val_loss: 0.0744 - val_acc: 0.4123\n",
      "Epoch 382/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0745 - acc: 0.4151 - val_loss: 0.0743 - val_acc: 0.4121\n",
      "Epoch 383/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0744 - acc: 0.4160 - val_loss: 0.0742 - val_acc: 0.4125\n",
      "Epoch 384/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0743 - acc: 0.4162 - val_loss: 0.0741 - val_acc: 0.4125\n",
      "Epoch 385/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0742 - acc: 0.4166 - val_loss: 0.0740 - val_acc: 0.4127\n",
      "Epoch 386/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0741 - acc: 0.4168 - val_loss: 0.0739 - val_acc: 0.4133\n",
      "Epoch 387/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0740 - acc: 0.4177 - val_loss: 0.0738 - val_acc: 0.4133\n",
      "Epoch 388/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0739 - acc: 0.4177 - val_loss: 0.0737 - val_acc: 0.4136\n",
      "Epoch 389/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0738 - acc: 0.4182 - val_loss: 0.0736 - val_acc: 0.4141\n",
      "Epoch 390/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0737 - acc: 0.4188 - val_loss: 0.0735 - val_acc: 0.4145\n",
      "Epoch 391/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0736 - acc: 0.4192 - val_loss: 0.0734 - val_acc: 0.4155\n",
      "Epoch 392/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0735 - acc: 0.4198 - val_loss: 0.0733 - val_acc: 0.4163\n",
      "Epoch 393/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0734 - acc: 0.4205 - val_loss: 0.0732 - val_acc: 0.4166\n",
      "Epoch 394/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0733 - acc: 0.4211 - val_loss: 0.0731 - val_acc: 0.4174\n",
      "Epoch 395/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0732 - acc: 0.4216 - val_loss: 0.0730 - val_acc: 0.4179\n",
      "Epoch 396/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0731 - acc: 0.4225 - val_loss: 0.0729 - val_acc: 0.4182\n",
      "Epoch 397/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0730 - acc: 0.4234 - val_loss: 0.0728 - val_acc: 0.4191\n",
      "Epoch 398/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0729 - acc: 0.4236 - val_loss: 0.0727 - val_acc: 0.4197\n",
      "Epoch 399/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0728 - acc: 0.4242 - val_loss: 0.0726 - val_acc: 0.4204\n",
      "Epoch 400/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0726 - acc: 0.4252 - val_loss: 0.0725 - val_acc: 0.4208\n",
      "Epoch 401/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0725 - acc: 0.4261 - val_loss: 0.0724 - val_acc: 0.4214\n",
      "Epoch 402/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0724 - acc: 0.4271 - val_loss: 0.0723 - val_acc: 0.4226\n",
      "Epoch 403/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0723 - acc: 0.4276 - val_loss: 0.0722 - val_acc: 0.4232\n",
      "Epoch 404/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0722 - acc: 0.4287 - val_loss: 0.0721 - val_acc: 0.4240\n",
      "Epoch 405/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0721 - acc: 0.4292 - val_loss: 0.0720 - val_acc: 0.4252\n",
      "Epoch 406/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0720 - acc: 0.4303 - val_loss: 0.0719 - val_acc: 0.4260\n",
      "Epoch 407/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0719 - acc: 0.4312 - val_loss: 0.0717 - val_acc: 0.4273\n",
      "Epoch 408/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0718 - acc: 0.4322 - val_loss: 0.0716 - val_acc: 0.4283\n",
      "Epoch 409/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0717 - acc: 0.4327 - val_loss: 0.0715 - val_acc: 0.4301\n",
      "Epoch 410/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0716 - acc: 0.4341 - val_loss: 0.0714 - val_acc: 0.4311\n",
      "Epoch 411/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0715 - acc: 0.4349 - val_loss: 0.0713 - val_acc: 0.4316\n",
      "Epoch 412/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0714 - acc: 0.4362 - val_loss: 0.0712 - val_acc: 0.4327\n",
      "Epoch 413/2000\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0713 - acc: 0.4372 - val_loss: 0.0711 - val_acc: 0.4339\n",
      "Epoch 414/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0712 - acc: 0.4384 - val_loss: 0.0710 - val_acc: 0.4348\n",
      "Epoch 415/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0711 - acc: 0.4393 - val_loss: 0.0709 - val_acc: 0.4357\n",
      "Epoch 416/2000\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0710 - acc: 0.4404 - val_loss: 0.0708 - val_acc: 0.4367\n",
      "Epoch 417/2000\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0709 - acc: 0.4421 - val_loss: 0.0707 - val_acc: 0.4382\n",
      "Epoch 418/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0708 - acc: 0.4434 - val_loss: 0.0706 - val_acc: 0.4401\n",
      "Epoch 419/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0707 - acc: 0.4449 - val_loss: 0.0705 - val_acc: 0.4413\n",
      "Epoch 420/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0706 - acc: 0.4458 - val_loss: 0.0704 - val_acc: 0.4418\n",
      "Epoch 421/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0704 - acc: 0.4472 - val_loss: 0.0703 - val_acc: 0.4427\n",
      "Epoch 422/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0703 - acc: 0.4483 - val_loss: 0.0702 - val_acc: 0.4444\n",
      "Epoch 423/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0702 - acc: 0.4496 - val_loss: 0.0701 - val_acc: 0.4454\n",
      "Epoch 424/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0701 - acc: 0.4508 - val_loss: 0.0700 - val_acc: 0.4467\n",
      "Epoch 425/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0700 - acc: 0.4521 - val_loss: 0.0698 - val_acc: 0.4480\n",
      "Epoch 426/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0699 - acc: 0.4536 - val_loss: 0.0697 - val_acc: 0.4492\n",
      "Epoch 427/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0698 - acc: 0.4547 - val_loss: 0.0696 - val_acc: 0.4503\n",
      "Epoch 428/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0697 - acc: 0.4562 - val_loss: 0.0695 - val_acc: 0.4515\n",
      "Epoch 429/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0696 - acc: 0.4574 - val_loss: 0.0694 - val_acc: 0.4534\n",
      "Epoch 430/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0695 - acc: 0.4591 - val_loss: 0.0693 - val_acc: 0.4546\n",
      "Epoch 431/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0694 - acc: 0.4609 - val_loss: 0.0692 - val_acc: 0.4563\n",
      "Epoch 432/2000\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0693 - acc: 0.4629 - val_loss: 0.0691 - val_acc: 0.4573\n",
      "Epoch 433/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0692 - acc: 0.4646 - val_loss: 0.0690 - val_acc: 0.4586\n",
      "Epoch 434/2000\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0691 - acc: 0.4664 - val_loss: 0.0689 - val_acc: 0.4603\n",
      "Epoch 435/2000\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0690 - acc: 0.4680 - val_loss: 0.0688 - val_acc: 0.4623\n",
      "Epoch 436/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0688 - acc: 0.4695 - val_loss: 0.0687 - val_acc: 0.4640\n",
      "Epoch 437/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0687 - acc: 0.4711 - val_loss: 0.0686 - val_acc: 0.4652\n",
      "Epoch 438/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0686 - acc: 0.4728 - val_loss: 0.0684 - val_acc: 0.4672\n",
      "Epoch 439/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0685 - acc: 0.4745 - val_loss: 0.0683 - val_acc: 0.4689\n",
      "Epoch 440/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0684 - acc: 0.4762 - val_loss: 0.0682 - val_acc: 0.4705\n",
      "Epoch 441/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0683 - acc: 0.4780 - val_loss: 0.0681 - val_acc: 0.4724\n",
      "Epoch 442/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0682 - acc: 0.4796 - val_loss: 0.0680 - val_acc: 0.4746\n",
      "Epoch 443/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0681 - acc: 0.4815 - val_loss: 0.0679 - val_acc: 0.4778\n",
      "Epoch 444/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0680 - acc: 0.4833 - val_loss: 0.0678 - val_acc: 0.4799\n",
      "Epoch 445/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0679 - acc: 0.4847 - val_loss: 0.0677 - val_acc: 0.4816\n",
      "Epoch 446/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0678 - acc: 0.4866 - val_loss: 0.0676 - val_acc: 0.4834\n",
      "Epoch 447/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0677 - acc: 0.4886 - val_loss: 0.0675 - val_acc: 0.4861\n",
      "Epoch 448/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0675 - acc: 0.4909 - val_loss: 0.0674 - val_acc: 0.4878\n",
      "Epoch 449/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0674 - acc: 0.4928 - val_loss: 0.0673 - val_acc: 0.4896\n",
      "Epoch 450/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0673 - acc: 0.4945 - val_loss: 0.0671 - val_acc: 0.4916\n",
      "Epoch 451/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0672 - acc: 0.4965 - val_loss: 0.0670 - val_acc: 0.4939\n",
      "Epoch 452/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0671 - acc: 0.4981 - val_loss: 0.0669 - val_acc: 0.4961\n",
      "Epoch 453/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0670 - acc: 0.5000 - val_loss: 0.0668 - val_acc: 0.4979\n",
      "Epoch 454/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0669 - acc: 0.5022 - val_loss: 0.0667 - val_acc: 0.4996\n",
      "Epoch 455/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0668 - acc: 0.5036 - val_loss: 0.0666 - val_acc: 0.5018\n",
      "Epoch 456/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0667 - acc: 0.5055 - val_loss: 0.0665 - val_acc: 0.5040\n",
      "Epoch 457/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0666 - acc: 0.5077 - val_loss: 0.0664 - val_acc: 0.5056\n",
      "Epoch 458/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0665 - acc: 0.5097 - val_loss: 0.0663 - val_acc: 0.5084\n",
      "Epoch 459/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0664 - acc: 0.5116 - val_loss: 0.0662 - val_acc: 0.5110\n",
      "Epoch 460/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0662 - acc: 0.5134 - val_loss: 0.0660 - val_acc: 0.5128\n",
      "Epoch 461/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0661 - acc: 0.5152 - val_loss: 0.0659 - val_acc: 0.5155\n",
      "Epoch 462/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0660 - acc: 0.5176 - val_loss: 0.0658 - val_acc: 0.5169\n",
      "Epoch 463/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0659 - acc: 0.5196 - val_loss: 0.0657 - val_acc: 0.5192\n",
      "Epoch 464/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0658 - acc: 0.5214 - val_loss: 0.0656 - val_acc: 0.5204\n",
      "Epoch 465/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0657 - acc: 0.5230 - val_loss: 0.0655 - val_acc: 0.5213\n",
      "Epoch 466/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0656 - acc: 0.5246 - val_loss: 0.0654 - val_acc: 0.5235\n",
      "Epoch 467/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0655 - acc: 0.5266 - val_loss: 0.0653 - val_acc: 0.5258\n",
      "Epoch 468/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0654 - acc: 0.5288 - val_loss: 0.0652 - val_acc: 0.5276\n",
      "Epoch 469/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0653 - acc: 0.5307 - val_loss: 0.0651 - val_acc: 0.5298\n",
      "Epoch 470/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0651 - acc: 0.5321 - val_loss: 0.0649 - val_acc: 0.5321\n",
      "Epoch 471/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0650 - acc: 0.5341 - val_loss: 0.0648 - val_acc: 0.5339\n",
      "Epoch 472/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0649 - acc: 0.5356 - val_loss: 0.0647 - val_acc: 0.5353\n",
      "Epoch 473/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0648 - acc: 0.5374 - val_loss: 0.0646 - val_acc: 0.5373\n",
      "Epoch 474/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0647 - acc: 0.5387 - val_loss: 0.0645 - val_acc: 0.5388\n",
      "Epoch 475/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0646 - acc: 0.5403 - val_loss: 0.0644 - val_acc: 0.5408\n",
      "Epoch 476/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0645 - acc: 0.5425 - val_loss: 0.0643 - val_acc: 0.5423\n",
      "Epoch 477/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0644 - acc: 0.5442 - val_loss: 0.0642 - val_acc: 0.5443\n",
      "Epoch 478/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0643 - acc: 0.5459 - val_loss: 0.0641 - val_acc: 0.5464\n",
      "Epoch 479/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0642 - acc: 0.5474 - val_loss: 0.0640 - val_acc: 0.5488\n",
      "Epoch 480/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0641 - acc: 0.5490 - val_loss: 0.0638 - val_acc: 0.5506\n",
      "Epoch 481/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0639 - acc: 0.5508 - val_loss: 0.0637 - val_acc: 0.5523\n",
      "Epoch 482/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0638 - acc: 0.5526 - val_loss: 0.0636 - val_acc: 0.5544\n",
      "Epoch 483/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0637 - acc: 0.5543 - val_loss: 0.0635 - val_acc: 0.5560\n",
      "Epoch 484/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0636 - acc: 0.5557 - val_loss: 0.0634 - val_acc: 0.5569\n",
      "Epoch 485/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0635 - acc: 0.5575 - val_loss: 0.0633 - val_acc: 0.5588\n",
      "Epoch 486/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0634 - acc: 0.5588 - val_loss: 0.0632 - val_acc: 0.5611\n",
      "Epoch 487/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0633 - acc: 0.5602 - val_loss: 0.0631 - val_acc: 0.5622\n",
      "Epoch 488/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0632 - acc: 0.5616 - val_loss: 0.0630 - val_acc: 0.5640\n",
      "Epoch 489/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0631 - acc: 0.5632 - val_loss: 0.0628 - val_acc: 0.5650\n",
      "Epoch 490/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0630 - acc: 0.5643 - val_loss: 0.0627 - val_acc: 0.5666\n",
      "Epoch 491/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0628 - acc: 0.5660 - val_loss: 0.0626 - val_acc: 0.5693\n",
      "Epoch 492/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0627 - acc: 0.5673 - val_loss: 0.0625 - val_acc: 0.5710\n",
      "Epoch 493/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0626 - acc: 0.5684 - val_loss: 0.0624 - val_acc: 0.5723\n",
      "Epoch 494/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0625 - acc: 0.5702 - val_loss: 0.0623 - val_acc: 0.5738\n",
      "Epoch 495/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0624 - acc: 0.5719 - val_loss: 0.0622 - val_acc: 0.5754\n",
      "Epoch 496/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0623 - acc: 0.5730 - val_loss: 0.0621 - val_acc: 0.5767\n",
      "Epoch 497/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0622 - acc: 0.5741 - val_loss: 0.0620 - val_acc: 0.5779\n",
      "Epoch 498/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0621 - acc: 0.5757 - val_loss: 0.0619 - val_acc: 0.5790\n",
      "Epoch 499/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0620 - acc: 0.5767 - val_loss: 0.0617 - val_acc: 0.5799\n",
      "Epoch 500/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0619 - acc: 0.5780 - val_loss: 0.0616 - val_acc: 0.5807\n",
      "Epoch 501/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0617 - acc: 0.5790 - val_loss: 0.0615 - val_acc: 0.5822\n",
      "Epoch 502/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0616 - acc: 0.5802 - val_loss: 0.0614 - val_acc: 0.5840\n",
      "Epoch 503/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0615 - acc: 0.5813 - val_loss: 0.0613 - val_acc: 0.5851\n",
      "Epoch 504/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0614 - acc: 0.5827 - val_loss: 0.0612 - val_acc: 0.5869\n",
      "Epoch 505/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0613 - acc: 0.5838 - val_loss: 0.0611 - val_acc: 0.5881\n",
      "Epoch 506/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0612 - acc: 0.5849 - val_loss: 0.0610 - val_acc: 0.5899\n",
      "Epoch 507/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0611 - acc: 0.5861 - val_loss: 0.0609 - val_acc: 0.5914\n",
      "Epoch 508/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0610 - acc: 0.5876 - val_loss: 0.0608 - val_acc: 0.5922\n",
      "Epoch 509/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0609 - acc: 0.5888 - val_loss: 0.0606 - val_acc: 0.5934\n",
      "Epoch 510/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0608 - acc: 0.5900 - val_loss: 0.0605 - val_acc: 0.5938\n",
      "Epoch 511/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0607 - acc: 0.5909 - val_loss: 0.0604 - val_acc: 0.5954\n",
      "Epoch 512/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0606 - acc: 0.5921 - val_loss: 0.0603 - val_acc: 0.5966\n",
      "Epoch 513/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0604 - acc: 0.5930 - val_loss: 0.0602 - val_acc: 0.5975\n",
      "Epoch 514/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0603 - acc: 0.5942 - val_loss: 0.0601 - val_acc: 0.5988\n",
      "Epoch 515/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0602 - acc: 0.5950 - val_loss: 0.0600 - val_acc: 0.5995\n",
      "Epoch 516/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0601 - acc: 0.5962 - val_loss: 0.0599 - val_acc: 0.6007\n",
      "Epoch 517/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0600 - acc: 0.5971 - val_loss: 0.0598 - val_acc: 0.6010\n",
      "Epoch 518/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0599 - acc: 0.5981 - val_loss: 0.0597 - val_acc: 0.6014\n",
      "Epoch 519/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0598 - acc: 0.5993 - val_loss: 0.0596 - val_acc: 0.6025\n",
      "Epoch 520/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0597 - acc: 0.6001 - val_loss: 0.0594 - val_acc: 0.6040\n",
      "Epoch 521/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0596 - acc: 0.6010 - val_loss: 0.0593 - val_acc: 0.6053\n",
      "Epoch 522/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0595 - acc: 0.6022 - val_loss: 0.0592 - val_acc: 0.6057\n",
      "Epoch 523/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0594 - acc: 0.6030 - val_loss: 0.0591 - val_acc: 0.6072\n",
      "Epoch 524/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0593 - acc: 0.6039 - val_loss: 0.0590 - val_acc: 0.6081\n",
      "Epoch 525/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0592 - acc: 0.6049 - val_loss: 0.0589 - val_acc: 0.6089\n",
      "Epoch 526/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0590 - acc: 0.6061 - val_loss: 0.0588 - val_acc: 0.6096\n",
      "Epoch 527/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0589 - acc: 0.6074 - val_loss: 0.0587 - val_acc: 0.6101\n",
      "Epoch 528/2000\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0588 - acc: 0.6084 - val_loss: 0.0586 - val_acc: 0.6114\n",
      "Epoch 529/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0587 - acc: 0.6092 - val_loss: 0.0585 - val_acc: 0.6131\n",
      "Epoch 530/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0586 - acc: 0.6103 - val_loss: 0.0584 - val_acc: 0.6143\n",
      "Epoch 531/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0585 - acc: 0.6116 - val_loss: 0.0583 - val_acc: 0.6154\n",
      "Epoch 532/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0584 - acc: 0.6122 - val_loss: 0.0582 - val_acc: 0.6164\n",
      "Epoch 533/2000\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0583 - acc: 0.6134 - val_loss: 0.0581 - val_acc: 0.6169\n",
      "Epoch 534/2000\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0582 - acc: 0.6143 - val_loss: 0.0579 - val_acc: 0.6181\n",
      "Epoch 535/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0581 - acc: 0.6151 - val_loss: 0.0578 - val_acc: 0.6186\n",
      "Epoch 536/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0580 - acc: 0.6159 - val_loss: 0.0577 - val_acc: 0.6195\n",
      "Epoch 537/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0579 - acc: 0.6166 - val_loss: 0.0576 - val_acc: 0.6209\n",
      "Epoch 538/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0578 - acc: 0.6177 - val_loss: 0.0575 - val_acc: 0.6213\n",
      "Epoch 539/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0577 - acc: 0.6184 - val_loss: 0.0574 - val_acc: 0.6222\n",
      "Epoch 540/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0576 - acc: 0.6195 - val_loss: 0.0573 - val_acc: 0.6233\n",
      "Epoch 541/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0575 - acc: 0.6201 - val_loss: 0.0572 - val_acc: 0.6238\n",
      "Epoch 542/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0574 - acc: 0.6209 - val_loss: 0.0571 - val_acc: 0.6245\n",
      "Epoch 543/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0573 - acc: 0.6218 - val_loss: 0.0570 - val_acc: 0.6248\n",
      "Epoch 544/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0572 - acc: 0.6225 - val_loss: 0.0569 - val_acc: 0.6258\n",
      "Epoch 545/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0571 - acc: 0.6232 - val_loss: 0.0568 - val_acc: 0.6267\n",
      "Epoch 546/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0570 - acc: 0.6238 - val_loss: 0.0567 - val_acc: 0.6272\n",
      "Epoch 547/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0568 - acc: 0.6244 - val_loss: 0.0566 - val_acc: 0.6282\n",
      "Epoch 548/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0567 - acc: 0.6251 - val_loss: 0.0565 - val_acc: 0.6288\n",
      "Epoch 549/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0566 - acc: 0.6258 - val_loss: 0.0564 - val_acc: 0.6296\n",
      "Epoch 550/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0565 - acc: 0.6266 - val_loss: 0.0563 - val_acc: 0.6300\n",
      "Epoch 551/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0564 - acc: 0.6273 - val_loss: 0.0562 - val_acc: 0.6305\n",
      "Epoch 552/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0563 - acc: 0.6279 - val_loss: 0.0561 - val_acc: 0.6316\n",
      "Epoch 553/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0562 - acc: 0.6287 - val_loss: 0.0560 - val_acc: 0.6322\n",
      "Epoch 554/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0561 - acc: 0.6295 - val_loss: 0.0559 - val_acc: 0.6328\n",
      "Epoch 555/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0560 - acc: 0.6304 - val_loss: 0.0558 - val_acc: 0.6330\n",
      "Epoch 556/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0559 - acc: 0.6311 - val_loss: 0.0557 - val_acc: 0.6335\n",
      "Epoch 557/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0558 - acc: 0.6317 - val_loss: 0.0556 - val_acc: 0.6347\n",
      "Epoch 558/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0557 - acc: 0.6321 - val_loss: 0.0555 - val_acc: 0.6356\n",
      "Epoch 559/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0556 - acc: 0.6329 - val_loss: 0.0554 - val_acc: 0.6364\n",
      "Epoch 560/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0555 - acc: 0.6334 - val_loss: 0.0553 - val_acc: 0.6367\n",
      "Epoch 561/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0554 - acc: 0.6340 - val_loss: 0.0552 - val_acc: 0.6375\n",
      "Epoch 562/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0553 - acc: 0.6349 - val_loss: 0.0551 - val_acc: 0.6380\n",
      "Epoch 563/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0552 - acc: 0.6353 - val_loss: 0.0550 - val_acc: 0.6386\n",
      "Epoch 564/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0551 - acc: 0.6361 - val_loss: 0.0549 - val_acc: 0.6397\n",
      "Epoch 565/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0550 - acc: 0.6370 - val_loss: 0.0548 - val_acc: 0.6400\n",
      "Epoch 566/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0549 - acc: 0.6378 - val_loss: 0.0547 - val_acc: 0.6410\n",
      "Epoch 567/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0548 - acc: 0.6386 - val_loss: 0.0546 - val_acc: 0.6419\n",
      "Epoch 568/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0548 - acc: 0.6397 - val_loss: 0.0545 - val_acc: 0.6426\n",
      "Epoch 569/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0547 - acc: 0.6404 - val_loss: 0.0544 - val_acc: 0.6431\n",
      "Epoch 570/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0546 - acc: 0.6411 - val_loss: 0.0543 - val_acc: 0.6436\n",
      "Epoch 571/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0545 - acc: 0.6417 - val_loss: 0.0542 - val_acc: 0.6442\n",
      "Epoch 572/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0544 - acc: 0.6425 - val_loss: 0.0541 - val_acc: 0.6451\n",
      "Epoch 573/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0543 - acc: 0.6431 - val_loss: 0.0540 - val_acc: 0.6456\n",
      "Epoch 574/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0542 - acc: 0.6438 - val_loss: 0.0539 - val_acc: 0.6469\n",
      "Epoch 575/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0541 - acc: 0.6448 - val_loss: 0.0538 - val_acc: 0.6478\n",
      "Epoch 576/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0540 - acc: 0.6453 - val_loss: 0.0537 - val_acc: 0.6485\n",
      "Epoch 577/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0539 - acc: 0.6462 - val_loss: 0.0536 - val_acc: 0.6489\n",
      "Epoch 578/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0538 - acc: 0.6466 - val_loss: 0.0535 - val_acc: 0.6493\n",
      "Epoch 579/2000\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0537 - acc: 0.6477 - val_loss: 0.0534 - val_acc: 0.6499\n",
      "Epoch 580/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0536 - acc: 0.6486 - val_loss: 0.0533 - val_acc: 0.6506\n",
      "Epoch 581/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0535 - acc: 0.6490 - val_loss: 0.0532 - val_acc: 0.6516\n",
      "Epoch 582/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0534 - acc: 0.6499 - val_loss: 0.0531 - val_acc: 0.6520\n",
      "Epoch 583/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0533 - acc: 0.6507 - val_loss: 0.0530 - val_acc: 0.6523\n",
      "Epoch 584/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0532 - acc: 0.6514 - val_loss: 0.0529 - val_acc: 0.6531\n",
      "Epoch 585/2000\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0531 - acc: 0.6522 - val_loss: 0.0529 - val_acc: 0.6535\n",
      "Epoch 586/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0531 - acc: 0.6529 - val_loss: 0.0528 - val_acc: 0.6540\n",
      "Epoch 587/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0530 - acc: 0.6536 - val_loss: 0.0527 - val_acc: 0.6544\n",
      "Epoch 588/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0529 - acc: 0.6542 - val_loss: 0.0526 - val_acc: 0.6553\n",
      "Epoch 589/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0528 - acc: 0.6551 - val_loss: 0.0525 - val_acc: 0.6561\n",
      "Epoch 590/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0527 - acc: 0.6557 - val_loss: 0.0524 - val_acc: 0.6570\n",
      "Epoch 591/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0526 - acc: 0.6567 - val_loss: 0.0523 - val_acc: 0.6576\n",
      "Epoch 592/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0525 - acc: 0.6575 - val_loss: 0.0522 - val_acc: 0.6583\n",
      "Epoch 593/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0524 - acc: 0.6581 - val_loss: 0.0521 - val_acc: 0.6591\n",
      "Epoch 594/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0523 - acc: 0.6590 - val_loss: 0.0520 - val_acc: 0.6596\n",
      "Epoch 595/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0522 - acc: 0.6597 - val_loss: 0.0519 - val_acc: 0.6602\n",
      "Epoch 596/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0522 - acc: 0.6605 - val_loss: 0.0519 - val_acc: 0.6608\n",
      "Epoch 597/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0521 - acc: 0.6616 - val_loss: 0.0518 - val_acc: 0.6619\n",
      "Epoch 598/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0520 - acc: 0.6623 - val_loss: 0.0517 - val_acc: 0.6624\n",
      "Epoch 599/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0519 - acc: 0.6629 - val_loss: 0.0516 - val_acc: 0.6640\n",
      "Epoch 600/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0518 - acc: 0.6635 - val_loss: 0.0515 - val_acc: 0.6643\n",
      "Epoch 601/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0517 - acc: 0.6641 - val_loss: 0.0514 - val_acc: 0.6648\n",
      "Epoch 602/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0516 - acc: 0.6649 - val_loss: 0.0513 - val_acc: 0.6653\n",
      "Epoch 603/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0515 - acc: 0.6656 - val_loss: 0.0512 - val_acc: 0.6664\n",
      "Epoch 604/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0514 - acc: 0.6662 - val_loss: 0.0511 - val_acc: 0.6671\n",
      "Epoch 605/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0514 - acc: 0.6670 - val_loss: 0.0511 - val_acc: 0.6681\n",
      "Epoch 606/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0513 - acc: 0.6678 - val_loss: 0.0510 - val_acc: 0.6684\n",
      "Epoch 607/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0512 - acc: 0.6684 - val_loss: 0.0509 - val_acc: 0.6690\n",
      "Epoch 608/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0511 - acc: 0.6690 - val_loss: 0.0508 - val_acc: 0.6703\n",
      "Epoch 609/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0510 - acc: 0.6700 - val_loss: 0.0507 - val_acc: 0.6705\n",
      "Epoch 610/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0509 - acc: 0.6705 - val_loss: 0.0506 - val_acc: 0.6713\n",
      "Epoch 611/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0509 - acc: 0.6715 - val_loss: 0.0505 - val_acc: 0.6723\n",
      "Epoch 612/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0508 - acc: 0.6723 - val_loss: 0.0505 - val_acc: 0.6727\n",
      "Epoch 613/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0507 - acc: 0.6729 - val_loss: 0.0504 - val_acc: 0.6734\n",
      "Epoch 614/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0506 - acc: 0.6737 - val_loss: 0.0503 - val_acc: 0.6741\n",
      "Epoch 615/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0505 - acc: 0.6745 - val_loss: 0.0502 - val_acc: 0.6748\n",
      "Epoch 616/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0504 - acc: 0.6752 - val_loss: 0.0501 - val_acc: 0.6756\n",
      "Epoch 617/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0503 - acc: 0.6757 - val_loss: 0.0500 - val_acc: 0.6761\n",
      "Epoch 618/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0503 - acc: 0.6765 - val_loss: 0.0500 - val_acc: 0.6769\n",
      "Epoch 619/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0502 - acc: 0.6776 - val_loss: 0.0499 - val_acc: 0.6775\n",
      "Epoch 620/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0501 - acc: 0.6783 - val_loss: 0.0498 - val_acc: 0.6781\n",
      "Epoch 621/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0500 - acc: 0.6789 - val_loss: 0.0497 - val_acc: 0.6790\n",
      "Epoch 622/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0499 - acc: 0.6795 - val_loss: 0.0496 - val_acc: 0.6799\n",
      "Epoch 623/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0499 - acc: 0.6803 - val_loss: 0.0495 - val_acc: 0.6806\n",
      "Epoch 624/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0498 - acc: 0.6809 - val_loss: 0.0495 - val_acc: 0.6813\n",
      "Epoch 625/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0497 - acc: 0.6820 - val_loss: 0.0494 - val_acc: 0.6819\n",
      "Epoch 626/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0496 - acc: 0.6824 - val_loss: 0.0493 - val_acc: 0.6826\n",
      "Epoch 627/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0495 - acc: 0.6830 - val_loss: 0.0492 - val_acc: 0.6834\n",
      "Epoch 628/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0495 - acc: 0.6836 - val_loss: 0.0491 - val_acc: 0.6841\n",
      "Epoch 629/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0494 - acc: 0.6843 - val_loss: 0.0491 - val_acc: 0.6847\n",
      "Epoch 630/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0493 - acc: 0.6852 - val_loss: 0.0490 - val_acc: 0.6854\n",
      "Epoch 631/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0492 - acc: 0.6859 - val_loss: 0.0489 - val_acc: 0.6863\n",
      "Epoch 632/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0491 - acc: 0.6864 - val_loss: 0.0488 - val_acc: 0.6876\n",
      "Epoch 633/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0491 - acc: 0.6869 - val_loss: 0.0487 - val_acc: 0.6881\n",
      "Epoch 634/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0490 - acc: 0.6875 - val_loss: 0.0487 - val_acc: 0.6889\n",
      "Epoch 635/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0489 - acc: 0.6883 - val_loss: 0.0486 - val_acc: 0.6896\n",
      "Epoch 636/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0488 - acc: 0.6890 - val_loss: 0.0485 - val_acc: 0.6904\n",
      "Epoch 637/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0487 - acc: 0.6899 - val_loss: 0.0484 - val_acc: 0.6910\n",
      "Epoch 638/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0487 - acc: 0.6906 - val_loss: 0.0483 - val_acc: 0.6920\n",
      "Epoch 639/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0486 - acc: 0.6913 - val_loss: 0.0483 - val_acc: 0.6930\n",
      "Epoch 640/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0485 - acc: 0.6922 - val_loss: 0.0482 - val_acc: 0.6937\n",
      "Epoch 641/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0484 - acc: 0.6929 - val_loss: 0.0481 - val_acc: 0.6946\n",
      "Epoch 642/2000\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0484 - acc: 0.6938 - val_loss: 0.0480 - val_acc: 0.6952\n",
      "Epoch 643/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0483 - acc: 0.6942 - val_loss: 0.0480 - val_acc: 0.6960\n",
      "Epoch 644/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0482 - acc: 0.6946 - val_loss: 0.0479 - val_acc: 0.6966\n",
      "Epoch 645/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0481 - acc: 0.6952 - val_loss: 0.0478 - val_acc: 0.6974\n",
      "Epoch 646/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0481 - acc: 0.6958 - val_loss: 0.0477 - val_acc: 0.6990\n",
      "Epoch 647/2000\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0480 - acc: 0.6963 - val_loss: 0.0477 - val_acc: 0.6996\n",
      "Epoch 648/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0479 - acc: 0.6966 - val_loss: 0.0476 - val_acc: 0.7008\n",
      "Epoch 649/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0478 - acc: 0.6974 - val_loss: 0.0475 - val_acc: 0.7016\n",
      "Epoch 650/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0478 - acc: 0.6980 - val_loss: 0.0474 - val_acc: 0.7023\n",
      "Epoch 651/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0477 - acc: 0.6986 - val_loss: 0.0474 - val_acc: 0.7025\n",
      "Epoch 652/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0476 - acc: 0.6993 - val_loss: 0.0473 - val_acc: 0.7029\n",
      "Epoch 653/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0475 - acc: 0.6999 - val_loss: 0.0472 - val_acc: 0.7030\n",
      "Epoch 654/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0475 - acc: 0.7003 - val_loss: 0.0471 - val_acc: 0.7033\n",
      "Epoch 655/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0474 - acc: 0.7011 - val_loss: 0.0471 - val_acc: 0.7040\n",
      "Epoch 656/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0473 - acc: 0.7016 - val_loss: 0.0470 - val_acc: 0.7049\n",
      "Epoch 657/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0472 - acc: 0.7021 - val_loss: 0.0469 - val_acc: 0.7060\n",
      "Epoch 658/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0472 - acc: 0.7028 - val_loss: 0.0468 - val_acc: 0.7068\n",
      "Epoch 659/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0471 - acc: 0.7033 - val_loss: 0.0468 - val_acc: 0.7076\n",
      "Epoch 660/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0470 - acc: 0.7036 - val_loss: 0.0467 - val_acc: 0.7087\n",
      "Epoch 661/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0470 - acc: 0.7042 - val_loss: 0.0466 - val_acc: 0.7093\n",
      "Epoch 662/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0469 - acc: 0.7048 - val_loss: 0.0465 - val_acc: 0.7094\n",
      "Epoch 663/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0468 - acc: 0.7052 - val_loss: 0.0465 - val_acc: 0.7099\n",
      "Epoch 664/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0467 - acc: 0.7062 - val_loss: 0.0464 - val_acc: 0.7103\n",
      "Epoch 665/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0467 - acc: 0.7067 - val_loss: 0.0463 - val_acc: 0.7110\n",
      "Epoch 666/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0466 - acc: 0.7073 - val_loss: 0.0463 - val_acc: 0.7117\n",
      "Epoch 667/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0465 - acc: 0.7076 - val_loss: 0.0462 - val_acc: 0.7121\n",
      "Epoch 668/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0465 - acc: 0.7081 - val_loss: 0.0461 - val_acc: 0.7125\n",
      "Epoch 669/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0464 - acc: 0.7087 - val_loss: 0.0460 - val_acc: 0.7131\n",
      "Epoch 670/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0463 - acc: 0.7091 - val_loss: 0.0460 - val_acc: 0.7138\n",
      "Epoch 671/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0463 - acc: 0.7097 - val_loss: 0.0459 - val_acc: 0.7147\n",
      "Epoch 672/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0462 - acc: 0.7103 - val_loss: 0.0458 - val_acc: 0.7148\n",
      "Epoch 673/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0461 - acc: 0.7108 - val_loss: 0.0458 - val_acc: 0.7153\n",
      "Epoch 674/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0460 - acc: 0.7113 - val_loss: 0.0457 - val_acc: 0.7159\n",
      "Epoch 675/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0460 - acc: 0.7119 - val_loss: 0.0456 - val_acc: 0.7159\n",
      "Epoch 676/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0459 - acc: 0.7126 - val_loss: 0.0456 - val_acc: 0.7164\n",
      "Epoch 677/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0458 - acc: 0.7131 - val_loss: 0.0455 - val_acc: 0.7175\n",
      "Epoch 678/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0458 - acc: 0.7136 - val_loss: 0.0454 - val_acc: 0.7183\n",
      "Epoch 679/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0457 - acc: 0.7144 - val_loss: 0.0454 - val_acc: 0.7192\n",
      "Epoch 680/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0456 - acc: 0.7150 - val_loss: 0.0453 - val_acc: 0.7199\n",
      "Epoch 681/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0456 - acc: 0.7153 - val_loss: 0.0452 - val_acc: 0.7203\n",
      "Epoch 682/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0455 - acc: 0.7159 - val_loss: 0.0451 - val_acc: 0.7211\n",
      "Epoch 683/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0454 - acc: 0.7166 - val_loss: 0.0451 - val_acc: 0.7215\n",
      "Epoch 684/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0454 - acc: 0.7173 - val_loss: 0.0450 - val_acc: 0.7217\n",
      "Epoch 685/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0453 - acc: 0.7178 - val_loss: 0.0449 - val_acc: 0.7225\n",
      "Epoch 686/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0452 - acc: 0.7182 - val_loss: 0.0449 - val_acc: 0.7227\n",
      "Epoch 687/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0452 - acc: 0.7188 - val_loss: 0.0448 - val_acc: 0.7230\n",
      "Epoch 688/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0451 - acc: 0.7195 - val_loss: 0.0447 - val_acc: 0.7236\n",
      "Epoch 689/2000\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0450 - acc: 0.7201 - val_loss: 0.0447 - val_acc: 0.7240\n",
      "Epoch 690/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0450 - acc: 0.7206 - val_loss: 0.0446 - val_acc: 0.7248\n",
      "Epoch 691/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0449 - acc: 0.7210 - val_loss: 0.0445 - val_acc: 0.7249\n",
      "Epoch 692/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0448 - acc: 0.7214 - val_loss: 0.0445 - val_acc: 0.7254\n",
      "Epoch 693/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0448 - acc: 0.7218 - val_loss: 0.0444 - val_acc: 0.7262\n",
      "Epoch 694/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0447 - acc: 0.7221 - val_loss: 0.0443 - val_acc: 0.7268\n",
      "Epoch 695/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0446 - acc: 0.7225 - val_loss: 0.0443 - val_acc: 0.7277\n",
      "Epoch 696/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0446 - acc: 0.7230 - val_loss: 0.0442 - val_acc: 0.7286\n",
      "Epoch 697/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0445 - acc: 0.7236 - val_loss: 0.0442 - val_acc: 0.7288\n",
      "Epoch 698/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0444 - acc: 0.7240 - val_loss: 0.0441 - val_acc: 0.7298\n",
      "Epoch 699/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0444 - acc: 0.7243 - val_loss: 0.0440 - val_acc: 0.7305\n",
      "Epoch 700/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0443 - acc: 0.7247 - val_loss: 0.0440 - val_acc: 0.7307\n",
      "Epoch 701/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0443 - acc: 0.7253 - val_loss: 0.0439 - val_acc: 0.7309\n",
      "Epoch 702/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0442 - acc: 0.7258 - val_loss: 0.0438 - val_acc: 0.7323\n",
      "Epoch 703/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0441 - acc: 0.7265 - val_loss: 0.0438 - val_acc: 0.7327\n",
      "Epoch 704/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0441 - acc: 0.7270 - val_loss: 0.0437 - val_acc: 0.7330\n",
      "Epoch 705/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0440 - acc: 0.7273 - val_loss: 0.0436 - val_acc: 0.7335\n",
      "Epoch 706/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0439 - acc: 0.7278 - val_loss: 0.0436 - val_acc: 0.7342\n",
      "Epoch 707/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0439 - acc: 0.7282 - val_loss: 0.0435 - val_acc: 0.7344\n",
      "Epoch 708/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0438 - acc: 0.7288 - val_loss: 0.0434 - val_acc: 0.7348\n",
      "Epoch 709/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0437 - acc: 0.7291 - val_loss: 0.0434 - val_acc: 0.7354\n",
      "Epoch 710/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0437 - acc: 0.7296 - val_loss: 0.0433 - val_acc: 0.7355\n",
      "Epoch 711/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0436 - acc: 0.7300 - val_loss: 0.0433 - val_acc: 0.7357\n",
      "Epoch 712/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0436 - acc: 0.7303 - val_loss: 0.0432 - val_acc: 0.7361\n",
      "Epoch 713/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0435 - acc: 0.7306 - val_loss: 0.0431 - val_acc: 0.7367\n",
      "Epoch 714/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0434 - acc: 0.7311 - val_loss: 0.0431 - val_acc: 0.7372\n",
      "Epoch 715/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0434 - acc: 0.7314 - val_loss: 0.0430 - val_acc: 0.7375\n",
      "Epoch 716/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0433 - acc: 0.7318 - val_loss: 0.0429 - val_acc: 0.7377\n",
      "Epoch 717/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0433 - acc: 0.7322 - val_loss: 0.0429 - val_acc: 0.7384\n",
      "Epoch 718/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0432 - acc: 0.7328 - val_loss: 0.0428 - val_acc: 0.7384\n",
      "Epoch 719/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0431 - acc: 0.7332 - val_loss: 0.0428 - val_acc: 0.7386\n",
      "Epoch 720/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0431 - acc: 0.7336 - val_loss: 0.0427 - val_acc: 0.7391\n",
      "Epoch 721/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0430 - acc: 0.7340 - val_loss: 0.0426 - val_acc: 0.7398\n",
      "Epoch 722/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0430 - acc: 0.7344 - val_loss: 0.0426 - val_acc: 0.7403\n",
      "Epoch 723/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0429 - acc: 0.7349 - val_loss: 0.0425 - val_acc: 0.7412\n",
      "Epoch 724/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0428 - acc: 0.7353 - val_loss: 0.0425 - val_acc: 0.7418\n",
      "Epoch 725/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0428 - acc: 0.7357 - val_loss: 0.0424 - val_acc: 0.7423\n",
      "Epoch 726/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0427 - acc: 0.7361 - val_loss: 0.0423 - val_acc: 0.7429\n",
      "Epoch 727/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0427 - acc: 0.7364 - val_loss: 0.0423 - val_acc: 0.7432\n",
      "Epoch 728/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0426 - acc: 0.7370 - val_loss: 0.0422 - val_acc: 0.7435\n",
      "Epoch 729/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0425 - acc: 0.7373 - val_loss: 0.0422 - val_acc: 0.7438\n",
      "Epoch 730/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0425 - acc: 0.7377 - val_loss: 0.0421 - val_acc: 0.7438\n",
      "Epoch 731/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0424 - acc: 0.7380 - val_loss: 0.0420 - val_acc: 0.7445\n",
      "Epoch 732/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0424 - acc: 0.7385 - val_loss: 0.0420 - val_acc: 0.7452\n",
      "Epoch 733/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0423 - acc: 0.7388 - val_loss: 0.0419 - val_acc: 0.7457\n",
      "Epoch 734/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0422 - acc: 0.7392 - val_loss: 0.0419 - val_acc: 0.7461\n",
      "Epoch 735/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0422 - acc: 0.7396 - val_loss: 0.0418 - val_acc: 0.7467\n",
      "Epoch 736/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0421 - acc: 0.7401 - val_loss: 0.0417 - val_acc: 0.7475\n",
      "Epoch 737/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0421 - acc: 0.7404 - val_loss: 0.0417 - val_acc: 0.7478\n",
      "Epoch 738/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0420 - acc: 0.7407 - val_loss: 0.0416 - val_acc: 0.7479\n",
      "Epoch 739/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0419 - acc: 0.7411 - val_loss: 0.0416 - val_acc: 0.7480\n",
      "Epoch 740/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0419 - acc: 0.7416 - val_loss: 0.0415 - val_acc: 0.7485\n",
      "Epoch 741/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0418 - acc: 0.7420 - val_loss: 0.0414 - val_acc: 0.7493\n",
      "Epoch 742/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0418 - acc: 0.7424 - val_loss: 0.0414 - val_acc: 0.7499\n",
      "Epoch 743/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0417 - acc: 0.7429 - val_loss: 0.0413 - val_acc: 0.7503\n",
      "Epoch 744/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0417 - acc: 0.7431 - val_loss: 0.0413 - val_acc: 0.7506\n",
      "Epoch 745/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0416 - acc: 0.7435 - val_loss: 0.0412 - val_acc: 0.7508\n",
      "Epoch 746/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0415 - acc: 0.7438 - val_loss: 0.0412 - val_acc: 0.7510\n",
      "Epoch 747/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0415 - acc: 0.7444 - val_loss: 0.0411 - val_acc: 0.7514\n",
      "Epoch 748/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0414 - acc: 0.7447 - val_loss: 0.0410 - val_acc: 0.7522\n",
      "Epoch 749/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0414 - acc: 0.7452 - val_loss: 0.0410 - val_acc: 0.7525\n",
      "Epoch 750/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0413 - acc: 0.7454 - val_loss: 0.0409 - val_acc: 0.7528\n",
      "Epoch 751/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0413 - acc: 0.7458 - val_loss: 0.0409 - val_acc: 0.7537\n",
      "Epoch 752/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0412 - acc: 0.7460 - val_loss: 0.0408 - val_acc: 0.7540\n",
      "Epoch 753/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0411 - acc: 0.7464 - val_loss: 0.0408 - val_acc: 0.7541\n",
      "Epoch 754/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0411 - acc: 0.7468 - val_loss: 0.0407 - val_acc: 0.7544\n",
      "Epoch 755/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0410 - acc: 0.7471 - val_loss: 0.0406 - val_acc: 0.7545\n",
      "Epoch 756/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0410 - acc: 0.7476 - val_loss: 0.0406 - val_acc: 0.7548\n",
      "Epoch 757/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0409 - acc: 0.7479 - val_loss: 0.0405 - val_acc: 0.7553\n",
      "Epoch 758/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0409 - acc: 0.7483 - val_loss: 0.0405 - val_acc: 0.7557\n",
      "Epoch 759/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0408 - acc: 0.7485 - val_loss: 0.0404 - val_acc: 0.7561\n",
      "Epoch 760/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0408 - acc: 0.7488 - val_loss: 0.0404 - val_acc: 0.7566\n",
      "Epoch 761/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0407 - acc: 0.7491 - val_loss: 0.0403 - val_acc: 0.7571\n",
      "Epoch 762/2000\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0406 - acc: 0.7495 - val_loss: 0.0402 - val_acc: 0.7572\n",
      "Epoch 763/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0406 - acc: 0.7498 - val_loss: 0.0402 - val_acc: 0.7576\n",
      "Epoch 764/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0405 - acc: 0.7500 - val_loss: 0.0401 - val_acc: 0.7584\n",
      "Epoch 765/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0405 - acc: 0.7502 - val_loss: 0.0401 - val_acc: 0.7587\n",
      "Epoch 766/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0404 - acc: 0.7506 - val_loss: 0.0400 - val_acc: 0.7589\n",
      "Epoch 767/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0404 - acc: 0.7510 - val_loss: 0.0400 - val_acc: 0.7595\n",
      "Epoch 768/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0403 - acc: 0.7513 - val_loss: 0.0399 - val_acc: 0.7602\n",
      "Epoch 769/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0403 - acc: 0.7517 - val_loss: 0.0399 - val_acc: 0.7604\n",
      "Epoch 770/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0402 - acc: 0.7520 - val_loss: 0.0398 - val_acc: 0.7604\n",
      "Epoch 771/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0402 - acc: 0.7523 - val_loss: 0.0398 - val_acc: 0.7603\n",
      "Epoch 772/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0401 - acc: 0.7527 - val_loss: 0.0397 - val_acc: 0.7606\n",
      "Epoch 773/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0401 - acc: 0.7530 - val_loss: 0.0396 - val_acc: 0.7611\n",
      "Epoch 774/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0400 - acc: 0.7532 - val_loss: 0.0396 - val_acc: 0.7612\n",
      "Epoch 775/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0399 - acc: 0.7535 - val_loss: 0.0395 - val_acc: 0.7615\n",
      "Epoch 776/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0399 - acc: 0.7538 - val_loss: 0.0395 - val_acc: 0.7617\n",
      "Epoch 777/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0398 - acc: 0.7541 - val_loss: 0.0394 - val_acc: 0.7620\n",
      "Epoch 778/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0398 - acc: 0.7545 - val_loss: 0.0394 - val_acc: 0.7627\n",
      "Epoch 779/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0397 - acc: 0.7548 - val_loss: 0.0393 - val_acc: 0.7634\n",
      "Epoch 780/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0397 - acc: 0.7551 - val_loss: 0.0393 - val_acc: 0.7634\n",
      "Epoch 781/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0396 - acc: 0.7554 - val_loss: 0.0392 - val_acc: 0.7636\n",
      "Epoch 782/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0396 - acc: 0.7556 - val_loss: 0.0392 - val_acc: 0.7638\n",
      "Epoch 783/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0395 - acc: 0.7559 - val_loss: 0.0391 - val_acc: 0.7641\n",
      "Epoch 784/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0395 - acc: 0.7560 - val_loss: 0.0391 - val_acc: 0.7648\n",
      "Epoch 785/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0394 - acc: 0.7565 - val_loss: 0.0390 - val_acc: 0.7648\n",
      "Epoch 786/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0394 - acc: 0.7568 - val_loss: 0.0390 - val_acc: 0.7649\n",
      "Epoch 787/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0393 - acc: 0.7572 - val_loss: 0.0389 - val_acc: 0.7654\n",
      "Epoch 788/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0393 - acc: 0.7573 - val_loss: 0.0388 - val_acc: 0.7656\n",
      "Epoch 789/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0392 - acc: 0.7576 - val_loss: 0.0388 - val_acc: 0.7660\n",
      "Epoch 790/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0392 - acc: 0.7579 - val_loss: 0.0387 - val_acc: 0.7660\n",
      "Epoch 791/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0391 - acc: 0.7581 - val_loss: 0.0387 - val_acc: 0.7660\n",
      "Epoch 792/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0391 - acc: 0.7586 - val_loss: 0.0386 - val_acc: 0.7662\n",
      "Epoch 793/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0390 - acc: 0.7589 - val_loss: 0.0386 - val_acc: 0.7665\n",
      "Epoch 794/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0390 - acc: 0.7592 - val_loss: 0.0385 - val_acc: 0.7669\n",
      "Epoch 795/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0389 - acc: 0.7594 - val_loss: 0.0385 - val_acc: 0.7669\n",
      "Epoch 796/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0389 - acc: 0.7598 - val_loss: 0.0384 - val_acc: 0.7675\n",
      "Epoch 797/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0388 - acc: 0.7601 - val_loss: 0.0384 - val_acc: 0.7680\n",
      "Epoch 798/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0388 - acc: 0.7603 - val_loss: 0.0383 - val_acc: 0.7682\n",
      "Epoch 799/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0387 - acc: 0.7607 - val_loss: 0.0383 - val_acc: 0.7685\n",
      "Epoch 800/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0387 - acc: 0.7609 - val_loss: 0.0382 - val_acc: 0.7686\n",
      "Epoch 801/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0386 - acc: 0.7613 - val_loss: 0.0382 - val_acc: 0.7688\n",
      "Epoch 802/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0385 - acc: 0.7615 - val_loss: 0.0381 - val_acc: 0.7691\n",
      "Epoch 803/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0385 - acc: 0.7617 - val_loss: 0.0381 - val_acc: 0.7695\n",
      "Epoch 804/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0384 - acc: 0.7620 - val_loss: 0.0380 - val_acc: 0.7696\n",
      "Epoch 805/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0384 - acc: 0.7621 - val_loss: 0.0380 - val_acc: 0.7700\n",
      "Epoch 806/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0383 - acc: 0.7622 - val_loss: 0.0379 - val_acc: 0.7701\n",
      "Epoch 807/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0383 - acc: 0.7624 - val_loss: 0.0379 - val_acc: 0.7706\n",
      "Epoch 808/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0382 - acc: 0.7627 - val_loss: 0.0378 - val_acc: 0.7711\n",
      "Epoch 809/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0382 - acc: 0.7630 - val_loss: 0.0378 - val_acc: 0.7713\n",
      "Epoch 810/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0382 - acc: 0.7634 - val_loss: 0.0377 - val_acc: 0.7716\n",
      "Epoch 811/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0381 - acc: 0.7637 - val_loss: 0.0377 - val_acc: 0.7720\n",
      "Epoch 812/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0381 - acc: 0.7638 - val_loss: 0.0376 - val_acc: 0.7720\n",
      "Epoch 813/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0380 - acc: 0.7641 - val_loss: 0.0376 - val_acc: 0.7722\n",
      "Epoch 814/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0380 - acc: 0.7645 - val_loss: 0.0375 - val_acc: 0.7724\n",
      "Epoch 815/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0379 - acc: 0.7648 - val_loss: 0.0375 - val_acc: 0.7724\n",
      "Epoch 816/2000\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0379 - acc: 0.7651 - val_loss: 0.0374 - val_acc: 0.7725\n",
      "Epoch 817/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0378 - acc: 0.7653 - val_loss: 0.0374 - val_acc: 0.7725\n",
      "Epoch 818/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0378 - acc: 0.7654 - val_loss: 0.0373 - val_acc: 0.7724\n",
      "Epoch 819/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0377 - acc: 0.7657 - val_loss: 0.0373 - val_acc: 0.7724\n",
      "Epoch 820/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0377 - acc: 0.7660 - val_loss: 0.0372 - val_acc: 0.7727\n",
      "Epoch 821/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0376 - acc: 0.7663 - val_loss: 0.0372 - val_acc: 0.7732\n",
      "Epoch 822/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0376 - acc: 0.7667 - val_loss: 0.0371 - val_acc: 0.7734\n",
      "Epoch 823/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0375 - acc: 0.7670 - val_loss: 0.0371 - val_acc: 0.7735\n",
      "Epoch 824/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0375 - acc: 0.7672 - val_loss: 0.0370 - val_acc: 0.7736\n",
      "Epoch 825/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0374 - acc: 0.7675 - val_loss: 0.0370 - val_acc: 0.7740\n",
      "Epoch 826/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0374 - acc: 0.7678 - val_loss: 0.0369 - val_acc: 0.7742\n",
      "Epoch 827/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0373 - acc: 0.7681 - val_loss: 0.0369 - val_acc: 0.7742\n",
      "Epoch 828/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0373 - acc: 0.7685 - val_loss: 0.0368 - val_acc: 0.7746\n",
      "Epoch 829/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0372 - acc: 0.7688 - val_loss: 0.0368 - val_acc: 0.7746\n",
      "Epoch 830/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0372 - acc: 0.7691 - val_loss: 0.0367 - val_acc: 0.7746\n",
      "Epoch 831/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0371 - acc: 0.7694 - val_loss: 0.0367 - val_acc: 0.7750\n",
      "Epoch 832/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0371 - acc: 0.7697 - val_loss: 0.0366 - val_acc: 0.7752\n",
      "Epoch 833/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0370 - acc: 0.7701 - val_loss: 0.0366 - val_acc: 0.7753\n",
      "Epoch 834/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0370 - acc: 0.7703 - val_loss: 0.0365 - val_acc: 0.7756\n",
      "Epoch 835/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0369 - acc: 0.7706 - val_loss: 0.0365 - val_acc: 0.7757\n",
      "Epoch 836/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0369 - acc: 0.7709 - val_loss: 0.0364 - val_acc: 0.7762\n",
      "Epoch 837/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0369 - acc: 0.7711 - val_loss: 0.0364 - val_acc: 0.7766\n",
      "Epoch 838/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0368 - acc: 0.7714 - val_loss: 0.0364 - val_acc: 0.7771\n",
      "Epoch 839/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0368 - acc: 0.7717 - val_loss: 0.0363 - val_acc: 0.7773\n",
      "Epoch 840/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0367 - acc: 0.7720 - val_loss: 0.0363 - val_acc: 0.7775\n",
      "Epoch 841/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0367 - acc: 0.7722 - val_loss: 0.0362 - val_acc: 0.7778\n",
      "Epoch 842/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0366 - acc: 0.7726 - val_loss: 0.0362 - val_acc: 0.7782\n",
      "Epoch 843/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0366 - acc: 0.7730 - val_loss: 0.0361 - val_acc: 0.7783\n",
      "Epoch 844/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0365 - acc: 0.7733 - val_loss: 0.0361 - val_acc: 0.7786\n",
      "Epoch 845/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0365 - acc: 0.7736 - val_loss: 0.0360 - val_acc: 0.7793\n",
      "Epoch 846/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0364 - acc: 0.7742 - val_loss: 0.0360 - val_acc: 0.7799\n",
      "Epoch 847/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0364 - acc: 0.7744 - val_loss: 0.0359 - val_acc: 0.7801\n",
      "Epoch 848/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0363 - acc: 0.7749 - val_loss: 0.0359 - val_acc: 0.7804\n",
      "Epoch 849/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0363 - acc: 0.7751 - val_loss: 0.0358 - val_acc: 0.7810\n",
      "Epoch 850/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0362 - acc: 0.7754 - val_loss: 0.0358 - val_acc: 0.7814\n",
      "Epoch 851/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0362 - acc: 0.7757 - val_loss: 0.0357 - val_acc: 0.7819\n",
      "Epoch 852/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0362 - acc: 0.7760 - val_loss: 0.0357 - val_acc: 0.7820\n",
      "Epoch 853/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0361 - acc: 0.7763 - val_loss: 0.0356 - val_acc: 0.7824\n",
      "Epoch 854/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0361 - acc: 0.7765 - val_loss: 0.0356 - val_acc: 0.7831\n",
      "Epoch 855/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0360 - acc: 0.7766 - val_loss: 0.0356 - val_acc: 0.7833\n",
      "Epoch 856/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0360 - acc: 0.7770 - val_loss: 0.0355 - val_acc: 0.7836\n",
      "Epoch 857/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0359 - acc: 0.7773 - val_loss: 0.0355 - val_acc: 0.7841\n",
      "Epoch 858/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0359 - acc: 0.7777 - val_loss: 0.0354 - val_acc: 0.7843\n",
      "Epoch 859/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0358 - acc: 0.7779 - val_loss: 0.0354 - val_acc: 0.7846\n",
      "Epoch 860/2000\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0358 - acc: 0.7783 - val_loss: 0.0353 - val_acc: 0.7852\n",
      "Epoch 861/2000\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0357 - acc: 0.7786 - val_loss: 0.0353 - val_acc: 0.7856\n",
      "Epoch 862/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0357 - acc: 0.7789 - val_loss: 0.0352 - val_acc: 0.7858\n",
      "Epoch 863/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0357 - acc: 0.7794 - val_loss: 0.0352 - val_acc: 0.7860\n",
      "Epoch 864/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0356 - acc: 0.7798 - val_loss: 0.0351 - val_acc: 0.7863\n",
      "Epoch 865/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0356 - acc: 0.7801 - val_loss: 0.0351 - val_acc: 0.7865\n",
      "Epoch 866/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0355 - acc: 0.7805 - val_loss: 0.0351 - val_acc: 0.7868\n",
      "Epoch 867/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0355 - acc: 0.7809 - val_loss: 0.0350 - val_acc: 0.7875\n",
      "Epoch 868/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0354 - acc: 0.7814 - val_loss: 0.0350 - val_acc: 0.7880\n",
      "Epoch 869/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0354 - acc: 0.7818 - val_loss: 0.0349 - val_acc: 0.7882\n",
      "Epoch 870/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0353 - acc: 0.7821 - val_loss: 0.0349 - val_acc: 0.7887\n",
      "Epoch 871/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0353 - acc: 0.7824 - val_loss: 0.0348 - val_acc: 0.7889\n",
      "Epoch 872/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0353 - acc: 0.7827 - val_loss: 0.0348 - val_acc: 0.7893\n",
      "Epoch 873/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0352 - acc: 0.7830 - val_loss: 0.0347 - val_acc: 0.7895\n",
      "Epoch 874/2000\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0352 - acc: 0.7833 - val_loss: 0.0347 - val_acc: 0.7897\n",
      "Epoch 875/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0351 - acc: 0.7836 - val_loss: 0.0347 - val_acc: 0.7903\n",
      "Epoch 876/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0351 - acc: 0.7839 - val_loss: 0.0346 - val_acc: 0.7906\n",
      "Epoch 877/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0350 - acc: 0.7842 - val_loss: 0.0346 - val_acc: 0.7908\n",
      "Epoch 878/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0350 - acc: 0.7847 - val_loss: 0.0345 - val_acc: 0.7910\n",
      "Epoch 879/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0350 - acc: 0.7850 - val_loss: 0.0345 - val_acc: 0.7913\n",
      "Epoch 880/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0349 - acc: 0.7853 - val_loss: 0.0344 - val_acc: 0.7915\n",
      "Epoch 881/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0349 - acc: 0.7856 - val_loss: 0.0344 - val_acc: 0.7920\n",
      "Epoch 882/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0348 - acc: 0.7861 - val_loss: 0.0343 - val_acc: 0.7926\n",
      "Epoch 883/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0348 - acc: 0.7864 - val_loss: 0.0343 - val_acc: 0.7926\n",
      "Epoch 884/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0347 - acc: 0.7867 - val_loss: 0.0343 - val_acc: 0.7928\n",
      "Epoch 885/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0347 - acc: 0.7871 - val_loss: 0.0342 - val_acc: 0.7929\n",
      "Epoch 886/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0347 - acc: 0.7874 - val_loss: 0.0342 - val_acc: 0.7935\n",
      "Epoch 887/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0346 - acc: 0.7877 - val_loss: 0.0341 - val_acc: 0.7943\n",
      "Epoch 888/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0346 - acc: 0.7882 - val_loss: 0.0341 - val_acc: 0.7946\n",
      "Epoch 889/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0345 - acc: 0.7885 - val_loss: 0.0340 - val_acc: 0.7952\n",
      "Epoch 890/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0345 - acc: 0.7890 - val_loss: 0.0340 - val_acc: 0.7955\n",
      "Epoch 891/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0344 - acc: 0.7892 - val_loss: 0.0340 - val_acc: 0.7961\n",
      "Epoch 892/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0344 - acc: 0.7897 - val_loss: 0.0339 - val_acc: 0.7963\n",
      "Epoch 893/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0344 - acc: 0.7901 - val_loss: 0.0339 - val_acc: 0.7964\n",
      "Epoch 894/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0343 - acc: 0.7906 - val_loss: 0.0338 - val_acc: 0.7967\n",
      "Epoch 895/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0343 - acc: 0.7909 - val_loss: 0.0338 - val_acc: 0.7972\n",
      "Epoch 896/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0342 - acc: 0.7914 - val_loss: 0.0337 - val_acc: 0.7978\n",
      "Epoch 897/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0342 - acc: 0.7917 - val_loss: 0.0337 - val_acc: 0.7981\n",
      "Epoch 898/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0341 - acc: 0.7922 - val_loss: 0.0336 - val_acc: 0.7985\n",
      "Epoch 899/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0341 - acc: 0.7927 - val_loss: 0.0336 - val_acc: 0.7989\n",
      "Epoch 900/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0341 - acc: 0.7930 - val_loss: 0.0336 - val_acc: 0.7992\n",
      "Epoch 901/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0340 - acc: 0.7936 - val_loss: 0.0335 - val_acc: 0.7996\n",
      "Epoch 902/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0340 - acc: 0.7941 - val_loss: 0.0335 - val_acc: 0.8000\n",
      "Epoch 903/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0339 - acc: 0.7944 - val_loss: 0.0334 - val_acc: 0.8006\n",
      "Epoch 904/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0339 - acc: 0.7948 - val_loss: 0.0334 - val_acc: 0.8012\n",
      "Epoch 905/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0338 - acc: 0.7952 - val_loss: 0.0334 - val_acc: 0.8015\n",
      "Epoch 906/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0338 - acc: 0.7957 - val_loss: 0.0333 - val_acc: 0.8016\n",
      "Epoch 907/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0338 - acc: 0.7960 - val_loss: 0.0333 - val_acc: 0.8018\n",
      "Epoch 908/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0337 - acc: 0.7964 - val_loss: 0.0332 - val_acc: 0.8024\n",
      "Epoch 909/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0337 - acc: 0.7966 - val_loss: 0.0332 - val_acc: 0.8031\n",
      "Epoch 910/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0336 - acc: 0.7970 - val_loss: 0.0331 - val_acc: 0.8037\n",
      "Epoch 911/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0336 - acc: 0.7973 - val_loss: 0.0331 - val_acc: 0.8042\n",
      "Epoch 912/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0336 - acc: 0.7976 - val_loss: 0.0331 - val_acc: 0.8046\n",
      "Epoch 913/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0335 - acc: 0.7978 - val_loss: 0.0330 - val_acc: 0.8049\n",
      "Epoch 914/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0335 - acc: 0.7983 - val_loss: 0.0330 - val_acc: 0.8053\n",
      "Epoch 915/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0334 - acc: 0.7985 - val_loss: 0.0329 - val_acc: 0.8059\n",
      "Epoch 916/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0334 - acc: 0.7988 - val_loss: 0.0329 - val_acc: 0.8064\n",
      "Epoch 917/2000\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0334 - acc: 0.7993 - val_loss: 0.0328 - val_acc: 0.8071\n",
      "Epoch 918/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0333 - acc: 0.7997 - val_loss: 0.0328 - val_acc: 0.8072\n",
      "Epoch 919/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0333 - acc: 0.8001 - val_loss: 0.0328 - val_acc: 0.8076\n",
      "Epoch 920/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0332 - acc: 0.8005 - val_loss: 0.0327 - val_acc: 0.8083\n",
      "Epoch 921/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0332 - acc: 0.8011 - val_loss: 0.0327 - val_acc: 0.8084\n",
      "Epoch 922/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0331 - acc: 0.8014 - val_loss: 0.0326 - val_acc: 0.8084\n",
      "Epoch 923/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0331 - acc: 0.8018 - val_loss: 0.0326 - val_acc: 0.8089\n",
      "Epoch 924/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0331 - acc: 0.8022 - val_loss: 0.0326 - val_acc: 0.8092\n",
      "Epoch 925/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0330 - acc: 0.8025 - val_loss: 0.0325 - val_acc: 0.8095\n",
      "Epoch 926/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0330 - acc: 0.8029 - val_loss: 0.0325 - val_acc: 0.8098\n",
      "Epoch 927/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0329 - acc: 0.8032 - val_loss: 0.0324 - val_acc: 0.8097\n",
      "Epoch 928/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0329 - acc: 0.8036 - val_loss: 0.0324 - val_acc: 0.8101\n",
      "Epoch 929/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0329 - acc: 0.8039 - val_loss: 0.0324 - val_acc: 0.8105\n",
      "Epoch 930/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0328 - acc: 0.8044 - val_loss: 0.0323 - val_acc: 0.8104\n",
      "Epoch 931/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0328 - acc: 0.8047 - val_loss: 0.0323 - val_acc: 0.8109\n",
      "Epoch 932/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0327 - acc: 0.8052 - val_loss: 0.0322 - val_acc: 0.8109\n",
      "Epoch 933/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0327 - acc: 0.8056 - val_loss: 0.0322 - val_acc: 0.8117\n",
      "Epoch 934/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0327 - acc: 0.8060 - val_loss: 0.0322 - val_acc: 0.8119\n",
      "Epoch 935/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0326 - acc: 0.8063 - val_loss: 0.0321 - val_acc: 0.8122\n",
      "Epoch 936/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0326 - acc: 0.8068 - val_loss: 0.0321 - val_acc: 0.8127\n",
      "Epoch 937/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0325 - acc: 0.8071 - val_loss: 0.0320 - val_acc: 0.8128\n",
      "Epoch 938/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0325 - acc: 0.8076 - val_loss: 0.0320 - val_acc: 0.8128\n",
      "Epoch 939/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0325 - acc: 0.8079 - val_loss: 0.0320 - val_acc: 0.8134\n",
      "Epoch 940/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0324 - acc: 0.8085 - val_loss: 0.0319 - val_acc: 0.8136\n",
      "Epoch 941/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0324 - acc: 0.8087 - val_loss: 0.0319 - val_acc: 0.8141\n",
      "Epoch 942/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0324 - acc: 0.8090 - val_loss: 0.0318 - val_acc: 0.8145\n",
      "Epoch 943/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0323 - acc: 0.8094 - val_loss: 0.0318 - val_acc: 0.8145\n",
      "Epoch 944/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0323 - acc: 0.8096 - val_loss: 0.0318 - val_acc: 0.8147\n",
      "Epoch 945/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0322 - acc: 0.8100 - val_loss: 0.0317 - val_acc: 0.8150\n",
      "Epoch 946/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0322 - acc: 0.8103 - val_loss: 0.0317 - val_acc: 0.8154\n",
      "Epoch 947/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0322 - acc: 0.8106 - val_loss: 0.0316 - val_acc: 0.8161\n",
      "Epoch 948/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0321 - acc: 0.8111 - val_loss: 0.0316 - val_acc: 0.8166\n",
      "Epoch 949/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0321 - acc: 0.8115 - val_loss: 0.0316 - val_acc: 0.8171\n",
      "Epoch 950/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0320 - acc: 0.8119 - val_loss: 0.0315 - val_acc: 0.8178\n",
      "Epoch 951/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0320 - acc: 0.8123 - val_loss: 0.0315 - val_acc: 0.8183\n",
      "Epoch 952/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0320 - acc: 0.8126 - val_loss: 0.0314 - val_acc: 0.8187\n",
      "Epoch 953/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0319 - acc: 0.8131 - val_loss: 0.0314 - val_acc: 0.8189\n",
      "Epoch 954/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0319 - acc: 0.8134 - val_loss: 0.0314 - val_acc: 0.8192\n",
      "Epoch 955/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0318 - acc: 0.8137 - val_loss: 0.0313 - val_acc: 0.8196\n",
      "Epoch 956/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0318 - acc: 0.8141 - val_loss: 0.0313 - val_acc: 0.8202\n",
      "Epoch 957/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0318 - acc: 0.8144 - val_loss: 0.0312 - val_acc: 0.8206\n",
      "Epoch 958/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0317 - acc: 0.8147 - val_loss: 0.0312 - val_acc: 0.8211\n",
      "Epoch 959/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0317 - acc: 0.8151 - val_loss: 0.0312 - val_acc: 0.8213\n",
      "Epoch 960/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0317 - acc: 0.8153 - val_loss: 0.0311 - val_acc: 0.8216\n",
      "Epoch 961/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0316 - acc: 0.8157 - val_loss: 0.0311 - val_acc: 0.8221\n",
      "Epoch 962/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0316 - acc: 0.8161 - val_loss: 0.0311 - val_acc: 0.8222\n",
      "Epoch 963/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0315 - acc: 0.8163 - val_loss: 0.0310 - val_acc: 0.8227\n",
      "Epoch 964/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0315 - acc: 0.8166 - val_loss: 0.0310 - val_acc: 0.8234\n",
      "Epoch 965/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0315 - acc: 0.8170 - val_loss: 0.0309 - val_acc: 0.8238\n",
      "Epoch 966/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0314 - acc: 0.8173 - val_loss: 0.0309 - val_acc: 0.8242\n",
      "Epoch 967/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0314 - acc: 0.8176 - val_loss: 0.0309 - val_acc: 0.8243\n",
      "Epoch 968/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0314 - acc: 0.8180 - val_loss: 0.0308 - val_acc: 0.8246\n",
      "Epoch 969/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0313 - acc: 0.8183 - val_loss: 0.0308 - val_acc: 0.8250\n",
      "Epoch 970/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0313 - acc: 0.8186 - val_loss: 0.0308 - val_acc: 0.8251\n",
      "Epoch 971/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0312 - acc: 0.8189 - val_loss: 0.0307 - val_acc: 0.8257\n",
      "Epoch 972/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0312 - acc: 0.8193 - val_loss: 0.0307 - val_acc: 0.8258\n",
      "Epoch 973/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0312 - acc: 0.8196 - val_loss: 0.0306 - val_acc: 0.8261\n",
      "Epoch 974/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0311 - acc: 0.8199 - val_loss: 0.0306 - val_acc: 0.8266\n",
      "Epoch 975/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0311 - acc: 0.8203 - val_loss: 0.0306 - val_acc: 0.8270\n",
      "Epoch 976/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0311 - acc: 0.8204 - val_loss: 0.0305 - val_acc: 0.8275\n",
      "Epoch 977/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0310 - acc: 0.8209 - val_loss: 0.0305 - val_acc: 0.8279\n",
      "Epoch 978/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0310 - acc: 0.8212 - val_loss: 0.0305 - val_acc: 0.8282\n",
      "Epoch 979/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0310 - acc: 0.8217 - val_loss: 0.0304 - val_acc: 0.8283\n",
      "Epoch 980/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0309 - acc: 0.8219 - val_loss: 0.0304 - val_acc: 0.8287\n",
      "Epoch 981/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0309 - acc: 0.8225 - val_loss: 0.0303 - val_acc: 0.8289\n",
      "Epoch 982/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0308 - acc: 0.8226 - val_loss: 0.0303 - val_acc: 0.8294\n",
      "Epoch 983/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0308 - acc: 0.8227 - val_loss: 0.0303 - val_acc: 0.8299\n",
      "Epoch 984/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0308 - acc: 0.8230 - val_loss: 0.0302 - val_acc: 0.8303\n",
      "Epoch 985/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0307 - acc: 0.8234 - val_loss: 0.0302 - val_acc: 0.8305\n",
      "Epoch 986/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0307 - acc: 0.8237 - val_loss: 0.0302 - val_acc: 0.8308\n",
      "Epoch 987/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0307 - acc: 0.8240 - val_loss: 0.0301 - val_acc: 0.8314\n",
      "Epoch 988/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0306 - acc: 0.8242 - val_loss: 0.0301 - val_acc: 0.8317\n",
      "Epoch 989/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0306 - acc: 0.8244 - val_loss: 0.0300 - val_acc: 0.8318\n",
      "Epoch 990/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0306 - acc: 0.8247 - val_loss: 0.0300 - val_acc: 0.8323\n",
      "Epoch 991/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0305 - acc: 0.8251 - val_loss: 0.0300 - val_acc: 0.8324\n",
      "Epoch 992/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0305 - acc: 0.8254 - val_loss: 0.0299 - val_acc: 0.8326\n",
      "Epoch 993/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0304 - acc: 0.8257 - val_loss: 0.0299 - val_acc: 0.8331\n",
      "Epoch 994/2000\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0304 - acc: 0.8260 - val_loss: 0.0299 - val_acc: 0.8333\n",
      "Epoch 995/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0304 - acc: 0.8262 - val_loss: 0.0298 - val_acc: 0.8336\n",
      "Epoch 996/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0303 - acc: 0.8266 - val_loss: 0.0298 - val_acc: 0.8341\n",
      "Epoch 997/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0303 - acc: 0.8271 - val_loss: 0.0298 - val_acc: 0.8346\n",
      "Epoch 998/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0303 - acc: 0.8275 - val_loss: 0.0297 - val_acc: 0.8350\n",
      "Epoch 999/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0302 - acc: 0.8278 - val_loss: 0.0297 - val_acc: 0.8359\n",
      "Epoch 1000/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0302 - acc: 0.8280 - val_loss: 0.0297 - val_acc: 0.8363\n",
      "Epoch 1001/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0302 - acc: 0.8283 - val_loss: 0.0296 - val_acc: 0.8367\n",
      "Epoch 1002/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0301 - acc: 0.8287 - val_loss: 0.0296 - val_acc: 0.8368\n",
      "Epoch 1003/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0301 - acc: 0.8289 - val_loss: 0.0295 - val_acc: 0.8373\n",
      "Epoch 1004/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0301 - acc: 0.8292 - val_loss: 0.0295 - val_acc: 0.8375\n",
      "Epoch 1005/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0300 - acc: 0.8296 - val_loss: 0.0295 - val_acc: 0.8378\n",
      "Epoch 1006/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0300 - acc: 0.8299 - val_loss: 0.0294 - val_acc: 0.8378\n",
      "Epoch 1007/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0300 - acc: 0.8302 - val_loss: 0.0294 - val_acc: 0.8384\n",
      "Epoch 1008/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0299 - acc: 0.8304 - val_loss: 0.0294 - val_acc: 0.8388\n",
      "Epoch 1009/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0299 - acc: 0.8307 - val_loss: 0.0293 - val_acc: 0.8389\n",
      "Epoch 1010/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0299 - acc: 0.8311 - val_loss: 0.0293 - val_acc: 0.8392\n",
      "Epoch 1011/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0298 - acc: 0.8313 - val_loss: 0.0293 - val_acc: 0.8393\n",
      "Epoch 1012/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0298 - acc: 0.8315 - val_loss: 0.0292 - val_acc: 0.8396\n",
      "Epoch 1013/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0298 - acc: 0.8319 - val_loss: 0.0292 - val_acc: 0.8402\n",
      "Epoch 1014/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0297 - acc: 0.8323 - val_loss: 0.0292 - val_acc: 0.8405\n",
      "Epoch 1015/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0297 - acc: 0.8325 - val_loss: 0.0291 - val_acc: 0.8406\n",
      "Epoch 1016/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0297 - acc: 0.8326 - val_loss: 0.0291 - val_acc: 0.8408\n",
      "Epoch 1017/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0296 - acc: 0.8330 - val_loss: 0.0291 - val_acc: 0.8408\n",
      "Epoch 1018/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0296 - acc: 0.8332 - val_loss: 0.0290 - val_acc: 0.8413\n",
      "Epoch 1019/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0295 - acc: 0.8335 - val_loss: 0.0290 - val_acc: 0.8413\n",
      "Epoch 1020/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0295 - acc: 0.8337 - val_loss: 0.0290 - val_acc: 0.8413\n",
      "Epoch 1021/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0295 - acc: 0.8340 - val_loss: 0.0289 - val_acc: 0.8416\n",
      "Epoch 1022/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0294 - acc: 0.8343 - val_loss: 0.0289 - val_acc: 0.8415\n",
      "Epoch 1023/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0294 - acc: 0.8346 - val_loss: 0.0289 - val_acc: 0.8419\n",
      "Epoch 1024/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0294 - acc: 0.8347 - val_loss: 0.0288 - val_acc: 0.8422\n",
      "Epoch 1025/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0293 - acc: 0.8351 - val_loss: 0.0288 - val_acc: 0.8424\n",
      "Epoch 1026/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0293 - acc: 0.8352 - val_loss: 0.0288 - val_acc: 0.8427\n",
      "Epoch 1027/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0293 - acc: 0.8354 - val_loss: 0.0287 - val_acc: 0.8433\n",
      "Epoch 1028/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0292 - acc: 0.8356 - val_loss: 0.0287 - val_acc: 0.8435\n",
      "Epoch 1029/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0292 - acc: 0.8358 - val_loss: 0.0287 - val_acc: 0.8434\n",
      "Epoch 1030/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0292 - acc: 0.8359 - val_loss: 0.0286 - val_acc: 0.8434\n",
      "Epoch 1031/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0291 - acc: 0.8361 - val_loss: 0.0286 - val_acc: 0.8437\n",
      "Epoch 1032/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0291 - acc: 0.8364 - val_loss: 0.0286 - val_acc: 0.8439\n",
      "Epoch 1033/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0291 - acc: 0.8365 - val_loss: 0.0285 - val_acc: 0.8443\n",
      "Epoch 1034/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0291 - acc: 0.8367 - val_loss: 0.0285 - val_acc: 0.8446\n",
      "Epoch 1035/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0290 - acc: 0.8370 - val_loss: 0.0285 - val_acc: 0.8446\n",
      "Epoch 1036/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0290 - acc: 0.8372 - val_loss: 0.0284 - val_acc: 0.8448\n",
      "Epoch 1037/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0290 - acc: 0.8374 - val_loss: 0.0284 - val_acc: 0.8455\n",
      "Epoch 1038/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0289 - acc: 0.8377 - val_loss: 0.0284 - val_acc: 0.8457\n",
      "Epoch 1039/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0289 - acc: 0.8379 - val_loss: 0.0283 - val_acc: 0.8461\n",
      "Epoch 1040/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0289 - acc: 0.8381 - val_loss: 0.0283 - val_acc: 0.8463\n",
      "Epoch 1041/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0288 - acc: 0.8383 - val_loss: 0.0283 - val_acc: 0.8466\n",
      "Epoch 1042/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0288 - acc: 0.8386 - val_loss: 0.0282 - val_acc: 0.8466\n",
      "Epoch 1043/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0288 - acc: 0.8390 - val_loss: 0.0282 - val_acc: 0.8468\n",
      "Epoch 1044/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0287 - acc: 0.8391 - val_loss: 0.0282 - val_acc: 0.8471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1045/2000\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0287 - acc: 0.8393 - val_loss: 0.0281 - val_acc: 0.8473\n",
      "Epoch 1046/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0287 - acc: 0.8395 - val_loss: 0.0281 - val_acc: 0.8476\n",
      "Epoch 1047/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0286 - acc: 0.8398 - val_loss: 0.0281 - val_acc: 0.8478\n",
      "Epoch 1048/2000\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0286 - acc: 0.8401 - val_loss: 0.0280 - val_acc: 0.8478\n",
      "Epoch 1049/2000\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0286 - acc: 0.8401 - val_loss: 0.0280 - val_acc: 0.8480\n",
      "Epoch 1050/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0285 - acc: 0.8403 - val_loss: 0.0280 - val_acc: 0.8481\n",
      "Epoch 1051/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0285 - acc: 0.8406 - val_loss: 0.0279 - val_acc: 0.8484\n",
      "Epoch 1052/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0285 - acc: 0.8408 - val_loss: 0.0279 - val_acc: 0.8487\n",
      "Epoch 1053/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0284 - acc: 0.8412 - val_loss: 0.0279 - val_acc: 0.8490\n",
      "Epoch 1054/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0284 - acc: 0.8414 - val_loss: 0.0278 - val_acc: 0.8492\n",
      "Epoch 1055/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0284 - acc: 0.8416 - val_loss: 0.0278 - val_acc: 0.8496\n",
      "Epoch 1056/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0283 - acc: 0.8419 - val_loss: 0.0278 - val_acc: 0.8501\n",
      "Epoch 1057/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0283 - acc: 0.8419 - val_loss: 0.0277 - val_acc: 0.8503\n",
      "Epoch 1058/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0283 - acc: 0.8421 - val_loss: 0.0277 - val_acc: 0.8505\n",
      "Epoch 1059/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0283 - acc: 0.8424 - val_loss: 0.0277 - val_acc: 0.8507\n",
      "Epoch 1060/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0282 - acc: 0.8424 - val_loss: 0.0276 - val_acc: 0.8511\n",
      "Epoch 1061/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0282 - acc: 0.8425 - val_loss: 0.0276 - val_acc: 0.8517\n",
      "Epoch 1062/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0282 - acc: 0.8428 - val_loss: 0.0276 - val_acc: 0.8519\n",
      "Epoch 1063/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0281 - acc: 0.8429 - val_loss: 0.0276 - val_acc: 0.8522\n",
      "Epoch 1064/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0281 - acc: 0.8432 - val_loss: 0.0275 - val_acc: 0.8522\n",
      "Epoch 1065/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0281 - acc: 0.8434 - val_loss: 0.0275 - val_acc: 0.8527\n",
      "Epoch 1066/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0280 - acc: 0.8436 - val_loss: 0.0275 - val_acc: 0.8527\n",
      "Epoch 1067/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0280 - acc: 0.8438 - val_loss: 0.0274 - val_acc: 0.8529\n",
      "Epoch 1068/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0280 - acc: 0.8441 - val_loss: 0.0274 - val_acc: 0.8531\n",
      "Epoch 1069/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0280 - acc: 0.8442 - val_loss: 0.0274 - val_acc: 0.8535\n",
      "Epoch 1070/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0279 - acc: 0.8445 - val_loss: 0.0273 - val_acc: 0.8536\n",
      "Epoch 1071/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0279 - acc: 0.8445 - val_loss: 0.0273 - val_acc: 0.8538\n",
      "Epoch 1072/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0279 - acc: 0.8449 - val_loss: 0.0273 - val_acc: 0.8539\n",
      "Epoch 1073/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0278 - acc: 0.8449 - val_loss: 0.0272 - val_acc: 0.8539\n",
      "Epoch 1074/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0278 - acc: 0.8452 - val_loss: 0.0272 - val_acc: 0.8538\n",
      "Epoch 1075/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0278 - acc: 0.8453 - val_loss: 0.0272 - val_acc: 0.8541\n",
      "Epoch 1076/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0277 - acc: 0.8453 - val_loss: 0.0272 - val_acc: 0.8542\n",
      "Epoch 1077/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0277 - acc: 0.8455 - val_loss: 0.0271 - val_acc: 0.8545\n",
      "Epoch 1078/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0277 - acc: 0.8457 - val_loss: 0.0271 - val_acc: 0.8551\n",
      "Epoch 1079/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0277 - acc: 0.8457 - val_loss: 0.0271 - val_acc: 0.8552\n",
      "Epoch 1080/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0276 - acc: 0.8460 - val_loss: 0.0270 - val_acc: 0.8556\n",
      "Epoch 1081/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0276 - acc: 0.8462 - val_loss: 0.0270 - val_acc: 0.8559\n",
      "Epoch 1082/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0276 - acc: 0.8464 - val_loss: 0.0270 - val_acc: 0.8560\n",
      "Epoch 1083/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0275 - acc: 0.8465 - val_loss: 0.0269 - val_acc: 0.8563\n",
      "Epoch 1084/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0275 - acc: 0.8467 - val_loss: 0.0269 - val_acc: 0.8564\n",
      "Epoch 1085/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0275 - acc: 0.8468 - val_loss: 0.0269 - val_acc: 0.8568\n",
      "Epoch 1086/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0274 - acc: 0.8470 - val_loss: 0.0269 - val_acc: 0.8570\n",
      "Epoch 1087/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0274 - acc: 0.8474 - val_loss: 0.0268 - val_acc: 0.8569\n",
      "Epoch 1088/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0274 - acc: 0.8476 - val_loss: 0.0268 - val_acc: 0.8569\n",
      "Epoch 1089/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0274 - acc: 0.8478 - val_loss: 0.0268 - val_acc: 0.8569\n",
      "Epoch 1090/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0273 - acc: 0.8481 - val_loss: 0.0267 - val_acc: 0.8569\n",
      "Epoch 1091/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0273 - acc: 0.8482 - val_loss: 0.0267 - val_acc: 0.8571\n",
      "Epoch 1092/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0273 - acc: 0.8483 - val_loss: 0.0267 - val_acc: 0.8571\n",
      "Epoch 1093/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0272 - acc: 0.8484 - val_loss: 0.0266 - val_acc: 0.8576\n",
      "Epoch 1094/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0272 - acc: 0.8486 - val_loss: 0.0266 - val_acc: 0.8580\n",
      "Epoch 1095/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0272 - acc: 0.8488 - val_loss: 0.0266 - val_acc: 0.8581\n",
      "Epoch 1096/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0272 - acc: 0.8489 - val_loss: 0.0266 - val_acc: 0.8583\n",
      "Epoch 1097/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0271 - acc: 0.8491 - val_loss: 0.0265 - val_acc: 0.8589\n",
      "Epoch 1098/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0271 - acc: 0.8493 - val_loss: 0.0265 - val_acc: 0.8589\n",
      "Epoch 1099/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0271 - acc: 0.8495 - val_loss: 0.0265 - val_acc: 0.8591\n",
      "Epoch 1100/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0270 - acc: 0.8497 - val_loss: 0.0264 - val_acc: 0.8592\n",
      "Epoch 1101/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0270 - acc: 0.8499 - val_loss: 0.0264 - val_acc: 0.8595\n",
      "Epoch 1102/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0270 - acc: 0.8499 - val_loss: 0.0264 - val_acc: 0.8600\n",
      "Epoch 1103/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0270 - acc: 0.8503 - val_loss: 0.0264 - val_acc: 0.8598\n",
      "Epoch 1104/2000\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0269 - acc: 0.8504 - val_loss: 0.0263 - val_acc: 0.8600\n",
      "Epoch 1105/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0269 - acc: 0.8506 - val_loss: 0.0263 - val_acc: 0.8601\n",
      "Epoch 1106/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0269 - acc: 0.8507 - val_loss: 0.0263 - val_acc: 0.8600\n",
      "Epoch 1107/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0268 - acc: 0.8509 - val_loss: 0.0262 - val_acc: 0.8599\n",
      "Epoch 1108/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0268 - acc: 0.8510 - val_loss: 0.0262 - val_acc: 0.8598\n",
      "Epoch 1109/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0268 - acc: 0.8514 - val_loss: 0.0262 - val_acc: 0.8599\n",
      "Epoch 1110/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0268 - acc: 0.8515 - val_loss: 0.0262 - val_acc: 0.8602\n",
      "Epoch 1111/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0267 - acc: 0.8516 - val_loss: 0.0261 - val_acc: 0.8602\n",
      "Epoch 1112/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0267 - acc: 0.8517 - val_loss: 0.0261 - val_acc: 0.8606\n",
      "Epoch 1113/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0267 - acc: 0.8520 - val_loss: 0.0261 - val_acc: 0.8606\n",
      "Epoch 1114/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0267 - acc: 0.8520 - val_loss: 0.0261 - val_acc: 0.8609\n",
      "Epoch 1115/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0266 - acc: 0.8522 - val_loss: 0.0260 - val_acc: 0.8613\n",
      "Epoch 1116/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0266 - acc: 0.8523 - val_loss: 0.0260 - val_acc: 0.8616\n",
      "Epoch 1117/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0266 - acc: 0.8524 - val_loss: 0.0260 - val_acc: 0.8616\n",
      "Epoch 1118/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0265 - acc: 0.8526 - val_loss: 0.0259 - val_acc: 0.8617\n",
      "Epoch 1119/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0265 - acc: 0.8527 - val_loss: 0.0259 - val_acc: 0.8617\n",
      "Epoch 1120/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0265 - acc: 0.8528 - val_loss: 0.0259 - val_acc: 0.8617\n",
      "Epoch 1121/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0265 - acc: 0.8530 - val_loss: 0.0259 - val_acc: 0.8618\n",
      "Epoch 1122/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0264 - acc: 0.8532 - val_loss: 0.0258 - val_acc: 0.8620\n",
      "Epoch 1123/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0264 - acc: 0.8534 - val_loss: 0.0258 - val_acc: 0.8619\n",
      "Epoch 1124/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0264 - acc: 0.8535 - val_loss: 0.0258 - val_acc: 0.8620\n",
      "Epoch 1125/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0264 - acc: 0.8537 - val_loss: 0.0257 - val_acc: 0.8621\n",
      "Epoch 1126/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0263 - acc: 0.8538 - val_loss: 0.0257 - val_acc: 0.8622\n",
      "Epoch 1127/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0263 - acc: 0.8540 - val_loss: 0.0257 - val_acc: 0.8623\n",
      "Epoch 1128/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0263 - acc: 0.8541 - val_loss: 0.0257 - val_acc: 0.8624\n",
      "Epoch 1129/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0263 - acc: 0.8543 - val_loss: 0.0256 - val_acc: 0.8626\n",
      "Epoch 1130/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0262 - acc: 0.8544 - val_loss: 0.0256 - val_acc: 0.8626\n",
      "Epoch 1131/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0262 - acc: 0.8545 - val_loss: 0.0256 - val_acc: 0.8627\n",
      "Epoch 1132/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0262 - acc: 0.8547 - val_loss: 0.0256 - val_acc: 0.8629\n",
      "Epoch 1133/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0261 - acc: 0.8549 - val_loss: 0.0255 - val_acc: 0.8631\n",
      "Epoch 1134/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0261 - acc: 0.8552 - val_loss: 0.0255 - val_acc: 0.8632\n",
      "Epoch 1135/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0261 - acc: 0.8553 - val_loss: 0.0255 - val_acc: 0.8635\n",
      "Epoch 1136/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0261 - acc: 0.8555 - val_loss: 0.0255 - val_acc: 0.8638\n",
      "Epoch 1137/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0260 - acc: 0.8556 - val_loss: 0.0254 - val_acc: 0.8638\n",
      "Epoch 1138/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0260 - acc: 0.8557 - val_loss: 0.0254 - val_acc: 0.8639\n",
      "Epoch 1139/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0260 - acc: 0.8558 - val_loss: 0.0254 - val_acc: 0.8640\n",
      "Epoch 1140/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0260 - acc: 0.8560 - val_loss: 0.0253 - val_acc: 0.8641\n",
      "Epoch 1141/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0259 - acc: 0.8561 - val_loss: 0.0253 - val_acc: 0.8641\n",
      "Epoch 1142/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0259 - acc: 0.8562 - val_loss: 0.0253 - val_acc: 0.8643\n",
      "Epoch 1143/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0259 - acc: 0.8563 - val_loss: 0.0253 - val_acc: 0.8643\n",
      "Epoch 1144/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0259 - acc: 0.8565 - val_loss: 0.0252 - val_acc: 0.8645\n",
      "Epoch 1145/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0258 - acc: 0.8567 - val_loss: 0.0252 - val_acc: 0.8645\n",
      "Epoch 1146/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0258 - acc: 0.8567 - val_loss: 0.0252 - val_acc: 0.8646\n",
      "Epoch 1147/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0258 - acc: 0.8570 - val_loss: 0.0252 - val_acc: 0.8647\n",
      "Epoch 1148/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0258 - acc: 0.8572 - val_loss: 0.0251 - val_acc: 0.8649\n",
      "Epoch 1149/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0257 - acc: 0.8572 - val_loss: 0.0251 - val_acc: 0.8650\n",
      "Epoch 1150/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0257 - acc: 0.8574 - val_loss: 0.0251 - val_acc: 0.8650\n",
      "Epoch 1151/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0257 - acc: 0.8575 - val_loss: 0.0251 - val_acc: 0.8651\n",
      "Epoch 1152/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0257 - acc: 0.8577 - val_loss: 0.0250 - val_acc: 0.8652\n",
      "Epoch 1153/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0256 - acc: 0.8579 - val_loss: 0.0250 - val_acc: 0.8653\n",
      "Epoch 1154/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0256 - acc: 0.8579 - val_loss: 0.0250 - val_acc: 0.8655\n",
      "Epoch 1155/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0256 - acc: 0.8582 - val_loss: 0.0250 - val_acc: 0.8656\n",
      "Epoch 1156/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0256 - acc: 0.8582 - val_loss: 0.0249 - val_acc: 0.8657\n",
      "Epoch 1157/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0255 - acc: 0.8584 - val_loss: 0.0249 - val_acc: 0.8657\n",
      "Epoch 1158/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0255 - acc: 0.8586 - val_loss: 0.0249 - val_acc: 0.8659\n",
      "Epoch 1159/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0255 - acc: 0.8587 - val_loss: 0.0249 - val_acc: 0.8661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1160/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0255 - acc: 0.8589 - val_loss: 0.0248 - val_acc: 0.8660\n",
      "Epoch 1161/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0254 - acc: 0.8591 - val_loss: 0.0248 - val_acc: 0.8662\n",
      "Epoch 1162/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0254 - acc: 0.8592 - val_loss: 0.0248 - val_acc: 0.8663\n",
      "Epoch 1163/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0254 - acc: 0.8592 - val_loss: 0.0248 - val_acc: 0.8666\n",
      "Epoch 1164/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0254 - acc: 0.8594 - val_loss: 0.0247 - val_acc: 0.8668\n",
      "Epoch 1165/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0253 - acc: 0.8596 - val_loss: 0.0247 - val_acc: 0.8670\n",
      "Epoch 1166/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0253 - acc: 0.8597 - val_loss: 0.0247 - val_acc: 0.8669\n",
      "Epoch 1167/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0253 - acc: 0.8599 - val_loss: 0.0247 - val_acc: 0.8671\n",
      "Epoch 1168/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0253 - acc: 0.8600 - val_loss: 0.0246 - val_acc: 0.8671\n",
      "Epoch 1169/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0252 - acc: 0.8600 - val_loss: 0.0246 - val_acc: 0.8671\n",
      "Epoch 1170/2000\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0252 - acc: 0.8602 - val_loss: 0.0246 - val_acc: 0.8671\n",
      "Epoch 1171/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0252 - acc: 0.8603 - val_loss: 0.0246 - val_acc: 0.8673\n",
      "Epoch 1172/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0252 - acc: 0.8604 - val_loss: 0.0245 - val_acc: 0.8673\n",
      "Epoch 1173/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0251 - acc: 0.8605 - val_loss: 0.0245 - val_acc: 0.8674\n",
      "Epoch 1174/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0251 - acc: 0.8606 - val_loss: 0.0245 - val_acc: 0.8677\n",
      "Epoch 1175/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0251 - acc: 0.8607 - val_loss: 0.0245 - val_acc: 0.8679\n",
      "Epoch 1176/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0251 - acc: 0.8607 - val_loss: 0.0244 - val_acc: 0.8681\n",
      "Epoch 1177/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0250 - acc: 0.8608 - val_loss: 0.0244 - val_acc: 0.8682\n",
      "Epoch 1178/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0250 - acc: 0.8609 - val_loss: 0.0244 - val_acc: 0.8686\n",
      "Epoch 1179/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0250 - acc: 0.8611 - val_loss: 0.0244 - val_acc: 0.8687\n",
      "Epoch 1180/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0250 - acc: 0.8612 - val_loss: 0.0243 - val_acc: 0.8687\n",
      "Epoch 1181/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0250 - acc: 0.8614 - val_loss: 0.0243 - val_acc: 0.8690\n",
      "Epoch 1182/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0249 - acc: 0.8616 - val_loss: 0.0243 - val_acc: 0.8693\n",
      "Epoch 1183/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0249 - acc: 0.8616 - val_loss: 0.0243 - val_acc: 0.8694\n",
      "Epoch 1184/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0249 - acc: 0.8616 - val_loss: 0.0243 - val_acc: 0.8696\n",
      "Epoch 1185/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0249 - acc: 0.8617 - val_loss: 0.0242 - val_acc: 0.8698\n",
      "Epoch 1186/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0248 - acc: 0.8619 - val_loss: 0.0242 - val_acc: 0.8699\n",
      "Epoch 1187/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0248 - acc: 0.8620 - val_loss: 0.0242 - val_acc: 0.8700\n",
      "Epoch 1188/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0248 - acc: 0.8622 - val_loss: 0.0242 - val_acc: 0.8702\n",
      "Epoch 1189/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0248 - acc: 0.8622 - val_loss: 0.0241 - val_acc: 0.8702\n",
      "Epoch 1190/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0247 - acc: 0.8624 - val_loss: 0.0241 - val_acc: 0.8704\n",
      "Epoch 1191/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0247 - acc: 0.8626 - val_loss: 0.0241 - val_acc: 0.8705\n",
      "Epoch 1192/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0247 - acc: 0.8626 - val_loss: 0.0241 - val_acc: 0.8706\n",
      "Epoch 1193/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0247 - acc: 0.8628 - val_loss: 0.0240 - val_acc: 0.8710\n",
      "Epoch 1194/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0247 - acc: 0.8629 - val_loss: 0.0240 - val_acc: 0.8711\n",
      "Epoch 1195/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0246 - acc: 0.8630 - val_loss: 0.0240 - val_acc: 0.8714\n",
      "Epoch 1196/2000\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0246 - acc: 0.8631 - val_loss: 0.0240 - val_acc: 0.8716\n",
      "Epoch 1197/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0246 - acc: 0.8633 - val_loss: 0.0239 - val_acc: 0.8716\n",
      "Epoch 1198/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0246 - acc: 0.8634 - val_loss: 0.0239 - val_acc: 0.8714\n",
      "Epoch 1199/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0245 - acc: 0.8634 - val_loss: 0.0239 - val_acc: 0.8715\n",
      "Epoch 1200/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0245 - acc: 0.8636 - val_loss: 0.0239 - val_acc: 0.8716\n",
      "Epoch 1201/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0245 - acc: 0.8636 - val_loss: 0.0239 - val_acc: 0.8717\n",
      "Epoch 1202/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0245 - acc: 0.8636 - val_loss: 0.0238 - val_acc: 0.8717\n",
      "Epoch 1203/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0244 - acc: 0.8637 - val_loss: 0.0238 - val_acc: 0.8721\n",
      "Epoch 1204/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0244 - acc: 0.8639 - val_loss: 0.0238 - val_acc: 0.8723\n",
      "Epoch 1205/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0244 - acc: 0.8641 - val_loss: 0.0238 - val_acc: 0.8725\n",
      "Epoch 1206/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0244 - acc: 0.8641 - val_loss: 0.0237 - val_acc: 0.8727\n",
      "Epoch 1207/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0244 - acc: 0.8644 - val_loss: 0.0237 - val_acc: 0.8727\n",
      "Epoch 1208/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0243 - acc: 0.8645 - val_loss: 0.0237 - val_acc: 0.8728\n",
      "Epoch 1209/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0243 - acc: 0.8645 - val_loss: 0.0237 - val_acc: 0.8729\n",
      "Epoch 1210/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0243 - acc: 0.8646 - val_loss: 0.0237 - val_acc: 0.8729\n",
      "Epoch 1211/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0243 - acc: 0.8648 - val_loss: 0.0236 - val_acc: 0.8730\n",
      "Epoch 1212/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0242 - acc: 0.8648 - val_loss: 0.0236 - val_acc: 0.8731\n",
      "Epoch 1213/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0242 - acc: 0.8649 - val_loss: 0.0236 - val_acc: 0.8732\n",
      "Epoch 1214/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0242 - acc: 0.8650 - val_loss: 0.0236 - val_acc: 0.8731\n",
      "Epoch 1215/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0242 - acc: 0.8651 - val_loss: 0.0235 - val_acc: 0.8732\n",
      "Epoch 1216/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0242 - acc: 0.8652 - val_loss: 0.0235 - val_acc: 0.8733\n",
      "Epoch 1217/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0241 - acc: 0.8652 - val_loss: 0.0235 - val_acc: 0.8734\n",
      "Epoch 1218/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0241 - acc: 0.8653 - val_loss: 0.0235 - val_acc: 0.8733\n",
      "Epoch 1219/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0241 - acc: 0.8654 - val_loss: 0.0235 - val_acc: 0.8733\n",
      "Epoch 1220/2000\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0241 - acc: 0.8656 - val_loss: 0.0234 - val_acc: 0.8733\n",
      "Epoch 1221/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0240 - acc: 0.8657 - val_loss: 0.0234 - val_acc: 0.8735\n",
      "Epoch 1222/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0240 - acc: 0.8657 - val_loss: 0.0234 - val_acc: 0.8735\n",
      "Epoch 1223/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0240 - acc: 0.8658 - val_loss: 0.0234 - val_acc: 0.8737\n",
      "Epoch 1224/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0240 - acc: 0.8660 - val_loss: 0.0233 - val_acc: 0.8737\n",
      "Epoch 1225/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0240 - acc: 0.8661 - val_loss: 0.0233 - val_acc: 0.8738\n",
      "Epoch 1226/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0239 - acc: 0.8662 - val_loss: 0.0233 - val_acc: 0.8740\n",
      "Epoch 1227/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0239 - acc: 0.8663 - val_loss: 0.0233 - val_acc: 0.8742\n",
      "Epoch 1228/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0239 - acc: 0.8665 - val_loss: 0.0233 - val_acc: 0.8742\n",
      "Epoch 1229/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0239 - acc: 0.8665 - val_loss: 0.0232 - val_acc: 0.8741\n",
      "Epoch 1230/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0239 - acc: 0.8666 - val_loss: 0.0232 - val_acc: 0.8742\n",
      "Epoch 1231/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0238 - acc: 0.8666 - val_loss: 0.0232 - val_acc: 0.8743\n",
      "Epoch 1232/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0238 - acc: 0.8667 - val_loss: 0.0232 - val_acc: 0.8743\n",
      "Epoch 1233/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0238 - acc: 0.8668 - val_loss: 0.0231 - val_acc: 0.8746\n",
      "Epoch 1234/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0238 - acc: 0.8669 - val_loss: 0.0231 - val_acc: 0.8748\n",
      "Epoch 1235/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0238 - acc: 0.8671 - val_loss: 0.0231 - val_acc: 0.8747\n",
      "Epoch 1236/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0237 - acc: 0.8671 - val_loss: 0.0231 - val_acc: 0.8748\n",
      "Epoch 1237/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0237 - acc: 0.8671 - val_loss: 0.0231 - val_acc: 0.8748\n",
      "Epoch 1238/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0237 - acc: 0.8674 - val_loss: 0.0230 - val_acc: 0.8752\n",
      "Epoch 1239/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0237 - acc: 0.8675 - val_loss: 0.0230 - val_acc: 0.8754\n",
      "Epoch 1240/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0236 - acc: 0.8675 - val_loss: 0.0230 - val_acc: 0.8754\n",
      "Epoch 1241/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0236 - acc: 0.8677 - val_loss: 0.0230 - val_acc: 0.8756\n",
      "Epoch 1242/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0236 - acc: 0.8678 - val_loss: 0.0230 - val_acc: 0.8756\n",
      "Epoch 1243/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0236 - acc: 0.8679 - val_loss: 0.0229 - val_acc: 0.8756\n",
      "Epoch 1244/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0236 - acc: 0.8681 - val_loss: 0.0229 - val_acc: 0.8756\n",
      "Epoch 1245/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0235 - acc: 0.8681 - val_loss: 0.0229 - val_acc: 0.8757\n",
      "Epoch 1246/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0235 - acc: 0.8682 - val_loss: 0.0229 - val_acc: 0.8758\n",
      "Epoch 1247/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0235 - acc: 0.8682 - val_loss: 0.0229 - val_acc: 0.8759\n",
      "Epoch 1248/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0235 - acc: 0.8682 - val_loss: 0.0228 - val_acc: 0.8760\n",
      "Epoch 1249/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0235 - acc: 0.8683 - val_loss: 0.0228 - val_acc: 0.8761\n",
      "Epoch 1250/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0234 - acc: 0.8683 - val_loss: 0.0228 - val_acc: 0.8761\n",
      "Epoch 1251/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0234 - acc: 0.8685 - val_loss: 0.0228 - val_acc: 0.8763\n",
      "Epoch 1252/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0234 - acc: 0.8686 - val_loss: 0.0228 - val_acc: 0.8765\n",
      "Epoch 1253/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0234 - acc: 0.8686 - val_loss: 0.0227 - val_acc: 0.8768\n",
      "Epoch 1254/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0234 - acc: 0.8688 - val_loss: 0.0227 - val_acc: 0.8769\n",
      "Epoch 1255/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0233 - acc: 0.8688 - val_loss: 0.0227 - val_acc: 0.8770\n",
      "Epoch 1256/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0233 - acc: 0.8689 - val_loss: 0.0227 - val_acc: 0.8771\n",
      "Epoch 1257/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0233 - acc: 0.8689 - val_loss: 0.0227 - val_acc: 0.8771\n",
      "Epoch 1258/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0233 - acc: 0.8691 - val_loss: 0.0226 - val_acc: 0.8771\n",
      "Epoch 1259/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0233 - acc: 0.8692 - val_loss: 0.0226 - val_acc: 0.8771\n",
      "Epoch 1260/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0232 - acc: 0.8692 - val_loss: 0.0226 - val_acc: 0.8771\n",
      "Epoch 1261/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0232 - acc: 0.8693 - val_loss: 0.0226 - val_acc: 0.8771\n",
      "Epoch 1262/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0232 - acc: 0.8694 - val_loss: 0.0226 - val_acc: 0.8771\n",
      "Epoch 1263/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0232 - acc: 0.8694 - val_loss: 0.0225 - val_acc: 0.8773\n",
      "Epoch 1264/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0232 - acc: 0.8695 - val_loss: 0.0225 - val_acc: 0.8775\n",
      "Epoch 1265/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0231 - acc: 0.8697 - val_loss: 0.0225 - val_acc: 0.8777\n",
      "Epoch 1266/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0231 - acc: 0.8696 - val_loss: 0.0225 - val_acc: 0.8778\n",
      "Epoch 1267/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0231 - acc: 0.8698 - val_loss: 0.0225 - val_acc: 0.8780\n",
      "Epoch 1268/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0231 - acc: 0.8699 - val_loss: 0.0224 - val_acc: 0.8782\n",
      "Epoch 1269/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0231 - acc: 0.8701 - val_loss: 0.0224 - val_acc: 0.8784\n",
      "Epoch 1270/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0230 - acc: 0.8701 - val_loss: 0.0224 - val_acc: 0.8785\n",
      "Epoch 1271/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0230 - acc: 0.8703 - val_loss: 0.0224 - val_acc: 0.8785\n",
      "Epoch 1272/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0230 - acc: 0.8703 - val_loss: 0.0224 - val_acc: 0.8783\n",
      "Epoch 1273/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0230 - acc: 0.8704 - val_loss: 0.0223 - val_acc: 0.8783\n",
      "Epoch 1274/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0230 - acc: 0.8705 - val_loss: 0.0223 - val_acc: 0.8784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1275/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0229 - acc: 0.8706 - val_loss: 0.0223 - val_acc: 0.8784\n",
      "Epoch 1276/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0229 - acc: 0.8707 - val_loss: 0.0223 - val_acc: 0.8784\n",
      "Epoch 1277/2000\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0229 - acc: 0.8707 - val_loss: 0.0223 - val_acc: 0.8784\n",
      "Epoch 1278/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0229 - acc: 0.8708 - val_loss: 0.0222 - val_acc: 0.8785\n",
      "Epoch 1279/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0229 - acc: 0.8710 - val_loss: 0.0222 - val_acc: 0.8785\n",
      "Epoch 1280/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0229 - acc: 0.8710 - val_loss: 0.0222 - val_acc: 0.8786\n",
      "Epoch 1281/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0228 - acc: 0.8712 - val_loss: 0.0222 - val_acc: 0.8788\n",
      "Epoch 1282/2000\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0228 - acc: 0.8713 - val_loss: 0.0222 - val_acc: 0.8788\n",
      "Epoch 1283/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0228 - acc: 0.8714 - val_loss: 0.0221 - val_acc: 0.8788\n",
      "Epoch 1284/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0228 - acc: 0.8715 - val_loss: 0.0221 - val_acc: 0.8788\n",
      "Epoch 1285/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0228 - acc: 0.8716 - val_loss: 0.0221 - val_acc: 0.8789\n",
      "Epoch 1286/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0227 - acc: 0.8716 - val_loss: 0.0221 - val_acc: 0.8789\n",
      "Epoch 1287/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0227 - acc: 0.8717 - val_loss: 0.0221 - val_acc: 0.8789\n",
      "Epoch 1288/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0227 - acc: 0.8718 - val_loss: 0.0220 - val_acc: 0.8790\n",
      "Epoch 1289/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0227 - acc: 0.8720 - val_loss: 0.0220 - val_acc: 0.8790\n",
      "Epoch 1290/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0227 - acc: 0.8721 - val_loss: 0.0220 - val_acc: 0.8790\n",
      "Epoch 1291/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0226 - acc: 0.8722 - val_loss: 0.0220 - val_acc: 0.8791\n",
      "Epoch 1292/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0226 - acc: 0.8723 - val_loss: 0.0220 - val_acc: 0.8791\n",
      "Epoch 1293/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0226 - acc: 0.8724 - val_loss: 0.0220 - val_acc: 0.8790\n",
      "Epoch 1294/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0226 - acc: 0.8725 - val_loss: 0.0219 - val_acc: 0.8793\n",
      "Epoch 1295/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0226 - acc: 0.8726 - val_loss: 0.0219 - val_acc: 0.8794\n",
      "Epoch 1296/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0226 - acc: 0.8726 - val_loss: 0.0219 - val_acc: 0.8796\n",
      "Epoch 1297/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0225 - acc: 0.8727 - val_loss: 0.0219 - val_acc: 0.8797\n",
      "Epoch 1298/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0225 - acc: 0.8728 - val_loss: 0.0219 - val_acc: 0.8797\n",
      "Epoch 1299/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0225 - acc: 0.8728 - val_loss: 0.0218 - val_acc: 0.8798\n",
      "Epoch 1300/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0225 - acc: 0.8730 - val_loss: 0.0218 - val_acc: 0.8798\n",
      "Epoch 1301/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0225 - acc: 0.8730 - val_loss: 0.0218 - val_acc: 0.8799\n",
      "Epoch 1302/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0224 - acc: 0.8731 - val_loss: 0.0218 - val_acc: 0.8800\n",
      "Epoch 1303/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0224 - acc: 0.8732 - val_loss: 0.0218 - val_acc: 0.8800\n",
      "Epoch 1304/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0224 - acc: 0.8733 - val_loss: 0.0218 - val_acc: 0.8801\n",
      "Epoch 1305/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0224 - acc: 0.8734 - val_loss: 0.0217 - val_acc: 0.8800\n",
      "Epoch 1306/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0224 - acc: 0.8736 - val_loss: 0.0217 - val_acc: 0.8800\n",
      "Epoch 1307/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0224 - acc: 0.8736 - val_loss: 0.0217 - val_acc: 0.8799\n",
      "Epoch 1308/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0223 - acc: 0.8737 - val_loss: 0.0217 - val_acc: 0.8799\n",
      "Epoch 1309/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0223 - acc: 0.8738 - val_loss: 0.0217 - val_acc: 0.8800\n",
      "Epoch 1310/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0223 - acc: 0.8739 - val_loss: 0.0216 - val_acc: 0.8801\n",
      "Epoch 1311/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0223 - acc: 0.8739 - val_loss: 0.0216 - val_acc: 0.8803\n",
      "Epoch 1312/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0223 - acc: 0.8741 - val_loss: 0.0216 - val_acc: 0.8805\n",
      "Epoch 1313/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0222 - acc: 0.8742 - val_loss: 0.0216 - val_acc: 0.8807\n",
      "Epoch 1314/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0222 - acc: 0.8742 - val_loss: 0.0216 - val_acc: 0.8806\n",
      "Epoch 1315/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0222 - acc: 0.8743 - val_loss: 0.0216 - val_acc: 0.8806\n",
      "Epoch 1316/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0222 - acc: 0.8744 - val_loss: 0.0215 - val_acc: 0.8807\n",
      "Epoch 1317/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0222 - acc: 0.8745 - val_loss: 0.0215 - val_acc: 0.8808\n",
      "Epoch 1318/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0222 - acc: 0.8745 - val_loss: 0.0215 - val_acc: 0.8809\n",
      "Epoch 1319/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0221 - acc: 0.8746 - val_loss: 0.0215 - val_acc: 0.8809\n",
      "Epoch 1320/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0221 - acc: 0.8748 - val_loss: 0.0215 - val_acc: 0.8809\n",
      "Epoch 1321/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0221 - acc: 0.8749 - val_loss: 0.0214 - val_acc: 0.8809\n",
      "Epoch 1322/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0221 - acc: 0.8749 - val_loss: 0.0214 - val_acc: 0.8809\n",
      "Epoch 1323/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0221 - acc: 0.8751 - val_loss: 0.0214 - val_acc: 0.8809\n",
      "Epoch 1324/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0221 - acc: 0.8750 - val_loss: 0.0214 - val_acc: 0.8811\n",
      "Epoch 1325/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0220 - acc: 0.8752 - val_loss: 0.0214 - val_acc: 0.8811\n",
      "Epoch 1326/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0220 - acc: 0.8752 - val_loss: 0.0214 - val_acc: 0.8810\n",
      "Epoch 1327/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0220 - acc: 0.8753 - val_loss: 0.0213 - val_acc: 0.8809\n",
      "Epoch 1328/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0220 - acc: 0.8754 - val_loss: 0.0213 - val_acc: 0.8808\n",
      "Epoch 1329/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0220 - acc: 0.8754 - val_loss: 0.0213 - val_acc: 0.8809\n",
      "Epoch 1330/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0219 - acc: 0.8755 - val_loss: 0.0213 - val_acc: 0.8810\n",
      "Epoch 1331/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0219 - acc: 0.8756 - val_loss: 0.0213 - val_acc: 0.8810\n",
      "Epoch 1332/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0219 - acc: 0.8757 - val_loss: 0.0213 - val_acc: 0.8810\n",
      "Epoch 1333/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0219 - acc: 0.8757 - val_loss: 0.0212 - val_acc: 0.8810\n",
      "Epoch 1334/2000\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0219 - acc: 0.8759 - val_loss: 0.0212 - val_acc: 0.8812\n",
      "Epoch 1335/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0219 - acc: 0.8759 - val_loss: 0.0212 - val_acc: 0.8813\n",
      "Epoch 1336/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0218 - acc: 0.8759 - val_loss: 0.0212 - val_acc: 0.8812\n",
      "Epoch 1337/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0218 - acc: 0.8761 - val_loss: 0.0212 - val_acc: 0.8812\n",
      "Epoch 1338/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0218 - acc: 0.8761 - val_loss: 0.0212 - val_acc: 0.8812\n",
      "Epoch 1339/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0218 - acc: 0.8762 - val_loss: 0.0211 - val_acc: 0.8812\n",
      "Epoch 1340/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0218 - acc: 0.8763 - val_loss: 0.0211 - val_acc: 0.8812\n",
      "Epoch 1341/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0218 - acc: 0.8763 - val_loss: 0.0211 - val_acc: 0.8812\n",
      "Epoch 1342/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0217 - acc: 0.8765 - val_loss: 0.0211 - val_acc: 0.8813\n",
      "Epoch 1343/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0217 - acc: 0.8765 - val_loss: 0.0211 - val_acc: 0.8814\n",
      "Epoch 1344/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0217 - acc: 0.8766 - val_loss: 0.0211 - val_acc: 0.8814\n",
      "Epoch 1345/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0217 - acc: 0.8766 - val_loss: 0.0210 - val_acc: 0.8815\n",
      "Epoch 1346/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0217 - acc: 0.8768 - val_loss: 0.0210 - val_acc: 0.8815\n",
      "Epoch 1347/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0217 - acc: 0.8768 - val_loss: 0.0210 - val_acc: 0.8819\n",
      "Epoch 1348/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0216 - acc: 0.8770 - val_loss: 0.0210 - val_acc: 0.8819\n",
      "Epoch 1349/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0216 - acc: 0.8770 - val_loss: 0.0210 - val_acc: 0.8821\n",
      "Epoch 1350/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0216 - acc: 0.8772 - val_loss: 0.0210 - val_acc: 0.8822\n",
      "Epoch 1351/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0216 - acc: 0.8772 - val_loss: 0.0209 - val_acc: 0.8823\n",
      "Epoch 1352/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0216 - acc: 0.8773 - val_loss: 0.0209 - val_acc: 0.8826\n",
      "Epoch 1353/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0216 - acc: 0.8774 - val_loss: 0.0209 - val_acc: 0.8827\n",
      "Epoch 1354/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0215 - acc: 0.8776 - val_loss: 0.0209 - val_acc: 0.8828\n",
      "Epoch 1355/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0215 - acc: 0.8777 - val_loss: 0.0209 - val_acc: 0.8828\n",
      "Epoch 1356/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0215 - acc: 0.8778 - val_loss: 0.0209 - val_acc: 0.8828\n",
      "Epoch 1357/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0215 - acc: 0.8778 - val_loss: 0.0208 - val_acc: 0.8827\n",
      "Epoch 1358/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0215 - acc: 0.8779 - val_loss: 0.0208 - val_acc: 0.8828\n",
      "Epoch 1359/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0215 - acc: 0.8780 - val_loss: 0.0208 - val_acc: 0.8827\n",
      "Epoch 1360/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0214 - acc: 0.8781 - val_loss: 0.0208 - val_acc: 0.8828\n",
      "Epoch 1361/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0214 - acc: 0.8781 - val_loss: 0.0208 - val_acc: 0.8829\n",
      "Epoch 1362/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0214 - acc: 0.8782 - val_loss: 0.0208 - val_acc: 0.8831\n",
      "Epoch 1363/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0214 - acc: 0.8781 - val_loss: 0.0207 - val_acc: 0.8832\n",
      "Epoch 1364/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0214 - acc: 0.8782 - val_loss: 0.0207 - val_acc: 0.8834\n",
      "Epoch 1365/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0214 - acc: 0.8783 - val_loss: 0.0207 - val_acc: 0.8836\n",
      "Epoch 1366/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0214 - acc: 0.8784 - val_loss: 0.0207 - val_acc: 0.8836\n",
      "Epoch 1367/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0213 - acc: 0.8784 - val_loss: 0.0207 - val_acc: 0.8837\n",
      "Epoch 1368/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0213 - acc: 0.8784 - val_loss: 0.0207 - val_acc: 0.8837\n",
      "Epoch 1369/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0213 - acc: 0.8787 - val_loss: 0.0206 - val_acc: 0.8838\n",
      "Epoch 1370/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0213 - acc: 0.8786 - val_loss: 0.0206 - val_acc: 0.8838\n",
      "Epoch 1371/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0213 - acc: 0.8788 - val_loss: 0.0206 - val_acc: 0.8837\n",
      "Epoch 1372/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0213 - acc: 0.8789 - val_loss: 0.0206 - val_acc: 0.8838\n",
      "Epoch 1373/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0212 - acc: 0.8790 - val_loss: 0.0206 - val_acc: 0.8838\n",
      "Epoch 1374/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0212 - acc: 0.8791 - val_loss: 0.0206 - val_acc: 0.8839\n",
      "Epoch 1375/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0212 - acc: 0.8792 - val_loss: 0.0206 - val_acc: 0.8839\n",
      "Epoch 1376/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0212 - acc: 0.8793 - val_loss: 0.0205 - val_acc: 0.8839\n",
      "Epoch 1377/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0212 - acc: 0.8793 - val_loss: 0.0205 - val_acc: 0.8840\n",
      "Epoch 1378/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0212 - acc: 0.8794 - val_loss: 0.0205 - val_acc: 0.8841\n",
      "Epoch 1379/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0211 - acc: 0.8795 - val_loss: 0.0205 - val_acc: 0.8842\n",
      "Epoch 1380/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0211 - acc: 0.8797 - val_loss: 0.0205 - val_acc: 0.8842\n",
      "Epoch 1381/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0211 - acc: 0.8797 - val_loss: 0.0205 - val_acc: 0.8842\n",
      "Epoch 1382/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0211 - acc: 0.8798 - val_loss: 0.0204 - val_acc: 0.8842\n",
      "Epoch 1383/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0211 - acc: 0.8798 - val_loss: 0.0204 - val_acc: 0.8841\n",
      "Epoch 1384/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0211 - acc: 0.8799 - val_loss: 0.0204 - val_acc: 0.8840\n",
      "Epoch 1385/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0211 - acc: 0.8800 - val_loss: 0.0204 - val_acc: 0.8841\n",
      "Epoch 1386/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0210 - acc: 0.8801 - val_loss: 0.0204 - val_acc: 0.8841\n",
      "Epoch 1387/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0210 - acc: 0.8803 - val_loss: 0.0204 - val_acc: 0.8842\n",
      "Epoch 1388/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0210 - acc: 0.8803 - val_loss: 0.0204 - val_acc: 0.8843\n",
      "Epoch 1389/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0210 - acc: 0.8803 - val_loss: 0.0203 - val_acc: 0.8843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1390/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0210 - acc: 0.8805 - val_loss: 0.0203 - val_acc: 0.8845\n",
      "Epoch 1391/2000\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0210 - acc: 0.8805 - val_loss: 0.0203 - val_acc: 0.8845\n",
      "Epoch 1392/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0209 - acc: 0.8806 - val_loss: 0.0203 - val_acc: 0.8846\n",
      "Epoch 1393/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0209 - acc: 0.8807 - val_loss: 0.0203 - val_acc: 0.8847\n",
      "Epoch 1394/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0209 - acc: 0.8806 - val_loss: 0.0203 - val_acc: 0.8848\n",
      "Epoch 1395/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0209 - acc: 0.8807 - val_loss: 0.0202 - val_acc: 0.8848\n",
      "Epoch 1396/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0209 - acc: 0.8807 - val_loss: 0.0202 - val_acc: 0.8849\n",
      "Epoch 1397/2000\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0209 - acc: 0.8807 - val_loss: 0.0202 - val_acc: 0.8849\n",
      "Epoch 1398/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0209 - acc: 0.8808 - val_loss: 0.0202 - val_acc: 0.8850\n",
      "Epoch 1399/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0208 - acc: 0.8809 - val_loss: 0.0202 - val_acc: 0.8850\n",
      "Epoch 1400/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0208 - acc: 0.8810 - val_loss: 0.0202 - val_acc: 0.8850\n",
      "Epoch 1401/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0208 - acc: 0.8810 - val_loss: 0.0202 - val_acc: 0.8850\n",
      "Epoch 1402/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0208 - acc: 0.8811 - val_loss: 0.0201 - val_acc: 0.8850\n",
      "Epoch 1403/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0208 - acc: 0.8811 - val_loss: 0.0201 - val_acc: 0.8850\n",
      "Epoch 1404/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0208 - acc: 0.8812 - val_loss: 0.0201 - val_acc: 0.8851\n",
      "Epoch 1405/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0208 - acc: 0.8813 - val_loss: 0.0201 - val_acc: 0.8851\n",
      "Epoch 1406/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0207 - acc: 0.8813 - val_loss: 0.0201 - val_acc: 0.8853\n",
      "Epoch 1407/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0207 - acc: 0.8814 - val_loss: 0.0201 - val_acc: 0.8853\n",
      "Epoch 1408/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0207 - acc: 0.8815 - val_loss: 0.0201 - val_acc: 0.8853\n",
      "Epoch 1409/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0207 - acc: 0.8816 - val_loss: 0.0200 - val_acc: 0.8853\n",
      "Epoch 1410/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0207 - acc: 0.8817 - val_loss: 0.0200 - val_acc: 0.8853\n",
      "Epoch 1411/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0207 - acc: 0.8817 - val_loss: 0.0200 - val_acc: 0.8853\n",
      "Epoch 1412/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0207 - acc: 0.8818 - val_loss: 0.0200 - val_acc: 0.8854\n",
      "Epoch 1413/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0206 - acc: 0.8818 - val_loss: 0.0200 - val_acc: 0.8856\n",
      "Epoch 1414/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0206 - acc: 0.8818 - val_loss: 0.0200 - val_acc: 0.8856\n",
      "Epoch 1415/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0206 - acc: 0.8819 - val_loss: 0.0200 - val_acc: 0.8857\n",
      "Epoch 1416/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0206 - acc: 0.8819 - val_loss: 0.0199 - val_acc: 0.8859\n",
      "Epoch 1417/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0206 - acc: 0.8819 - val_loss: 0.0199 - val_acc: 0.8859\n",
      "Epoch 1418/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0206 - acc: 0.8820 - val_loss: 0.0199 - val_acc: 0.8859\n",
      "Epoch 1419/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0205 - acc: 0.8820 - val_loss: 0.0199 - val_acc: 0.8860\n",
      "Epoch 1420/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0205 - acc: 0.8821 - val_loss: 0.0199 - val_acc: 0.8860\n",
      "Epoch 1421/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0205 - acc: 0.8822 - val_loss: 0.0199 - val_acc: 0.8859\n",
      "Epoch 1422/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0205 - acc: 0.8822 - val_loss: 0.0199 - val_acc: 0.8859\n",
      "Epoch 1423/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0205 - acc: 0.8825 - val_loss: 0.0198 - val_acc: 0.8859\n",
      "Epoch 1424/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0205 - acc: 0.8825 - val_loss: 0.0198 - val_acc: 0.8859\n",
      "Epoch 1425/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0205 - acc: 0.8825 - val_loss: 0.0198 - val_acc: 0.8860\n",
      "Epoch 1426/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0204 - acc: 0.8826 - val_loss: 0.0198 - val_acc: 0.8861\n",
      "Epoch 1427/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0204 - acc: 0.8826 - val_loss: 0.0198 - val_acc: 0.8863\n",
      "Epoch 1428/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0204 - acc: 0.8827 - val_loss: 0.0198 - val_acc: 0.8863\n",
      "Epoch 1429/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0204 - acc: 0.8827 - val_loss: 0.0198 - val_acc: 0.8862\n",
      "Epoch 1430/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0204 - acc: 0.8828 - val_loss: 0.0197 - val_acc: 0.8864\n",
      "Epoch 1431/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0204 - acc: 0.8829 - val_loss: 0.0197 - val_acc: 0.8866\n",
      "Epoch 1432/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0204 - acc: 0.8829 - val_loss: 0.0197 - val_acc: 0.8868\n",
      "Epoch 1433/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0203 - acc: 0.8831 - val_loss: 0.0197 - val_acc: 0.8867\n",
      "Epoch 1434/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0203 - acc: 0.8831 - val_loss: 0.0197 - val_acc: 0.8867\n",
      "Epoch 1435/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0203 - acc: 0.8832 - val_loss: 0.0197 - val_acc: 0.8868\n",
      "Epoch 1436/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0203 - acc: 0.8833 - val_loss: 0.0197 - val_acc: 0.8868\n",
      "Epoch 1437/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0203 - acc: 0.8833 - val_loss: 0.0196 - val_acc: 0.8869\n",
      "Epoch 1438/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0203 - acc: 0.8834 - val_loss: 0.0196 - val_acc: 0.8868\n",
      "Epoch 1439/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0203 - acc: 0.8835 - val_loss: 0.0196 - val_acc: 0.8870\n",
      "Epoch 1440/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0203 - acc: 0.8835 - val_loss: 0.0196 - val_acc: 0.8872\n",
      "Epoch 1441/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0202 - acc: 0.8835 - val_loss: 0.0196 - val_acc: 0.8872\n",
      "Epoch 1442/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0202 - acc: 0.8836 - val_loss: 0.0196 - val_acc: 0.8871\n",
      "Epoch 1443/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0202 - acc: 0.8837 - val_loss: 0.0196 - val_acc: 0.8872\n",
      "Epoch 1444/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0202 - acc: 0.8838 - val_loss: 0.0196 - val_acc: 0.8872\n",
      "Epoch 1445/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0202 - acc: 0.8840 - val_loss: 0.0195 - val_acc: 0.8873\n",
      "Epoch 1446/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0202 - acc: 0.8840 - val_loss: 0.0195 - val_acc: 0.8874\n",
      "Epoch 1447/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0202 - acc: 0.8840 - val_loss: 0.0195 - val_acc: 0.8876\n",
      "Epoch 1448/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0201 - acc: 0.8841 - val_loss: 0.0195 - val_acc: 0.8876\n",
      "Epoch 1449/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0201 - acc: 0.8842 - val_loss: 0.0195 - val_acc: 0.8876\n",
      "Epoch 1450/2000\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0201 - acc: 0.8842 - val_loss: 0.0195 - val_acc: 0.8876\n",
      "Epoch 1451/2000\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0201 - acc: 0.8843 - val_loss: 0.0195 - val_acc: 0.8876\n",
      "Epoch 1452/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0201 - acc: 0.8843 - val_loss: 0.0194 - val_acc: 0.8877\n",
      "Epoch 1453/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0201 - acc: 0.8844 - val_loss: 0.0194 - val_acc: 0.8877\n",
      "Epoch 1454/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0201 - acc: 0.8845 - val_loss: 0.0194 - val_acc: 0.8878\n",
      "Epoch 1455/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0200 - acc: 0.8845 - val_loss: 0.0194 - val_acc: 0.8879\n",
      "Epoch 1456/2000\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0200 - acc: 0.8845 - val_loss: 0.0194 - val_acc: 0.8879\n",
      "Epoch 1457/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0200 - acc: 0.8846 - val_loss: 0.0194 - val_acc: 0.8880\n",
      "Epoch 1458/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0200 - acc: 0.8847 - val_loss: 0.0194 - val_acc: 0.8879\n",
      "Epoch 1459/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0200 - acc: 0.8847 - val_loss: 0.0194 - val_acc: 0.8881\n",
      "Epoch 1460/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0200 - acc: 0.8848 - val_loss: 0.0193 - val_acc: 0.8879\n",
      "Epoch 1461/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0200 - acc: 0.8848 - val_loss: 0.0193 - val_acc: 0.8879\n",
      "Epoch 1462/2000\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0200 - acc: 0.8849 - val_loss: 0.0193 - val_acc: 0.8880\n",
      "Epoch 1463/2000\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0199 - acc: 0.8851 - val_loss: 0.0193 - val_acc: 0.8880\n",
      "Epoch 1464/2000\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0199 - acc: 0.8853 - val_loss: 0.0193 - val_acc: 0.8881\n",
      "Epoch 1465/2000\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0199 - acc: 0.8852 - val_loss: 0.0193 - val_acc: 0.8881\n",
      "Epoch 1466/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0199 - acc: 0.8853 - val_loss: 0.0193 - val_acc: 0.8881\n",
      "Epoch 1467/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0199 - acc: 0.8854 - val_loss: 0.0192 - val_acc: 0.8881\n",
      "Epoch 1468/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0199 - acc: 0.8854 - val_loss: 0.0192 - val_acc: 0.8882\n",
      "Epoch 1469/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0199 - acc: 0.8856 - val_loss: 0.0192 - val_acc: 0.8881\n",
      "Epoch 1470/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0198 - acc: 0.8857 - val_loss: 0.0192 - val_acc: 0.8882\n",
      "Epoch 1471/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0198 - acc: 0.8858 - val_loss: 0.0192 - val_acc: 0.8882\n",
      "Epoch 1472/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0198 - acc: 0.8858 - val_loss: 0.0192 - val_acc: 0.8883\n",
      "Epoch 1473/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0198 - acc: 0.8858 - val_loss: 0.0192 - val_acc: 0.8883\n",
      "Epoch 1474/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0198 - acc: 0.8859 - val_loss: 0.0192 - val_acc: 0.8885\n",
      "Epoch 1475/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0198 - acc: 0.8859 - val_loss: 0.0191 - val_acc: 0.8884\n",
      "Epoch 1476/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0198 - acc: 0.8860 - val_loss: 0.0191 - val_acc: 0.8884\n",
      "Epoch 1477/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0198 - acc: 0.8860 - val_loss: 0.0191 - val_acc: 0.8884\n",
      "Epoch 1478/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0197 - acc: 0.8861 - val_loss: 0.0191 - val_acc: 0.8883\n",
      "Epoch 1479/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0197 - acc: 0.8862 - val_loss: 0.0191 - val_acc: 0.8882\n",
      "Epoch 1480/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0197 - acc: 0.8863 - val_loss: 0.0191 - val_acc: 0.8882\n",
      "Epoch 1481/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0197 - acc: 0.8863 - val_loss: 0.0191 - val_acc: 0.8882\n",
      "Epoch 1482/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0197 - acc: 0.8863 - val_loss: 0.0191 - val_acc: 0.8885\n",
      "Epoch 1483/2000\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0197 - acc: 0.8864 - val_loss: 0.0190 - val_acc: 0.8885\n",
      "Epoch 1484/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0197 - acc: 0.8863 - val_loss: 0.0190 - val_acc: 0.8886\n",
      "Epoch 1485/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0197 - acc: 0.8864 - val_loss: 0.0190 - val_acc: 0.8886\n",
      "Epoch 1486/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0196 - acc: 0.8865 - val_loss: 0.0190 - val_acc: 0.8886\n",
      "Epoch 1487/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0196 - acc: 0.8866 - val_loss: 0.0190 - val_acc: 0.8886\n",
      "Epoch 1488/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0196 - acc: 0.8866 - val_loss: 0.0190 - val_acc: 0.8886\n",
      "Epoch 1489/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0196 - acc: 0.8868 - val_loss: 0.0190 - val_acc: 0.8885\n",
      "Epoch 1490/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0196 - acc: 0.8867 - val_loss: 0.0190 - val_acc: 0.8886\n",
      "Epoch 1491/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0196 - acc: 0.8868 - val_loss: 0.0189 - val_acc: 0.8888\n",
      "Epoch 1492/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0196 - acc: 0.8868 - val_loss: 0.0189 - val_acc: 0.8892\n",
      "Epoch 1493/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0196 - acc: 0.8869 - val_loss: 0.0189 - val_acc: 0.8892\n",
      "Epoch 1494/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0195 - acc: 0.8869 - val_loss: 0.0189 - val_acc: 0.8892\n",
      "Epoch 1495/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0195 - acc: 0.8869 - val_loss: 0.0189 - val_acc: 0.8892\n",
      "Epoch 1496/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0195 - acc: 0.8870 - val_loss: 0.0189 - val_acc: 0.8892\n",
      "Epoch 1497/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0195 - acc: 0.8871 - val_loss: 0.0189 - val_acc: 0.8891\n",
      "Epoch 1498/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0195 - acc: 0.8871 - val_loss: 0.0189 - val_acc: 0.8892\n",
      "Epoch 1499/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0195 - acc: 0.8871 - val_loss: 0.0188 - val_acc: 0.8892\n",
      "Epoch 1500/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0195 - acc: 0.8872 - val_loss: 0.0188 - val_acc: 0.8893\n",
      "Epoch 1501/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0195 - acc: 0.8872 - val_loss: 0.0188 - val_acc: 0.8893\n",
      "Epoch 1502/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0194 - acc: 0.8873 - val_loss: 0.0188 - val_acc: 0.8893\n",
      "Epoch 1503/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0194 - acc: 0.8873 - val_loss: 0.0188 - val_acc: 0.8893\n",
      "Epoch 1504/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0194 - acc: 0.8873 - val_loss: 0.0188 - val_acc: 0.8894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1505/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0194 - acc: 0.8875 - val_loss: 0.0188 - val_acc: 0.8895\n",
      "Epoch 1506/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0194 - acc: 0.8876 - val_loss: 0.0188 - val_acc: 0.8895\n",
      "Epoch 1507/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0194 - acc: 0.8876 - val_loss: 0.0188 - val_acc: 0.8896\n",
      "Epoch 1508/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0194 - acc: 0.8876 - val_loss: 0.0187 - val_acc: 0.8896\n",
      "Epoch 1509/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0194 - acc: 0.8876 - val_loss: 0.0187 - val_acc: 0.8898\n",
      "Epoch 1510/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0193 - acc: 0.8878 - val_loss: 0.0187 - val_acc: 0.8898\n",
      "Epoch 1511/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0193 - acc: 0.8878 - val_loss: 0.0187 - val_acc: 0.8899\n",
      "Epoch 1512/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0193 - acc: 0.8880 - val_loss: 0.0187 - val_acc: 0.8900\n",
      "Epoch 1513/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0193 - acc: 0.8881 - val_loss: 0.0187 - val_acc: 0.8901\n",
      "Epoch 1514/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0193 - acc: 0.8880 - val_loss: 0.0187 - val_acc: 0.8902\n",
      "Epoch 1515/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0193 - acc: 0.8882 - val_loss: 0.0187 - val_acc: 0.8903\n",
      "Epoch 1516/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0193 - acc: 0.8882 - val_loss: 0.0186 - val_acc: 0.8903\n",
      "Epoch 1517/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0193 - acc: 0.8883 - val_loss: 0.0186 - val_acc: 0.8903\n",
      "Epoch 1518/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0193 - acc: 0.8883 - val_loss: 0.0186 - val_acc: 0.8903\n",
      "Epoch 1519/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0192 - acc: 0.8883 - val_loss: 0.0186 - val_acc: 0.8903\n",
      "Epoch 1520/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0192 - acc: 0.8884 - val_loss: 0.0186 - val_acc: 0.8903\n",
      "Epoch 1521/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0192 - acc: 0.8884 - val_loss: 0.0186 - val_acc: 0.8904\n",
      "Epoch 1522/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0192 - acc: 0.8885 - val_loss: 0.0186 - val_acc: 0.8904\n",
      "Epoch 1523/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0192 - acc: 0.8886 - val_loss: 0.0186 - val_acc: 0.8906\n",
      "Epoch 1524/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0192 - acc: 0.8886 - val_loss: 0.0186 - val_acc: 0.8906\n",
      "Epoch 1525/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0192 - acc: 0.8886 - val_loss: 0.0185 - val_acc: 0.8905\n",
      "Epoch 1526/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0192 - acc: 0.8886 - val_loss: 0.0185 - val_acc: 0.8906\n",
      "Epoch 1527/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0191 - acc: 0.8887 - val_loss: 0.0185 - val_acc: 0.8907\n",
      "Epoch 1528/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0191 - acc: 0.8887 - val_loss: 0.0185 - val_acc: 0.8907\n",
      "Epoch 1529/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0191 - acc: 0.8888 - val_loss: 0.0185 - val_acc: 0.8909\n",
      "Epoch 1530/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0191 - acc: 0.8888 - val_loss: 0.0185 - val_acc: 0.8909\n",
      "Epoch 1531/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0191 - acc: 0.8888 - val_loss: 0.0185 - val_acc: 0.8911\n",
      "Epoch 1532/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0191 - acc: 0.8888 - val_loss: 0.0185 - val_acc: 0.8911\n",
      "Epoch 1533/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0191 - acc: 0.8888 - val_loss: 0.0185 - val_acc: 0.8912\n",
      "Epoch 1534/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0191 - acc: 0.8889 - val_loss: 0.0184 - val_acc: 0.8913\n",
      "Epoch 1535/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0191 - acc: 0.8888 - val_loss: 0.0184 - val_acc: 0.8915\n",
      "Epoch 1536/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0190 - acc: 0.8889 - val_loss: 0.0184 - val_acc: 0.8916\n",
      "Epoch 1537/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0190 - acc: 0.8890 - val_loss: 0.0184 - val_acc: 0.8916\n",
      "Epoch 1538/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0190 - acc: 0.8890 - val_loss: 0.0184 - val_acc: 0.8917\n",
      "Epoch 1539/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0190 - acc: 0.8889 - val_loss: 0.0184 - val_acc: 0.8917\n",
      "Epoch 1540/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0190 - acc: 0.8891 - val_loss: 0.0184 - val_acc: 0.8918\n",
      "Epoch 1541/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0190 - acc: 0.8891 - val_loss: 0.0184 - val_acc: 0.8918\n",
      "Epoch 1542/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0190 - acc: 0.8892 - val_loss: 0.0184 - val_acc: 0.8919\n",
      "Epoch 1543/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0190 - acc: 0.8892 - val_loss: 0.0183 - val_acc: 0.8923\n",
      "Epoch 1544/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0189 - acc: 0.8893 - val_loss: 0.0183 - val_acc: 0.8924\n",
      "Epoch 1545/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0189 - acc: 0.8893 - val_loss: 0.0183 - val_acc: 0.8926\n",
      "Epoch 1546/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0189 - acc: 0.8893 - val_loss: 0.0183 - val_acc: 0.8927\n",
      "Epoch 1547/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0189 - acc: 0.8894 - val_loss: 0.0183 - val_acc: 0.8927\n",
      "Epoch 1548/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0189 - acc: 0.8894 - val_loss: 0.0183 - val_acc: 0.8928\n",
      "Epoch 1549/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0189 - acc: 0.8894 - val_loss: 0.0183 - val_acc: 0.8929\n",
      "Epoch 1550/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0189 - acc: 0.8895 - val_loss: 0.0183 - val_acc: 0.8931\n",
      "Epoch 1551/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0189 - acc: 0.8896 - val_loss: 0.0183 - val_acc: 0.8931\n",
      "Epoch 1552/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0189 - acc: 0.8896 - val_loss: 0.0182 - val_acc: 0.8931\n",
      "Epoch 1553/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0188 - acc: 0.8896 - val_loss: 0.0182 - val_acc: 0.8932\n",
      "Epoch 1554/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0188 - acc: 0.8897 - val_loss: 0.0182 - val_acc: 0.8933\n",
      "Epoch 1555/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0188 - acc: 0.8898 - val_loss: 0.0182 - val_acc: 0.8933\n",
      "Epoch 1556/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0188 - acc: 0.8897 - val_loss: 0.0182 - val_acc: 0.8933\n",
      "Epoch 1557/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0188 - acc: 0.8898 - val_loss: 0.0182 - val_acc: 0.8932\n",
      "Epoch 1558/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0188 - acc: 0.8898 - val_loss: 0.0182 - val_acc: 0.8932\n",
      "Epoch 1559/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0188 - acc: 0.8899 - val_loss: 0.0182 - val_acc: 0.8933\n",
      "Epoch 1560/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0188 - acc: 0.8899 - val_loss: 0.0182 - val_acc: 0.8934\n",
      "Epoch 1561/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0188 - acc: 0.8899 - val_loss: 0.0181 - val_acc: 0.8936\n",
      "Epoch 1562/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0187 - acc: 0.8900 - val_loss: 0.0181 - val_acc: 0.8938\n",
      "Epoch 1563/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0187 - acc: 0.8900 - val_loss: 0.0181 - val_acc: 0.8938\n",
      "Epoch 1564/2000\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0187 - acc: 0.8901 - val_loss: 0.0181 - val_acc: 0.8938\n",
      "Epoch 1565/2000\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0187 - acc: 0.8902 - val_loss: 0.0181 - val_acc: 0.8938\n",
      "Epoch 1566/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0187 - acc: 0.8902 - val_loss: 0.0181 - val_acc: 0.8939\n",
      "Epoch 1567/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0187 - acc: 0.8903 - val_loss: 0.0181 - val_acc: 0.8939\n",
      "Epoch 1568/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0187 - acc: 0.8903 - val_loss: 0.0181 - val_acc: 0.8940\n",
      "Epoch 1569/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0187 - acc: 0.8903 - val_loss: 0.0181 - val_acc: 0.8941\n",
      "Epoch 1570/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0187 - acc: 0.8903 - val_loss: 0.0180 - val_acc: 0.8942\n",
      "Epoch 1571/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0186 - acc: 0.8904 - val_loss: 0.0180 - val_acc: 0.8942\n",
      "Epoch 1572/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0186 - acc: 0.8904 - val_loss: 0.0180 - val_acc: 0.8943\n",
      "Epoch 1573/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0186 - acc: 0.8906 - val_loss: 0.0180 - val_acc: 0.8943\n",
      "Epoch 1574/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0186 - acc: 0.8906 - val_loss: 0.0180 - val_acc: 0.8944\n",
      "Epoch 1575/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0186 - acc: 0.8907 - val_loss: 0.0180 - val_acc: 0.8944\n",
      "Epoch 1576/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0186 - acc: 0.8908 - val_loss: 0.0180 - val_acc: 0.8943\n",
      "Epoch 1577/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0186 - acc: 0.8908 - val_loss: 0.0180 - val_acc: 0.8943\n",
      "Epoch 1578/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0186 - acc: 0.8909 - val_loss: 0.0180 - val_acc: 0.8943\n",
      "Epoch 1579/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0186 - acc: 0.8910 - val_loss: 0.0180 - val_acc: 0.8943\n",
      "Epoch 1580/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0186 - acc: 0.8909 - val_loss: 0.0179 - val_acc: 0.8944\n",
      "Epoch 1581/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0185 - acc: 0.8910 - val_loss: 0.0179 - val_acc: 0.8944\n",
      "Epoch 1582/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0185 - acc: 0.8911 - val_loss: 0.0179 - val_acc: 0.8945\n",
      "Epoch 1583/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0185 - acc: 0.8910 - val_loss: 0.0179 - val_acc: 0.8947\n",
      "Epoch 1584/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0185 - acc: 0.8911 - val_loss: 0.0179 - val_acc: 0.8948\n",
      "Epoch 1585/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0185 - acc: 0.8912 - val_loss: 0.0179 - val_acc: 0.8949\n",
      "Epoch 1586/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0185 - acc: 0.8913 - val_loss: 0.0179 - val_acc: 0.8950\n",
      "Epoch 1587/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0185 - acc: 0.8913 - val_loss: 0.0179 - val_acc: 0.8950\n",
      "Epoch 1588/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0185 - acc: 0.8913 - val_loss: 0.0179 - val_acc: 0.8950\n",
      "Epoch 1589/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0185 - acc: 0.8914 - val_loss: 0.0179 - val_acc: 0.8952\n",
      "Epoch 1590/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0184 - acc: 0.8914 - val_loss: 0.0178 - val_acc: 0.8954\n",
      "Epoch 1591/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0184 - acc: 0.8914 - val_loss: 0.0178 - val_acc: 0.8954\n",
      "Epoch 1592/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0184 - acc: 0.8914 - val_loss: 0.0178 - val_acc: 0.8955\n",
      "Epoch 1593/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0184 - acc: 0.8915 - val_loss: 0.0178 - val_acc: 0.8954\n",
      "Epoch 1594/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0184 - acc: 0.8916 - val_loss: 0.0178 - val_acc: 0.8956\n",
      "Epoch 1595/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0184 - acc: 0.8917 - val_loss: 0.0178 - val_acc: 0.8956\n",
      "Epoch 1596/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0184 - acc: 0.8918 - val_loss: 0.0178 - val_acc: 0.8957\n",
      "Epoch 1597/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0184 - acc: 0.8918 - val_loss: 0.0178 - val_acc: 0.8957\n",
      "Epoch 1598/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0184 - acc: 0.8918 - val_loss: 0.0178 - val_acc: 0.8957\n",
      "Epoch 1599/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0184 - acc: 0.8919 - val_loss: 0.0178 - val_acc: 0.8957\n",
      "Epoch 1600/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0183 - acc: 0.8920 - val_loss: 0.0177 - val_acc: 0.8957\n",
      "Epoch 1601/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0183 - acc: 0.8920 - val_loss: 0.0177 - val_acc: 0.8957\n",
      "Epoch 1602/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0183 - acc: 0.8920 - val_loss: 0.0177 - val_acc: 0.8956\n",
      "Epoch 1603/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0183 - acc: 0.8921 - val_loss: 0.0177 - val_acc: 0.8956\n",
      "Epoch 1604/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0183 - acc: 0.8922 - val_loss: 0.0177 - val_acc: 0.8956\n",
      "Epoch 1605/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0183 - acc: 0.8922 - val_loss: 0.0177 - val_acc: 0.8958\n",
      "Epoch 1606/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0183 - acc: 0.8923 - val_loss: 0.0177 - val_acc: 0.8959\n",
      "Epoch 1607/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0183 - acc: 0.8923 - val_loss: 0.0177 - val_acc: 0.8959\n",
      "Epoch 1608/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0183 - acc: 0.8924 - val_loss: 0.0177 - val_acc: 0.8960\n",
      "Epoch 1609/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0183 - acc: 0.8924 - val_loss: 0.0177 - val_acc: 0.8959\n",
      "Epoch 1610/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0182 - acc: 0.8925 - val_loss: 0.0176 - val_acc: 0.8961\n",
      "Epoch 1611/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0182 - acc: 0.8924 - val_loss: 0.0176 - val_acc: 0.8962\n",
      "Epoch 1612/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0182 - acc: 0.8925 - val_loss: 0.0176 - val_acc: 0.8964\n",
      "Epoch 1613/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0182 - acc: 0.8925 - val_loss: 0.0176 - val_acc: 0.8964\n",
      "Epoch 1614/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0182 - acc: 0.8926 - val_loss: 0.0176 - val_acc: 0.8965\n",
      "Epoch 1615/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0182 - acc: 0.8927 - val_loss: 0.0176 - val_acc: 0.8965\n",
      "Epoch 1616/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0182 - acc: 0.8927 - val_loss: 0.0176 - val_acc: 0.8965\n",
      "Epoch 1617/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0182 - acc: 0.8928 - val_loss: 0.0176 - val_acc: 0.8966\n",
      "Epoch 1618/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0182 - acc: 0.8928 - val_loss: 0.0176 - val_acc: 0.8966\n",
      "Epoch 1619/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0182 - acc: 0.8929 - val_loss: 0.0176 - val_acc: 0.8966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1620/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0181 - acc: 0.8929 - val_loss: 0.0176 - val_acc: 0.8967\n",
      "Epoch 1621/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0181 - acc: 0.8929 - val_loss: 0.0175 - val_acc: 0.8967\n",
      "Epoch 1622/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0181 - acc: 0.8929 - val_loss: 0.0175 - val_acc: 0.8967\n",
      "Epoch 1623/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0181 - acc: 0.8931 - val_loss: 0.0175 - val_acc: 0.8968\n",
      "Epoch 1624/2000\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0181 - acc: 0.8931 - val_loss: 0.0175 - val_acc: 0.8969\n",
      "Epoch 1625/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0181 - acc: 0.8931 - val_loss: 0.0175 - val_acc: 0.8969\n",
      "Epoch 1626/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0181 - acc: 0.8931 - val_loss: 0.0175 - val_acc: 0.8970\n",
      "Epoch 1627/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0181 - acc: 0.8932 - val_loss: 0.0175 - val_acc: 0.8970\n",
      "Epoch 1628/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0181 - acc: 0.8931 - val_loss: 0.0175 - val_acc: 0.8970\n",
      "Epoch 1629/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0181 - acc: 0.8932 - val_loss: 0.0175 - val_acc: 0.8972\n",
      "Epoch 1630/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0180 - acc: 0.8932 - val_loss: 0.0175 - val_acc: 0.8973\n",
      "Epoch 1631/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0180 - acc: 0.8932 - val_loss: 0.0174 - val_acc: 0.8973\n",
      "Epoch 1632/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0180 - acc: 0.8933 - val_loss: 0.0174 - val_acc: 0.8973\n",
      "Epoch 1633/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0180 - acc: 0.8933 - val_loss: 0.0174 - val_acc: 0.8973\n",
      "Epoch 1634/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0180 - acc: 0.8934 - val_loss: 0.0174 - val_acc: 0.8973\n",
      "Epoch 1635/2000\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 0.0180 - acc: 0.893 - 1s 19us/step - loss: 0.0180 - acc: 0.8933 - val_loss: 0.0174 - val_acc: 0.8976\n",
      "Epoch 1636/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0180 - acc: 0.8934 - val_loss: 0.0174 - val_acc: 0.8977\n",
      "Epoch 1637/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0180 - acc: 0.8935 - val_loss: 0.0174 - val_acc: 0.8977\n",
      "Epoch 1638/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0180 - acc: 0.8935 - val_loss: 0.0174 - val_acc: 0.8978\n",
      "Epoch 1639/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0180 - acc: 0.8936 - val_loss: 0.0174 - val_acc: 0.8978\n",
      "Epoch 1640/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0179 - acc: 0.8937 - val_loss: 0.0174 - val_acc: 0.8978\n",
      "Epoch 1641/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0179 - acc: 0.8937 - val_loss: 0.0174 - val_acc: 0.8978\n",
      "Epoch 1642/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0179 - acc: 0.8938 - val_loss: 0.0173 - val_acc: 0.8978\n",
      "Epoch 1643/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0179 - acc: 0.8938 - val_loss: 0.0173 - val_acc: 0.8979\n",
      "Epoch 1644/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0179 - acc: 0.8938 - val_loss: 0.0173 - val_acc: 0.8979\n",
      "Epoch 1645/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0179 - acc: 0.8939 - val_loss: 0.0173 - val_acc: 0.8979\n",
      "Epoch 1646/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0179 - acc: 0.8939 - val_loss: 0.0173 - val_acc: 0.8980\n",
      "Epoch 1647/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0179 - acc: 0.8940 - val_loss: 0.0173 - val_acc: 0.8982\n",
      "Epoch 1648/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0179 - acc: 0.8941 - val_loss: 0.0173 - val_acc: 0.8982\n",
      "Epoch 1649/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0179 - acc: 0.8942 - val_loss: 0.0173 - val_acc: 0.8983\n",
      "Epoch 1650/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0179 - acc: 0.8943 - val_loss: 0.0173 - val_acc: 0.8983\n",
      "Epoch 1651/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0178 - acc: 0.8943 - val_loss: 0.0173 - val_acc: 0.8982\n",
      "Epoch 1652/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0178 - acc: 0.8944 - val_loss: 0.0173 - val_acc: 0.8982\n",
      "Epoch 1653/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0178 - acc: 0.8944 - val_loss: 0.0172 - val_acc: 0.8984\n",
      "Epoch 1654/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0178 - acc: 0.8944 - val_loss: 0.0172 - val_acc: 0.8984\n",
      "Epoch 1655/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0178 - acc: 0.8945 - val_loss: 0.0172 - val_acc: 0.8985\n",
      "Epoch 1656/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0178 - acc: 0.8946 - val_loss: 0.0172 - val_acc: 0.8985\n",
      "Epoch 1657/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0178 - acc: 0.8946 - val_loss: 0.0172 - val_acc: 0.8985\n",
      "Epoch 1658/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0178 - acc: 0.8946 - val_loss: 0.0172 - val_acc: 0.8985\n",
      "Epoch 1659/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0178 - acc: 0.8947 - val_loss: 0.0172 - val_acc: 0.8985\n",
      "Epoch 1660/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0178 - acc: 0.8947 - val_loss: 0.0172 - val_acc: 0.8984\n",
      "Epoch 1661/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0177 - acc: 0.8947 - val_loss: 0.0172 - val_acc: 0.8985\n",
      "Epoch 1662/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0177 - acc: 0.8947 - val_loss: 0.0172 - val_acc: 0.8985\n",
      "Epoch 1663/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0177 - acc: 0.8947 - val_loss: 0.0172 - val_acc: 0.8985\n",
      "Epoch 1664/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0177 - acc: 0.8948 - val_loss: 0.0171 - val_acc: 0.8985\n",
      "Epoch 1665/2000\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0177 - acc: 0.8949 - val_loss: 0.0171 - val_acc: 0.8986\n",
      "Epoch 1666/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0177 - acc: 0.8949 - val_loss: 0.0171 - val_acc: 0.8987\n",
      "Epoch 1667/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0177 - acc: 0.8950 - val_loss: 0.0171 - val_acc: 0.8988\n",
      "Epoch 1668/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0177 - acc: 0.8950 - val_loss: 0.0171 - val_acc: 0.8988\n",
      "Epoch 1669/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0177 - acc: 0.8950 - val_loss: 0.0171 - val_acc: 0.8988\n",
      "Epoch 1670/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0177 - acc: 0.8951 - val_loss: 0.0171 - val_acc: 0.8989\n",
      "Epoch 1671/2000\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0177 - acc: 0.8951 - val_loss: 0.0171 - val_acc: 0.8989\n",
      "Epoch 1672/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0176 - acc: 0.8951 - val_loss: 0.0171 - val_acc: 0.8989\n",
      "Epoch 1673/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0176 - acc: 0.8951 - val_loss: 0.0171 - val_acc: 0.8988\n",
      "Epoch 1674/2000\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0176 - acc: 0.8951 - val_loss: 0.0171 - val_acc: 0.8989\n",
      "Epoch 1675/2000\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0176 - acc: 0.8952 - val_loss: 0.0171 - val_acc: 0.8991\n",
      "Epoch 1676/2000\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0176 - acc: 0.8953 - val_loss: 0.0170 - val_acc: 0.8993\n",
      "Epoch 1677/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0176 - acc: 0.8953 - val_loss: 0.0170 - val_acc: 0.8993\n",
      "Epoch 1678/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0176 - acc: 0.8953 - val_loss: 0.0170 - val_acc: 0.8993\n",
      "Epoch 1679/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0176 - acc: 0.8954 - val_loss: 0.0170 - val_acc: 0.8993\n",
      "Epoch 1680/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0176 - acc: 0.8954 - val_loss: 0.0170 - val_acc: 0.8993\n",
      "Epoch 1681/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0176 - acc: 0.8955 - val_loss: 0.0170 - val_acc: 0.8995\n",
      "Epoch 1682/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0176 - acc: 0.8955 - val_loss: 0.0170 - val_acc: 0.8997\n",
      "Epoch 1683/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0175 - acc: 0.8955 - val_loss: 0.0170 - val_acc: 0.8997\n",
      "Epoch 1684/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0175 - acc: 0.8956 - val_loss: 0.0170 - val_acc: 0.8998\n",
      "Epoch 1685/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0175 - acc: 0.8957 - val_loss: 0.0170 - val_acc: 0.8999\n",
      "Epoch 1686/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0175 - acc: 0.8957 - val_loss: 0.0170 - val_acc: 0.8999\n",
      "Epoch 1687/2000\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0175 - acc: 0.8958 - val_loss: 0.0170 - val_acc: 0.8999\n",
      "Epoch 1688/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0175 - acc: 0.8958 - val_loss: 0.0169 - val_acc: 0.8999\n",
      "Epoch 1689/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0175 - acc: 0.8959 - val_loss: 0.0169 - val_acc: 0.9000\n",
      "Epoch 1690/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0175 - acc: 0.8959 - val_loss: 0.0169 - val_acc: 0.9000\n",
      "Epoch 1691/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0175 - acc: 0.8959 - val_loss: 0.0169 - val_acc: 0.9000\n",
      "Epoch 1692/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0175 - acc: 0.8959 - val_loss: 0.0169 - val_acc: 0.9000\n",
      "Epoch 1693/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0175 - acc: 0.8960 - val_loss: 0.0169 - val_acc: 0.9000\n",
      "Epoch 1694/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0175 - acc: 0.8961 - val_loss: 0.0169 - val_acc: 0.9002\n",
      "Epoch 1695/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0174 - acc: 0.8961 - val_loss: 0.0169 - val_acc: 0.9002\n",
      "Epoch 1696/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0174 - acc: 0.8962 - val_loss: 0.0169 - val_acc: 0.9002\n",
      "Epoch 1697/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0174 - acc: 0.8961 - val_loss: 0.0169 - val_acc: 0.9003\n",
      "Epoch 1698/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0174 - acc: 0.8962 - val_loss: 0.0169 - val_acc: 0.9004\n",
      "Epoch 1699/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0174 - acc: 0.8962 - val_loss: 0.0169 - val_acc: 0.9005\n",
      "Epoch 1700/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0174 - acc: 0.8962 - val_loss: 0.0168 - val_acc: 0.9005\n",
      "Epoch 1701/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0174 - acc: 0.8963 - val_loss: 0.0168 - val_acc: 0.9007\n",
      "Epoch 1702/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0174 - acc: 0.8963 - val_loss: 0.0168 - val_acc: 0.9007\n",
      "Epoch 1703/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0174 - acc: 0.8963 - val_loss: 0.0168 - val_acc: 0.9007\n",
      "Epoch 1704/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0174 - acc: 0.8963 - val_loss: 0.0168 - val_acc: 0.9007\n",
      "Epoch 1705/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0174 - acc: 0.8965 - val_loss: 0.0168 - val_acc: 0.9007\n",
      "Epoch 1706/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0173 - acc: 0.8965 - val_loss: 0.0168 - val_acc: 0.9007\n",
      "Epoch 1707/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0173 - acc: 0.8964 - val_loss: 0.0168 - val_acc: 0.9007\n",
      "Epoch 1708/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0173 - acc: 0.8965 - val_loss: 0.0168 - val_acc: 0.9007\n",
      "Epoch 1709/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0173 - acc: 0.8966 - val_loss: 0.0168 - val_acc: 0.9008\n",
      "Epoch 1710/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0173 - acc: 0.8966 - val_loss: 0.0168 - val_acc: 0.9008\n",
      "Epoch 1711/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0173 - acc: 0.8967 - val_loss: 0.0168 - val_acc: 0.9008\n",
      "Epoch 1712/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0173 - acc: 0.8967 - val_loss: 0.0167 - val_acc: 0.9009\n",
      "Epoch 1713/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0173 - acc: 0.8968 - val_loss: 0.0167 - val_acc: 0.9009\n",
      "Epoch 1714/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0173 - acc: 0.8969 - val_loss: 0.0167 - val_acc: 0.9009\n",
      "Epoch 1715/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0173 - acc: 0.8969 - val_loss: 0.0167 - val_acc: 0.9010\n",
      "Epoch 1716/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0173 - acc: 0.8969 - val_loss: 0.0167 - val_acc: 0.9010\n",
      "Epoch 1717/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0173 - acc: 0.8970 - val_loss: 0.0167 - val_acc: 0.9010\n",
      "Epoch 1718/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0172 - acc: 0.8970 - val_loss: 0.0167 - val_acc: 0.9010\n",
      "Epoch 1719/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0172 - acc: 0.8971 - val_loss: 0.0167 - val_acc: 0.9011\n",
      "Epoch 1720/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0172 - acc: 0.8970 - val_loss: 0.0167 - val_acc: 0.9011\n",
      "Epoch 1721/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0172 - acc: 0.8970 - val_loss: 0.0167 - val_acc: 0.9011\n",
      "Epoch 1722/2000\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0172 - acc: 0.8970 - val_loss: 0.0167 - val_acc: 0.9011\n",
      "Epoch 1723/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0172 - acc: 0.8971 - val_loss: 0.0167 - val_acc: 0.9012\n",
      "Epoch 1724/2000\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0172 - acc: 0.8971 - val_loss: 0.0167 - val_acc: 0.9013\n",
      "Epoch 1725/2000\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0172 - acc: 0.8971 - val_loss: 0.0166 - val_acc: 0.9012\n",
      "Epoch 1726/2000\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0172 - acc: 0.8972 - val_loss: 0.0166 - val_acc: 0.9013\n",
      "Epoch 1727/2000\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0172 - acc: 0.8972 - val_loss: 0.0166 - val_acc: 0.9013\n",
      "Epoch 1728/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0172 - acc: 0.8974 - val_loss: 0.0166 - val_acc: 0.9014\n",
      "Epoch 1729/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0172 - acc: 0.8974 - val_loss: 0.0166 - val_acc: 0.9014\n",
      "Epoch 1730/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0171 - acc: 0.8974 - val_loss: 0.0166 - val_acc: 0.9014\n",
      "Epoch 1731/2000\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0171 - acc: 0.8974 - val_loss: 0.0166 - val_acc: 0.9015\n",
      "Epoch 1732/2000\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0171 - acc: 0.8975 - val_loss: 0.0166 - val_acc: 0.9015\n",
      "Epoch 1733/2000\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0171 - acc: 0.8975 - val_loss: 0.0166 - val_acc: 0.9015\n",
      "Epoch 1734/2000\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0171 - acc: 0.8976 - val_loss: 0.0166 - val_acc: 0.9015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1735/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0171 - acc: 0.8977 - val_loss: 0.0166 - val_acc: 0.9015\n",
      "Epoch 1736/2000\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0171 - acc: 0.8977 - val_loss: 0.0166 - val_acc: 0.9015\n",
      "Epoch 1737/2000\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0171 - acc: 0.8977 - val_loss: 0.0166 - val_acc: 0.9015\n",
      "Epoch 1738/2000\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0171 - acc: 0.8977 - val_loss: 0.0165 - val_acc: 0.9016\n",
      "Epoch 1739/2000\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0171 - acc: 0.8978 - val_loss: 0.0165 - val_acc: 0.9018\n",
      "Epoch 1740/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0171 - acc: 0.8979 - val_loss: 0.0165 - val_acc: 0.9018\n",
      "Epoch 1741/2000\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0171 - acc: 0.8979 - val_loss: 0.0165 - val_acc: 0.9018\n",
      "Epoch 1742/2000\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0171 - acc: 0.8979 - val_loss: 0.0165 - val_acc: 0.9018\n",
      "Epoch 1743/2000\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0170 - acc: 0.8980 - val_loss: 0.0165 - val_acc: 0.9018\n",
      "Epoch 1744/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0170 - acc: 0.8980 - val_loss: 0.0165 - val_acc: 0.9018\n",
      "Epoch 1745/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0170 - acc: 0.8979 - val_loss: 0.0165 - val_acc: 0.9019\n",
      "Epoch 1746/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0170 - acc: 0.8980 - val_loss: 0.0165 - val_acc: 0.9019\n",
      "Epoch 1747/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0170 - acc: 0.8980 - val_loss: 0.0165 - val_acc: 0.9019\n",
      "Epoch 1748/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0170 - acc: 0.8980 - val_loss: 0.0165 - val_acc: 0.9019\n",
      "Epoch 1749/2000\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0170 - acc: 0.8981 - val_loss: 0.0165 - val_acc: 0.9019\n",
      "Epoch 1750/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0170 - acc: 0.8981 - val_loss: 0.0165 - val_acc: 0.9019\n",
      "Epoch 1751/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0170 - acc: 0.8982 - val_loss: 0.0164 - val_acc: 0.9019\n",
      "Epoch 1752/2000\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0170 - acc: 0.8983 - val_loss: 0.0164 - val_acc: 0.9019\n",
      "Epoch 1753/2000\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0170 - acc: 0.8983 - val_loss: 0.0164 - val_acc: 0.9020\n",
      "Epoch 1754/2000\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0170 - acc: 0.8983 - val_loss: 0.0164 - val_acc: 0.9020\n",
      "Epoch 1755/2000\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0169 - acc: 0.8983 - val_loss: 0.0164 - val_acc: 0.9020\n",
      "Epoch 1756/2000\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0169 - acc: 0.8984 - val_loss: 0.0164 - val_acc: 0.9022\n",
      "Epoch 1757/2000\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0169 - acc: 0.8984 - val_loss: 0.0164 - val_acc: 0.9022\n",
      "Epoch 1758/2000\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0169 - acc: 0.8985 - val_loss: 0.0164 - val_acc: 0.9022\n",
      "Epoch 1759/2000\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0169 - acc: 0.8985 - val_loss: 0.0164 - val_acc: 0.9023\n",
      "Epoch 1760/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0169 - acc: 0.8985 - val_loss: 0.0164 - val_acc: 0.9024\n",
      "Epoch 1761/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0169 - acc: 0.8986 - val_loss: 0.0164 - val_acc: 0.9024\n",
      "Epoch 1762/2000\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0169 - acc: 0.8986 - val_loss: 0.0164 - val_acc: 0.9024\n",
      "Epoch 1763/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0169 - acc: 0.8987 - val_loss: 0.0164 - val_acc: 0.9024\n",
      "Epoch 1764/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0169 - acc: 0.8987 - val_loss: 0.0163 - val_acc: 0.9024\n",
      "Epoch 1765/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0169 - acc: 0.8988 - val_loss: 0.0163 - val_acc: 0.9025\n",
      "Epoch 1766/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0169 - acc: 0.8987 - val_loss: 0.0163 - val_acc: 0.9025\n",
      "Epoch 1767/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0169 - acc: 0.8988 - val_loss: 0.0163 - val_acc: 0.9025\n",
      "Epoch 1768/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0168 - acc: 0.8989 - val_loss: 0.0163 - val_acc: 0.9025\n",
      "Epoch 1769/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0168 - acc: 0.8989 - val_loss: 0.0163 - val_acc: 0.9024\n",
      "Epoch 1770/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0168 - acc: 0.8990 - val_loss: 0.0163 - val_acc: 0.9024\n",
      "Epoch 1771/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0168 - acc: 0.8990 - val_loss: 0.0163 - val_acc: 0.9024\n",
      "Epoch 1772/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0168 - acc: 0.8990 - val_loss: 0.0163 - val_acc: 0.9024\n",
      "Epoch 1773/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0168 - acc: 0.8990 - val_loss: 0.0163 - val_acc: 0.9024\n",
      "Epoch 1774/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0168 - acc: 0.8990 - val_loss: 0.0163 - val_acc: 0.9025\n",
      "Epoch 1775/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0168 - acc: 0.8992 - val_loss: 0.0163 - val_acc: 0.9025\n",
      "Epoch 1776/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0168 - acc: 0.8991 - val_loss: 0.0163 - val_acc: 0.9026\n",
      "Epoch 1777/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0168 - acc: 0.8992 - val_loss: 0.0163 - val_acc: 0.9026\n",
      "Epoch 1778/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0168 - acc: 0.8992 - val_loss: 0.0162 - val_acc: 0.9028\n",
      "Epoch 1779/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0168 - acc: 0.8993 - val_loss: 0.0162 - val_acc: 0.9028\n",
      "Epoch 1780/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0168 - acc: 0.8994 - val_loss: 0.0162 - val_acc: 0.9028\n",
      "Epoch 1781/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0167 - acc: 0.8994 - val_loss: 0.0162 - val_acc: 0.9028\n",
      "Epoch 1782/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0167 - acc: 0.8994 - val_loss: 0.0162 - val_acc: 0.9029\n",
      "Epoch 1783/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0167 - acc: 0.8994 - val_loss: 0.0162 - val_acc: 0.9029\n",
      "Epoch 1784/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0167 - acc: 0.8995 - val_loss: 0.0162 - val_acc: 0.9030\n",
      "Epoch 1785/2000\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 0.0167 - acc: 0.899 - 1s 21us/step - loss: 0.0167 - acc: 0.8995 - val_loss: 0.0162 - val_acc: 0.9030\n",
      "Epoch 1786/2000\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0167 - acc: 0.8995 - val_loss: 0.0162 - val_acc: 0.9030\n",
      "Epoch 1787/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0167 - acc: 0.8995 - val_loss: 0.0162 - val_acc: 0.9030\n",
      "Epoch 1788/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0167 - acc: 0.8996 - val_loss: 0.0162 - val_acc: 0.9030\n",
      "Epoch 1789/2000\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0167 - acc: 0.8996 - val_loss: 0.0162 - val_acc: 0.9030\n",
      "Epoch 1790/2000\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0167 - acc: 0.8997 - val_loss: 0.0162 - val_acc: 0.9031\n",
      "Epoch 1791/2000\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0167 - acc: 0.8996 - val_loss: 0.0162 - val_acc: 0.9031\n",
      "Epoch 1792/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0167 - acc: 0.8997 - val_loss: 0.0162 - val_acc: 0.9031\n",
      "Epoch 1793/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0167 - acc: 0.8998 - val_loss: 0.0161 - val_acc: 0.9032\n",
      "Epoch 1794/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0166 - acc: 0.8998 - val_loss: 0.0161 - val_acc: 0.9031\n",
      "Epoch 1795/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0166 - acc: 0.8999 - val_loss: 0.0161 - val_acc: 0.9033\n",
      "Epoch 1796/2000\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0166 - acc: 0.8999 - val_loss: 0.0161 - val_acc: 0.9033\n",
      "Epoch 1797/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0166 - acc: 0.8999 - val_loss: 0.0161 - val_acc: 0.9033\n",
      "Epoch 1798/2000\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0166 - acc: 0.9000 - val_loss: 0.0161 - val_acc: 0.9034\n",
      "Epoch 1799/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0166 - acc: 0.8999 - val_loss: 0.0161 - val_acc: 0.9034\n",
      "Epoch 1800/2000\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0166 - acc: 0.9000 - val_loss: 0.0161 - val_acc: 0.9035\n",
      "Epoch 1801/2000\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0166 - acc: 0.9000 - val_loss: 0.0161 - val_acc: 0.9035\n",
      "Epoch 1802/2000\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0166 - acc: 0.9000 - val_loss: 0.0161 - val_acc: 0.9034\n",
      "Epoch 1803/2000\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0166 - acc: 0.9000 - val_loss: 0.0161 - val_acc: 0.9034\n",
      "Epoch 1804/2000\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0166 - acc: 0.9001 - val_loss: 0.0161 - val_acc: 0.9034\n",
      "Epoch 1805/2000\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0166 - acc: 0.9001 - val_loss: 0.0161 - val_acc: 0.9035\n",
      "Epoch 1806/2000\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0166 - acc: 0.9001 - val_loss: 0.0161 - val_acc: 0.9036\n",
      "Epoch 1807/2000\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0166 - acc: 0.9001 - val_loss: 0.0160 - val_acc: 0.9037\n",
      "Epoch 1808/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0165 - acc: 0.9001 - val_loss: 0.0160 - val_acc: 0.9037\n",
      "Epoch 1809/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0165 - acc: 0.9002 - val_loss: 0.0160 - val_acc: 0.9037\n",
      "Epoch 1810/2000\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0165 - acc: 0.9002 - val_loss: 0.0160 - val_acc: 0.9038\n",
      "Epoch 1811/2000\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0165 - acc: 0.9001 - val_loss: 0.0160 - val_acc: 0.9037\n",
      "Epoch 1812/2000\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0165 - acc: 0.9003 - val_loss: 0.0160 - val_acc: 0.9037\n",
      "Epoch 1813/2000\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0165 - acc: 0.9002 - val_loss: 0.0160 - val_acc: 0.9037\n",
      "Epoch 1814/2000\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0165 - acc: 0.9003 - val_loss: 0.0160 - val_acc: 0.9038\n",
      "Epoch 1815/2000\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0165 - acc: 0.9003 - val_loss: 0.0160 - val_acc: 0.9038\n",
      "Epoch 1816/2000\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0165 - acc: 0.9004 - val_loss: 0.0160 - val_acc: 0.9037\n",
      "Epoch 1817/2000\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0165 - acc: 0.9004 - val_loss: 0.0160 - val_acc: 0.9037\n",
      "Epoch 1818/2000\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0165 - acc: 0.9004 - val_loss: 0.0160 - val_acc: 0.9038\n",
      "Epoch 1819/2000\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0165 - acc: 0.9005 - val_loss: 0.0160 - val_acc: 0.9039\n",
      "Epoch 1820/2000\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0165 - acc: 0.9006 - val_loss: 0.0160 - val_acc: 0.9039\n",
      "Epoch 1821/2000\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0165 - acc: 0.9007 - val_loss: 0.0160 - val_acc: 0.9040\n",
      "Epoch 1822/2000\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0164 - acc: 0.9007 - val_loss: 0.0159 - val_acc: 0.9040\n",
      "Epoch 1823/2000\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0164 - acc: 0.9007 - val_loss: 0.0159 - val_acc: 0.9040\n",
      "Epoch 1824/2000\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0164 - acc: 0.9008 - val_loss: 0.0159 - val_acc: 0.9041\n",
      "Epoch 1825/2000\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0164 - acc: 0.9008 - val_loss: 0.0159 - val_acc: 0.9041\n",
      "Epoch 1826/2000\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0164 - acc: 0.9008 - val_loss: 0.0159 - val_acc: 0.9042\n",
      "Epoch 1827/2000\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0164 - acc: 0.9008 - val_loss: 0.0159 - val_acc: 0.9042\n",
      "Epoch 1828/2000\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0164 - acc: 0.9009 - val_loss: 0.0159 - val_acc: 0.9042\n",
      "Epoch 1829/2000\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0164 - acc: 0.9009 - val_loss: 0.0159 - val_acc: 0.9042\n",
      "Epoch 1830/2000\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0164 - acc: 0.9010 - val_loss: 0.0159 - val_acc: 0.9042\n",
      "Epoch 1831/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0164 - acc: 0.9010 - val_loss: 0.0159 - val_acc: 0.9042\n",
      "Epoch 1832/2000\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0164 - acc: 0.9011 - val_loss: 0.0159 - val_acc: 0.9043\n",
      "Epoch 1833/2000\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0164 - acc: 0.9011 - val_loss: 0.0159 - val_acc: 0.9044\n",
      "Epoch 1834/2000\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0164 - acc: 0.9012 - val_loss: 0.0159 - val_acc: 0.9044\n",
      "Epoch 1835/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0164 - acc: 0.9012 - val_loss: 0.0159 - val_acc: 0.9044\n",
      "Epoch 1836/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0163 - acc: 0.9013 - val_loss: 0.0159 - val_acc: 0.9044\n",
      "Epoch 1837/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0163 - acc: 0.9012 - val_loss: 0.0158 - val_acc: 0.9045\n",
      "Epoch 1838/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0163 - acc: 0.9012 - val_loss: 0.0158 - val_acc: 0.9046\n",
      "Epoch 1839/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0163 - acc: 0.9013 - val_loss: 0.0158 - val_acc: 0.9046\n",
      "Epoch 1840/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0163 - acc: 0.9014 - val_loss: 0.0158 - val_acc: 0.9045\n",
      "Epoch 1841/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0163 - acc: 0.9014 - val_loss: 0.0158 - val_acc: 0.9045\n",
      "Epoch 1842/2000\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0163 - acc: 0.9014 - val_loss: 0.0158 - val_acc: 0.9045\n",
      "Epoch 1843/2000\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 0.0163 - acc: 0.901 - 1s 20us/step - loss: 0.0163 - acc: 0.9016 - val_loss: 0.0158 - val_acc: 0.9045\n",
      "Epoch 1844/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0163 - acc: 0.9015 - val_loss: 0.0158 - val_acc: 0.9045\n",
      "Epoch 1845/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0163 - acc: 0.9015 - val_loss: 0.0158 - val_acc: 0.9045\n",
      "Epoch 1846/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0163 - acc: 0.9015 - val_loss: 0.0158 - val_acc: 0.9045\n",
      "Epoch 1847/2000\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0163 - acc: 0.9016 - val_loss: 0.0158 - val_acc: 0.9046\n",
      "Epoch 1848/2000\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0163 - acc: 0.9017 - val_loss: 0.0158 - val_acc: 0.9046\n",
      "Epoch 1849/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0163 - acc: 0.9017 - val_loss: 0.0158 - val_acc: 0.9046\n",
      "Epoch 1850/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0163 - acc: 0.9017 - val_loss: 0.0158 - val_acc: 0.9046\n",
      "Epoch 1851/2000\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0162 - acc: 0.9018 - val_loss: 0.0158 - val_acc: 0.9046\n",
      "Epoch 1852/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0162 - acc: 0.9018 - val_loss: 0.0158 - val_acc: 0.9046\n",
      "Epoch 1853/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0162 - acc: 0.9018 - val_loss: 0.0157 - val_acc: 0.9048\n",
      "Epoch 1854/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0162 - acc: 0.9018 - val_loss: 0.0157 - val_acc: 0.9048\n",
      "Epoch 1855/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0162 - acc: 0.9018 - val_loss: 0.0157 - val_acc: 0.9048\n",
      "Epoch 1856/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0162 - acc: 0.9019 - val_loss: 0.0157 - val_acc: 0.9048\n",
      "Epoch 1857/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0162 - acc: 0.9019 - val_loss: 0.0157 - val_acc: 0.9049\n",
      "Epoch 1858/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0162 - acc: 0.9019 - val_loss: 0.0157 - val_acc: 0.9049\n",
      "Epoch 1859/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0162 - acc: 0.9019 - val_loss: 0.0157 - val_acc: 0.9050\n",
      "Epoch 1860/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0162 - acc: 0.9020 - val_loss: 0.0157 - val_acc: 0.9050\n",
      "Epoch 1861/2000\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0162 - acc: 0.9020 - val_loss: 0.0157 - val_acc: 0.9050\n",
      "Epoch 1862/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0162 - acc: 0.9021 - val_loss: 0.0157 - val_acc: 0.9050\n",
      "Epoch 1863/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0162 - acc: 0.9021 - val_loss: 0.0157 - val_acc: 0.9050\n",
      "Epoch 1864/2000\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0162 - acc: 0.9021 - val_loss: 0.0157 - val_acc: 0.9051\n",
      "Epoch 1865/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0162 - acc: 0.9022 - val_loss: 0.0157 - val_acc: 0.9051\n",
      "Epoch 1866/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0161 - acc: 0.9022 - val_loss: 0.0157 - val_acc: 0.9054\n",
      "Epoch 1867/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0161 - acc: 0.9022 - val_loss: 0.0157 - val_acc: 0.9054\n",
      "Epoch 1868/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0161 - acc: 0.9023 - val_loss: 0.0157 - val_acc: 0.9054\n",
      "Epoch 1869/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0161 - acc: 0.9022 - val_loss: 0.0156 - val_acc: 0.9054\n",
      "Epoch 1870/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0161 - acc: 0.9023 - val_loss: 0.0156 - val_acc: 0.9054\n",
      "Epoch 1871/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0161 - acc: 0.9024 - val_loss: 0.0156 - val_acc: 0.9054\n",
      "Epoch 1872/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0161 - acc: 0.9024 - val_loss: 0.0156 - val_acc: 0.9055\n",
      "Epoch 1873/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0161 - acc: 0.9025 - val_loss: 0.0156 - val_acc: 0.9055\n",
      "Epoch 1874/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0161 - acc: 0.9025 - val_loss: 0.0156 - val_acc: 0.9056\n",
      "Epoch 1875/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0161 - acc: 0.9026 - val_loss: 0.0156 - val_acc: 0.9055\n",
      "Epoch 1876/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0161 - acc: 0.9026 - val_loss: 0.0156 - val_acc: 0.9056\n",
      "Epoch 1877/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0161 - acc: 0.9027 - val_loss: 0.0156 - val_acc: 0.9056\n",
      "Epoch 1878/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0161 - acc: 0.9027 - val_loss: 0.0156 - val_acc: 0.9056\n",
      "Epoch 1879/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0161 - acc: 0.9027 - val_loss: 0.0156 - val_acc: 0.9056\n",
      "Epoch 1880/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0161 - acc: 0.9027 - val_loss: 0.0156 - val_acc: 0.9056\n",
      "Epoch 1881/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0160 - acc: 0.9028 - val_loss: 0.0156 - val_acc: 0.9056\n",
      "Epoch 1882/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0160 - acc: 0.9029 - val_loss: 0.0156 - val_acc: 0.9056\n",
      "Epoch 1883/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0160 - acc: 0.9029 - val_loss: 0.0156 - val_acc: 0.9057\n",
      "Epoch 1884/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0160 - acc: 0.9030 - val_loss: 0.0156 - val_acc: 0.9059\n",
      "Epoch 1885/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0160 - acc: 0.9030 - val_loss: 0.0156 - val_acc: 0.9059\n",
      "Epoch 1886/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0160 - acc: 0.9030 - val_loss: 0.0155 - val_acc: 0.9059\n",
      "Epoch 1887/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0160 - acc: 0.9031 - val_loss: 0.0155 - val_acc: 0.9059\n",
      "Epoch 1888/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0160 - acc: 0.9031 - val_loss: 0.0155 - val_acc: 0.9058\n",
      "Epoch 1889/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0160 - acc: 0.9031 - val_loss: 0.0155 - val_acc: 0.9060\n",
      "Epoch 1890/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0160 - acc: 0.9031 - val_loss: 0.0155 - val_acc: 0.9060\n",
      "Epoch 1891/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0160 - acc: 0.9031 - val_loss: 0.0155 - val_acc: 0.9062\n",
      "Epoch 1892/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0160 - acc: 0.9032 - val_loss: 0.0155 - val_acc: 0.9062\n",
      "Epoch 1893/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0160 - acc: 0.9033 - val_loss: 0.0155 - val_acc: 0.9062\n",
      "Epoch 1894/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0160 - acc: 0.9033 - val_loss: 0.0155 - val_acc: 0.9063\n",
      "Epoch 1895/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0160 - acc: 0.9032 - val_loss: 0.0155 - val_acc: 0.9063\n",
      "Epoch 1896/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0160 - acc: 0.9033 - val_loss: 0.0155 - val_acc: 0.9064\n",
      "Epoch 1897/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0159 - acc: 0.9034 - val_loss: 0.0155 - val_acc: 0.9065\n",
      "Epoch 1898/2000\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0159 - acc: 0.9034 - val_loss: 0.0155 - val_acc: 0.9065\n",
      "Epoch 1899/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0159 - acc: 0.9034 - val_loss: 0.0155 - val_acc: 0.9065\n",
      "Epoch 1900/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0159 - acc: 0.9035 - val_loss: 0.0155 - val_acc: 0.9067\n",
      "Epoch 1901/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0159 - acc: 0.9035 - val_loss: 0.0155 - val_acc: 0.9067\n",
      "Epoch 1902/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0159 - acc: 0.9035 - val_loss: 0.0155 - val_acc: 0.9068\n",
      "Epoch 1903/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0159 - acc: 0.9036 - val_loss: 0.0154 - val_acc: 0.9068\n",
      "Epoch 1904/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0159 - acc: 0.9036 - val_loss: 0.0154 - val_acc: 0.9068\n",
      "Epoch 1905/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0159 - acc: 0.9037 - val_loss: 0.0154 - val_acc: 0.9068\n",
      "Epoch 1906/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0159 - acc: 0.9037 - val_loss: 0.0154 - val_acc: 0.9068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1907/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0159 - acc: 0.9037 - val_loss: 0.0154 - val_acc: 0.9068\n",
      "Epoch 1908/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0159 - acc: 0.9037 - val_loss: 0.0154 - val_acc: 0.9069\n",
      "Epoch 1909/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0159 - acc: 0.9037 - val_loss: 0.0154 - val_acc: 0.9070\n",
      "Epoch 1910/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0159 - acc: 0.9039 - val_loss: 0.0154 - val_acc: 0.9071\n",
      "Epoch 1911/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0159 - acc: 0.9039 - val_loss: 0.0154 - val_acc: 0.9071\n",
      "Epoch 1912/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0159 - acc: 0.9039 - val_loss: 0.0154 - val_acc: 0.9072\n",
      "Epoch 1913/2000\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0158 - acc: 0.9039 - val_loss: 0.0154 - val_acc: 0.9071\n",
      "Epoch 1914/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0158 - acc: 0.9039 - val_loss: 0.0154 - val_acc: 0.9072\n",
      "Epoch 1915/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0158 - acc: 0.9040 - val_loss: 0.0154 - val_acc: 0.9072\n",
      "Epoch 1916/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0158 - acc: 0.9041 - val_loss: 0.0154 - val_acc: 0.9072\n",
      "Epoch 1917/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0158 - acc: 0.9040 - val_loss: 0.0154 - val_acc: 0.9072\n",
      "Epoch 1918/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0158 - acc: 0.9041 - val_loss: 0.0154 - val_acc: 0.9072\n",
      "Epoch 1919/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0158 - acc: 0.9042 - val_loss: 0.0154 - val_acc: 0.9072\n",
      "Epoch 1920/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0158 - acc: 0.9042 - val_loss: 0.0154 - val_acc: 0.9072\n",
      "Epoch 1921/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0158 - acc: 0.9041 - val_loss: 0.0153 - val_acc: 0.9071\n",
      "Epoch 1922/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0158 - acc: 0.9042 - val_loss: 0.0153 - val_acc: 0.9071\n",
      "Epoch 1923/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0158 - acc: 0.9042 - val_loss: 0.0153 - val_acc: 0.9071\n",
      "Epoch 1924/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0158 - acc: 0.9042 - val_loss: 0.0153 - val_acc: 0.9071\n",
      "Epoch 1925/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0158 - acc: 0.9043 - val_loss: 0.0153 - val_acc: 0.9071\n",
      "Epoch 1926/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0158 - acc: 0.9042 - val_loss: 0.0153 - val_acc: 0.9071\n",
      "Epoch 1927/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0158 - acc: 0.9043 - val_loss: 0.0153 - val_acc: 0.9071\n",
      "Epoch 1928/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0158 - acc: 0.9044 - val_loss: 0.0153 - val_acc: 0.9072\n",
      "Epoch 1929/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0157 - acc: 0.9044 - val_loss: 0.0153 - val_acc: 0.9071\n",
      "Epoch 1930/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0157 - acc: 0.9045 - val_loss: 0.0153 - val_acc: 0.9071\n",
      "Epoch 1931/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0157 - acc: 0.9045 - val_loss: 0.0153 - val_acc: 0.9072\n",
      "Epoch 1932/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0157 - acc: 0.9045 - val_loss: 0.0153 - val_acc: 0.9072\n",
      "Epoch 1933/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0157 - acc: 0.9045 - val_loss: 0.0153 - val_acc: 0.9073\n",
      "Epoch 1934/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0157 - acc: 0.9046 - val_loss: 0.0153 - val_acc: 0.9073\n",
      "Epoch 1935/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0157 - acc: 0.9046 - val_loss: 0.0153 - val_acc: 0.9074\n",
      "Epoch 1936/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0157 - acc: 0.9048 - val_loss: 0.0153 - val_acc: 0.9074\n",
      "Epoch 1937/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0157 - acc: 0.9047 - val_loss: 0.0153 - val_acc: 0.9074\n",
      "Epoch 1938/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0157 - acc: 0.9047 - val_loss: 0.0153 - val_acc: 0.9074\n",
      "Epoch 1939/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0157 - acc: 0.9047 - val_loss: 0.0152 - val_acc: 0.9076\n",
      "Epoch 1940/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0157 - acc: 0.9048 - val_loss: 0.0152 - val_acc: 0.9076\n",
      "Epoch 1941/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0157 - acc: 0.9048 - val_loss: 0.0152 - val_acc: 0.9078\n",
      "Epoch 1942/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0157 - acc: 0.9048 - val_loss: 0.0152 - val_acc: 0.9078\n",
      "Epoch 1943/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0157 - acc: 0.9048 - val_loss: 0.0152 - val_acc: 0.9078\n",
      "Epoch 1944/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0157 - acc: 0.9049 - val_loss: 0.0152 - val_acc: 0.9078\n",
      "Epoch 1945/2000\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 0.0156 - acc: 0.904 - 1s 22us/step - loss: 0.0157 - acc: 0.9049 - val_loss: 0.0152 - val_acc: 0.9078\n",
      "Epoch 1946/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0156 - acc: 0.9050 - val_loss: 0.0152 - val_acc: 0.9078\n",
      "Epoch 1947/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0156 - acc: 0.9049 - val_loss: 0.0152 - val_acc: 0.9078\n",
      "Epoch 1948/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0156 - acc: 0.9051 - val_loss: 0.0152 - val_acc: 0.9078\n",
      "Epoch 1949/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0156 - acc: 0.9051 - val_loss: 0.0152 - val_acc: 0.9080\n",
      "Epoch 1950/2000\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0156 - acc: 0.9050 - val_loss: 0.0152 - val_acc: 0.9080\n",
      "Epoch 1951/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0156 - acc: 0.9052 - val_loss: 0.0152 - val_acc: 0.9081\n",
      "Epoch 1952/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0156 - acc: 0.9052 - val_loss: 0.0152 - val_acc: 0.9082\n",
      "Epoch 1953/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0156 - acc: 0.9053 - val_loss: 0.0152 - val_acc: 0.9082\n",
      "Epoch 1954/2000\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0156 - acc: 0.9054 - val_loss: 0.0152 - val_acc: 0.9082\n",
      "Epoch 1955/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0156 - acc: 0.9053 - val_loss: 0.0152 - val_acc: 0.9082\n",
      "Epoch 1956/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0156 - acc: 0.9054 - val_loss: 0.0152 - val_acc: 0.9082\n",
      "Epoch 1957/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0156 - acc: 0.9055 - val_loss: 0.0151 - val_acc: 0.9082\n",
      "Epoch 1958/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0156 - acc: 0.9054 - val_loss: 0.0151 - val_acc: 0.9083\n",
      "Epoch 1959/2000\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0156 - acc: 0.9055 - val_loss: 0.0151 - val_acc: 0.9084\n",
      "Epoch 1960/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0156 - acc: 0.9055 - val_loss: 0.0151 - val_acc: 0.9084\n",
      "Epoch 1961/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0156 - acc: 0.9055 - val_loss: 0.0151 - val_acc: 0.9084\n",
      "Epoch 1962/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0156 - acc: 0.9056 - val_loss: 0.0151 - val_acc: 0.9084\n",
      "Epoch 1963/2000\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0155 - acc: 0.9056 - val_loss: 0.0151 - val_acc: 0.9084\n",
      "Epoch 1964/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0155 - acc: 0.9056 - val_loss: 0.0151 - val_acc: 0.9084\n",
      "Epoch 1965/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0155 - acc: 0.9057 - val_loss: 0.0151 - val_acc: 0.9085\n",
      "Epoch 1966/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0155 - acc: 0.9057 - val_loss: 0.0151 - val_acc: 0.9086\n",
      "Epoch 1967/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0155 - acc: 0.9058 - val_loss: 0.0151 - val_acc: 0.9087\n",
      "Epoch 1968/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0155 - acc: 0.9057 - val_loss: 0.0151 - val_acc: 0.9089\n",
      "Epoch 1969/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0155 - acc: 0.9059 - val_loss: 0.0151 - val_acc: 0.9089\n",
      "Epoch 1970/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0155 - acc: 0.9058 - val_loss: 0.0151 - val_acc: 0.9090\n",
      "Epoch 1971/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0155 - acc: 0.9058 - val_loss: 0.0151 - val_acc: 0.9090\n",
      "Epoch 1972/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0155 - acc: 0.9059 - val_loss: 0.0151 - val_acc: 0.9090\n",
      "Epoch 1973/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0155 - acc: 0.9060 - val_loss: 0.0151 - val_acc: 0.9090\n",
      "Epoch 1974/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0155 - acc: 0.9060 - val_loss: 0.0151 - val_acc: 0.9090\n",
      "Epoch 1975/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0155 - acc: 0.9059 - val_loss: 0.0151 - val_acc: 0.9090\n",
      "Epoch 1976/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0155 - acc: 0.9060 - val_loss: 0.0150 - val_acc: 0.9090\n",
      "Epoch 1977/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0155 - acc: 0.9061 - val_loss: 0.0150 - val_acc: 0.9091\n",
      "Epoch 1978/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0155 - acc: 0.9061 - val_loss: 0.0150 - val_acc: 0.9091\n",
      "Epoch 1979/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0155 - acc: 0.9061 - val_loss: 0.0150 - val_acc: 0.9091\n",
      "Epoch 1980/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0155 - acc: 0.9063 - val_loss: 0.0150 - val_acc: 0.9091\n",
      "Epoch 1981/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0154 - acc: 0.9063 - val_loss: 0.0150 - val_acc: 0.9091\n",
      "Epoch 1982/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0154 - acc: 0.9063 - val_loss: 0.0150 - val_acc: 0.9091\n",
      "Epoch 1983/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0154 - acc: 0.9062 - val_loss: 0.0150 - val_acc: 0.9091\n",
      "Epoch 1984/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0154 - acc: 0.9062 - val_loss: 0.0150 - val_acc: 0.9091\n",
      "Epoch 1985/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0154 - acc: 0.9062 - val_loss: 0.0150 - val_acc: 0.9090\n",
      "Epoch 1986/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0154 - acc: 0.9062 - val_loss: 0.0150 - val_acc: 0.9091\n",
      "Epoch 1987/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0154 - acc: 0.9063 - val_loss: 0.0150 - val_acc: 0.9091\n",
      "Epoch 1988/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0154 - acc: 0.9063 - val_loss: 0.0150 - val_acc: 0.9091\n",
      "Epoch 1989/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0154 - acc: 0.9064 - val_loss: 0.0150 - val_acc: 0.9092\n",
      "Epoch 1990/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0154 - acc: 0.9064 - val_loss: 0.0150 - val_acc: 0.9092\n",
      "Epoch 1991/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0154 - acc: 0.9064 - val_loss: 0.0150 - val_acc: 0.9092\n",
      "Epoch 1992/2000\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0154 - acc: 0.9065 - val_loss: 0.0150 - val_acc: 0.9092\n",
      "Epoch 1993/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0154 - acc: 0.9065 - val_loss: 0.0150 - val_acc: 0.9092\n",
      "Epoch 1994/2000\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0154 - acc: 0.9065 - val_loss: 0.0150 - val_acc: 0.9093\n",
      "Epoch 1995/2000\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0154 - acc: 0.9066 - val_loss: 0.0150 - val_acc: 0.9093\n",
      "Epoch 1996/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0154 - acc: 0.9067 - val_loss: 0.0149 - val_acc: 0.9093\n",
      "Epoch 1997/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0154 - acc: 0.9067 - val_loss: 0.0149 - val_acc: 0.9093\n",
      "Epoch 1998/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0154 - acc: 0.9067 - val_loss: 0.0149 - val_acc: 0.9093\n",
      "Epoch 1999/2000\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0153 - acc: 0.9067 - val_loss: 0.0149 - val_acc: 0.9093\n",
      "Epoch 2000/2000\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0153 - acc: 0.9067 - val_loss: 0.0149 - val_acc: 0.9093\n"
     ]
    }
   ],
   "source": [
    "model1_1 = model1.fit(x_train_st, y_train, batch_size=150, epochs=2000, verbose=1, validation_data=(x_test_st, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 畫圖 accuracy as a function of epochs\n",
    "plt.plot(model1_1.history[\"acc\"])\n",
    "\n",
    "plt.title(\"training accuracy\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend([\"lr = 0.01\"], loc = \"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 能發現即使到了 epoch = 2000 正確率已到了 0.9067 仍有些微上升的趨勢, 因此很可能會趨於最大的正確率。\n",
    "* 但對於較大的 lr 來說它能很快的達到差不多的正確率, 因此可了解到並不是 lr 越小越好, 在時間及正確率的評估下應選擇一個正確率不會下降太多但達到最大值的 epoch 能越少越好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
